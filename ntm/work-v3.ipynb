{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of the Linear Logic Recurrent Neural Network (LLRNN)\n",
    "#\n",
    "\n",
    "################\n",
    "# GLOBAL FLAGS #\n",
    "################\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, pattern_ntm_alt\n",
    "task                  = 'copy' # copy, repeat copy, pattern\n",
    "epoch                 = 2 # number of training epochs, default to 200\n",
    "num_classes           = 10 # number of symbols, INCLUDING initial and terminal symbols\n",
    "N                     = 30 # length of input sequences for training, default to 20, INCLUDING initial and terminal symbols\n",
    "Ntest                 = 35 # length of sequences for testing, default to N, INCLUDING initial and terminal symbols\n",
    "batch_size            = 250 # default to 500 (too large does not fit on GPUs)\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "memory_address_size   = 128 # number of memory locations, default 20\n",
    "memory_content_size   = 20 # size of vector stored at a memory location, default 5\n",
    "powers_ring1          = [0,-1,1] # powers of R used on ring 1, default [0,-1,1]\n",
    "powers_ring2          = [0,-1,1] # powers of R used on ring 2, default [0,-1,1]\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "num_training          = 10000 # default to int(training_percent * (num_classes-2)**N)\n",
    "num_test              = num_training\n",
    "init_symbol           = num_classes - 2\n",
    "term_symbol           = num_classes - 1\n",
    "seq_length_min        = 3\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[3, 4, 0, 2, 6, 4, 3, 6, 2, 3, 4, 6, 4, 0, 3, 3, 0, 6, 2, 7, 0, 4, 1, 3, 1, 5, 6, 0, 6, 7]\n",
      "is mapped to\n",
      "[3, 4, 0, 2, 6, 4, 3, 6, 2, 3, 4, 6, 4, 0, 3, 3, 0, 6, 2, 7, 0, 4, 1, 3, 1, 5, 6, 0, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "if( task == 'repeat copy' ):\n",
    "    pattern = [0,1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "##############\n",
    "# PATTERN TASK\n",
    "if( task == 'pattern' ):\n",
    "    pattern = [1,0,0,2,0]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = [random.randint(0,num_classes-3) for i in range(N)]\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "state_size = 0\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "\n",
    "def init_state_ntm(batch_size, css, mas, mcs):\n",
    "    state_size = controller_state_size + 2*memory_address_size + memory_address_size * memory_content_size\n",
    "    \n",
    "    ra = [0.0]*mas\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,mas]) + ra\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    init_read_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_write_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_memory = tf.truncated_normal([batch_size, mas*mcs], 0.0, 1e-6, dtype=tf.float32)\n",
    "    \n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, memory_address_size, memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,memory_address_size,memory_content_size, powers_ring1)\n",
    "        \n",
    "#############\n",
    "# PATTERN NTM\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n",
    "    \n",
    "#################\n",
    "# PATTERN NTM ALT\n",
    "if( use_model == 'pattern_ntm_alt' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM_alt(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_114/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_112/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_110/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_108/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_106/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_104/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_102/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_100/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_98/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_96/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_94/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_92/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_90/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_88/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_86/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_84/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_82/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_80/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_78/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_76/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_74/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_72/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_70/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_68/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_66/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_64/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_62/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_60/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_58/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_56/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_54/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_52/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_50/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_48/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_46/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_44/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_42/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_40/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_38/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_36/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_34/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_32/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_30/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_28/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_26/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_24/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_22/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_20/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_18/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_16/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_14/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "write_addresses = []\n",
    "gamma_writes = []\n",
    "gamma_reads = []\n",
    "ss = []\n",
    "rnn_outputs = []\n",
    "    \n",
    "for i in range(N + N_out):\n",
    "    # Logging\n",
    "    h0, curr_read, curr_write, _ = tf.split(state, [controller_state_size,\n",
    "                                                    memory_address_size,\n",
    "                                                    memory_address_size,-1], 1)\n",
    "    \n",
    "    #### RUN MODEL ####\n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "    ###################\n",
    "    \n",
    "    # More logging\n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    with tf.variable_scope(\"NTM\",reuse=True):\n",
    "        W_gamma_write = tf.get_variable(\"W_gamma_write\", [controller_state_size,1])\n",
    "        B_gamma_write = tf.get_variable(\"B_gamma_write\", [])\n",
    "        gamma_write = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_write) + B_gamma_write) # shape [batch_size,1]\n",
    "        \n",
    "        W_gamma_read = tf.get_variable(\"W_gamma_read\", [controller_state_size,1])\n",
    "        B_gamma_read = tf.get_variable(\"B_gamma_read\", [])\n",
    "        gamma_read = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_read) + B_gamma_read) # shape [batch_size,1]\n",
    "        \n",
    "        W_s = tf.get_variable(\"W_s\", [controller_state_size,len(powers_ring1)])\n",
    "        B_s = tf.get_variable(\"B_s\", [len(powers_ring1)])\n",
    "        s = tf.nn.softmax(tf.matmul(h0,W_s) + B_s) # shape [batch_size,len(powers)]\n",
    "\n",
    "    gamma_writes.append(gamma_write[0,:])\n",
    "    gamma_reads.append(gamma_read[0,:])\n",
    "    ss.append(s[0,:])\n",
    "    reuse = True\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# Note: prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "\n",
    "# Note: We allow the length of input sequences to vary between batches, which means\n",
    "# that the cross entropy needs to be masked to the relevant part of the output\n",
    "\n",
    "# Note: we use log_softmax to avoid precision issues with floats causing log(0) to create NaNs\n",
    "\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.log_softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * prediction[i]) for i in range(N + N_out)] # an array of numbers\n",
    "mask = [tf.sign(tf.reduce_max(tf.abs(targets[i]))) for i in range(N + N_out)]\n",
    "ce_mask = [ce[i] * mask[i] for i in range(N + N_out)]\n",
    "cross_entropy = -tf.add_n(ce_mask)\n",
    "cross_entropy /= tf.add_n(mask) # DEBUG do we really need this?\n",
    "# NOTE: here in creating the mask we are assuming that batches have the same sequence length\n",
    "                    \n",
    "# optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "optimizer = tf.train.RMSPropOptimizer(1e-4,decay=0.9,momentum=0.9)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N + N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "errors_mask = [errors[i] * mask[i] for i in range(N + N_out)]\n",
    "mean_error = tf.add_n(errors_mask)\n",
    "mean_error /= tf.add_n(mask)\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 0 r-argmax [0] w-argmax [0] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 1 r-argmax [1] w-argmax [127] r-gamma [ 1.10664034] w-gamma [ 1.]\n",
      " Step 2 r-argmax [0] w-argmax [0] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 3 r-argmax [0] w-argmax [0] r-gamma [ 1.13913596] w-gamma [ 1.42873085]\n",
      " Step 4 r-argmax [0] w-argmax [0] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 5 r-argmax [0] w-argmax [127] r-gamma [ 1.29377246] w-gamma [ 1.05964637]\n",
      " Step 6 r-argmax [0] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.24010253]\n",
      " Step 7 r-argmax [0] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 8 r-argmax [0] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 9 r-argmax [0] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.45431781]\n",
      " Step 10 r-argmax [0] w-argmax [127] r-gamma [ 1.32226253] w-gamma [ 1.15934384]\n",
      " Step 11 r-argmax [0] w-argmax [0] r-gamma [ 1.71228981] w-gamma [ 1.81347656]\n",
      " Step 12 r-argmax [0] w-argmax [0] r-gamma [ 1.68183863] w-gamma [ 1.09685695]\n",
      " Step 13 r-argmax [0] w-argmax [127] r-gamma [ 1.06158054] w-gamma [ 1.]\n",
      " Step 14 r-argmax [0] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 15 r-argmax [127] w-argmax [127] r-gamma [ 1.14189458] w-gamma [ 1.05313873]\n",
      " Step 16 r-argmax [127] w-argmax [127] r-gamma [ 1.21565413] w-gamma [ 1.11209142]\n",
      " Step 17 r-argmax [126] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 18 r-argmax [126] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 19 r-argmax [126] w-argmax [127] r-gamma [ 1.19294167] w-gamma [ 1.]\n",
      " Step 20 r-argmax [126] w-argmax [127] r-gamma [ 1.10859621] w-gamma [ 1.]\n",
      " Step 21 r-argmax [125] w-argmax [127] r-gamma [ 1.41053975] w-gamma [ 1.]\n",
      " Step 22 r-argmax [125] w-argmax [0] r-gamma [ 1.26493716] w-gamma [ 1.]\n",
      " Step 23 r-argmax [125] w-argmax [127] r-gamma [ 1.02930844] w-gamma [ 1.]\n",
      " Step 24 r-argmax [124] w-argmax [127] r-gamma [ 1.17694259] w-gamma [ 1.]\n",
      " Step 25 r-argmax [124] w-argmax [0] r-gamma [ 1.02760577] w-gamma [ 1.]\n",
      " Step 26 r-argmax [124] w-argmax [127] r-gamma [ 1.20430791] w-gamma [ 1.]\n",
      " Step 27 r-argmax [123] w-argmax [0] r-gamma [ 1.07944572] w-gamma [ 1.]\n",
      " Step 28 r-argmax [123] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 29 r-argmax [123] w-argmax [127] r-gamma [ 1.27111912] w-gamma [ 1.]\n",
      " Step 30 r-argmax [123] w-argmax [127] r-gamma [ 1.00234532] w-gamma [ 1.]\n",
      " Step 31 r-argmax [122] w-argmax [127] r-gamma [ 1.14267015] w-gamma [ 1.]\n",
      " Step 32 r-argmax [122] w-argmax [127] r-gamma [ 1.23802304] w-gamma [ 1.]\n",
      " Step 33 r-argmax [122] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 34 r-argmax [121] w-argmax [127] r-gamma [ 1.28926134] w-gamma [ 1.]\n",
      " Step 35 r-argmax [121] w-argmax [127] r-gamma [ 1.01478887] w-gamma [ 1.]\n",
      " Step 36 r-argmax [121] w-argmax [127] r-gamma [ 1.17874193] w-gamma [ 1.]\n",
      " Step 37 r-argmax [121] w-argmax [127] r-gamma [ 1.22329438] w-gamma [ 1.]\n",
      " Step 38 r-argmax [120] w-argmax [127] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 39 r-argmax [120] w-argmax [127] r-gamma [ 1.15221262] w-gamma [ 1.]\n",
      " Step 40 r-argmax [120] w-argmax [127] r-gamma [ 1.13817632] w-gamma [ 1.]\n",
      " Step 41 r-argmax [119] w-argmax [127] r-gamma [ 1.07498038] w-gamma [ 1.]\n",
      " Step 42 r-argmax [119] w-argmax [127] r-gamma [ 1.09208632] w-gamma [ 1.]\n",
      " Step 43 r-argmax [119] w-argmax [127] r-gamma [ 1.11352432] w-gamma [ 1.]\n",
      " Step 44 r-argmax [119] w-argmax [127] r-gamma [ 1.0896666] w-gamma [ 1.]\n",
      " Step 45 r-argmax [118] w-argmax [127] r-gamma [ 1.13092685] w-gamma [ 1.]\n",
      " Step 46 r-argmax [118] w-argmax [127] r-gamma [ 1.10368204] w-gamma [ 1.]\n",
      " Step 47 r-argmax [118] w-argmax [127] r-gamma [ 1.07432747] w-gamma [ 1.]\n",
      " Step 48 r-argmax [118] w-argmax [127] r-gamma [ 1.19611084] w-gamma [ 1.]\n",
      " Step 49 r-argmax [117] w-argmax [126] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 50 r-argmax [117] w-argmax [126] r-gamma [ 1.12801719] w-gamma [ 1.]\n",
      " Step 51 r-argmax [117] w-argmax [126] r-gamma [ 1.20734251] w-gamma [ 1.]\n",
      " Step 52 r-argmax [117] w-argmax [126] r-gamma [ 1.] w-gamma [ 1.]\n",
      " Step 53 r-argmax [116] w-argmax [126] r-gamma [ 1.20331168] w-gamma [ 1.]\n",
      " Step 54 r-argmax [116] w-argmax [126] r-gamma [ 1.08616078] w-gamma [ 1.]\n",
      " Step 55 r-argmax [116] w-argmax [126] r-gamma [ 1.0450964] w-gamma [ 1.]\n",
      " Step 56 r-argmax [116] w-argmax [126] r-gamma [ 1.21439898] w-gamma [ 1.]\n",
      " Step 57 r-argmax [115] w-argmax [126] r-gamma [ 1.] w-gamma [ 1.]\n",
      "Epoch - 1, length - 11, error - 0.867273\n",
      "Epoch - 2, length - 19, error - 0.838526\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It took 258.035415173 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "###################\n",
    "# Note on sequences\n",
    "#\n",
    "# Our sequences are of varying length, in the alphabet {0,...,num_classes - 3}.\n",
    "# Each input sequence begins with an initial symbol and ends with a terminal symbol\n",
    "# (the value of which are num_classes - 2 and num_classes - 1 by default). Output\n",
    "# sequences do not have either an initial nor a terminal symbol.\n",
    "#\n",
    "# Both input and output sequences are written on a \"tape\" of length N + N_out.\n",
    "# Input sequences are aligned at the BEGINNING of the tape, and all remaining space\n",
    "# is filled with terminal symbols. Output sequences are aligned at the END OF THE \n",
    "# MATCHING INPUT, with all remaining space filled with zero vectors.\n",
    "#\n",
    "# Example: suppose N = N_out = 10, and num_classes = 10 so that init_symbol = 8\n",
    "# and term_symbol = 9. Then a sequence of length 8 (seq_length = 10 below) is\n",
    "#\n",
    "# a = [4, 4, 5, 6, 3, 3, 6, 7]\n",
    "#\n",
    "# which written on the tape is\n",
    "#\n",
    "# [8, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "#\n",
    "# If we are performing the copy task, so that the output sequence is also a, then\n",
    "# the output written on the tape will be (notice the alignment)\n",
    "#\n",
    "# [-, -, -, -, -, -, -, -, -, 4, 4, 5, 6, 3, 3, 6, 7, -, -, -]\n",
    "#\n",
    "# where - is a symbol whose encoding is the zero vector.\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences. Each\n",
    "        # batch has a fixed length of the sequences. Recall that all input seqs\n",
    "        # have an initial and terminal symbol, so if seq_length = 10 then there\n",
    "        # are eight positions for the \"content\" symbols\n",
    "        seq_length = random.randint(seq_length_min,N)\n",
    "        \n",
    "        for z in range(batch_size):\n",
    "            a = [random.randint(0,num_classes-3) for k in range(seq_length-2)]\n",
    "            fa = a\n",
    "            a = [init_symbol] + a + [term_symbol] + [term_symbol for k in range(N+N_out-seq_length)]\n",
    "            a_onehot = [one_hots[e] for e in a]\n",
    "            fa_onehot = [[0.0]*num_classes for k in range(seq_length-1)] + [one_hots[e] for e in fa] + [[0.0]*num_classes for k in range(N+N_out-2*seq_length+3)]\n",
    "            inp.append(np.array(a_onehot))\n",
    "            out.append(np.array(fa_onehot))        \n",
    "        \n",
    "        # An annoying thing here is that we cannot use a list as a key in a \n",
    "        # dictionary. The workaround we found on StackOverflow here:\n",
    "        # http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "        feed_dict = {}\n",
    "        for d in range(N + N_out):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N + N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "        \n",
    "        # for the first batch in an epoch, we have some logging\n",
    "        if( j == 0 and i % 25 == 0 ):\n",
    "            ss_val, gamma_reads_val, gamma_writes_val, read_addresses_val, write_addresses_val = sess.run([ss, gamma_reads,gamma_writes,read_addresses,write_addresses],feed_dict)\n",
    "    \n",
    "            s = 0\n",
    "            for r in range(len(write_addresses_val)):\n",
    "                print(\" Step \" + str(s) + \" r-argmax [\" + str(read_addresses_val[r].argmax()) + \"]\" + \n",
    "                      \" w-argmax [\" + str(write_addresses_val[r].argmax()) + \"]\" +\n",
    "                      \" r-gamma \" + str(gamma_reads_val[r]) +\n",
    "                      \" w-gamma \" + str(gamma_writes_val[r]))\n",
    "\n",
    "                # \" w-rotations \" + str(ss_val[r])\n",
    "                #if( r == len(write_addresses_val) - 1 ):\n",
    "                #    print(\"Write address -\")\n",
    "                #    print(write_addresses_val[r])               \n",
    "                s = s + 1\n",
    "        \n",
    "        ##### Do gradient descent #####\n",
    "        summary,_ = sess.run([merged_summaries,minimize], feed_dict)\n",
    "        ########\n",
    "        \n",
    "        # Write out TensorBoard logs\n",
    "        file_writer.add_summary(summary)\n",
    "\n",
    "    current_mean = sess.run(mean_error, feed_dict)\n",
    "    \n",
    "    # Print the mean error of the final batch in the epoch\n",
    "    print(\"Epoch - \" + str(i+1) + \", length - \" + str(seq_length - 2) + \", error - \" + str(current_mean))\n",
    "    \n",
    "# Matplotlib\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "f.add_subplot(111,frameon=False)\n",
    "plt.tick_params(labelcolor='none',top='off',bottom='off',left='off',right='off')\n",
    "plt.xlabel(\"Memory location\")\n",
    "plt.ylabel(\"Time\")\n",
    "\n",
    "ax1.imshow(np.stack(write_addresses_val), cmap='bone', interpolation='nearest')\n",
    "ax1.set_title('Write address')\n",
    "ax2.imshow(np.stack(read_addresses_val), cmap='bone', interpolation='nearest')\n",
    "ax2.set_title('Read address')\n",
    "plt.show()\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took\", time.time() - pre_train_time, \"seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch - 1, Mean error - 0.855758\n",
      "Batch - 2, Mean error - 0.849455\n",
      "Batch - 3, Mean error - 0.851758\n",
      "Batch - 4, Mean error - 0.851394\n",
      "Batch - 5, Mean error - 0.856727\n",
      "Batch - 6, Mean error - 0.860364\n",
      "Batch - 7, Mean error - 0.855879\n",
      "Batch - 8, Mean error - 0.859394\n",
      "Batch - 9, Mean error - 0.854303\n",
      "Batch - 10, Mean error - 0.856606\n",
      "Batch - 11, Mean error - 0.856364\n",
      "Batch - 12, Mean error - 0.853455\n",
      "Batch - 13, Mean error - 0.857818\n",
      "Batch - 14, Mean error - 0.859394\n",
      "Batch - 15, Mean error - 0.852485\n",
      "Batch - 16, Mean error - 0.859636\n",
      "Batch - 17, Mean error - 0.847758\n",
      "Batch - 18, Mean error - 0.849939\n",
      "Batch - 19, Mean error - 0.859273\n",
      "Batch - 20, Mean error - 0.85503\n",
      "Batch - 21, Mean error - 0.850424\n",
      "Batch - 22, Mean error - 0.860485\n",
      "Batch - 23, Mean error - 0.862182\n",
      "Batch - 24, Mean error - 0.860727\n",
      "Batch - 25, Mean error - 0.862545\n",
      "Batch - 26, Mean error - 0.856\n",
      "Batch - 27, Mean error - 0.858303\n",
      "Batch - 28, Mean error - 0.860727\n",
      "Batch - 29, Mean error - 0.860485\n",
      "Batch - 30, Mean error - 0.857576\n",
      "Batch - 31, Mean error - 0.861818\n",
      "Batch - 32, Mean error - 0.852364\n",
      "Batch - 33, Mean error - 0.86097\n",
      "Batch - 34, Mean error - 0.857091\n",
      "Batch - 35, Mean error - 0.856\n",
      "Batch - 36, Mean error - 0.855394\n",
      "Batch - 37, Mean error - 0.854061\n",
      "Batch - 38, Mean error - 0.855273\n",
      "Batch - 39, Mean error - 0.860606\n",
      "Batch - 40, Mean error - 0.854545\n",
      "\n",
      "###########\n",
      "# Summary #\n",
      "###########\n",
      "\n",
      "model         - ntm\n",
      "task name     - copy\n",
      "num_classes   - 10\n",
      "N             - 30\n",
      "N_out         - 28\n",
      "Ntest         - 35\n",
      "Ntest_out     - 33\n",
      "ring 1 powers - [0, -1, 1]\n",
      "ring 2 powers - [0, -1, 1]\n",
      "# epochs      - 2\n",
      "# weights     - 18958\n",
      "(css,mas,mcs) - (100,128,20)\n",
      "num_training  - 10000/1000000000000000000000000000000\n",
      "num_test      - 10000/1000000000000000000000000000000\n",
      "\n",
      "\n",
      "error         - 0.856509\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size,\n",
    "                                  memory_address_size, memory_content_size)\n",
    "    \n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,memory_address_size,memory_content_size, powers_ring1) \n",
    "\n",
    "# Set up test graph\n",
    "rnn_outputs_test = []\n",
    "reuse = True\n",
    "for i in range(Ntest + Ntest_out):\n",
    "    output, state = cell(inputs_test[i],state,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "\n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size])\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.log_softmax(logit) for logit in logits_test] \n",
    "mask = [tf.sign(tf.reduce_max(tf.abs(targets_test[i]))) for i in range(Ntest + Ntest_out)]\n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest + Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "errors_test_mask = [errors_test[i] * mask[i] for i in range(Ntest + Ntest_out)]\n",
    "mean_error_test = tf.add_n(errors_test_mask)\n",
    "mean_error_test /= tf.add_n(mask)\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    # We sample each batch on the fly from the set of all sequences\n",
    "    seq_length = Ntest\n",
    "    \n",
    "    for z in range(batch_size):\n",
    "        a = [random.randint(0,num_classes-3) for k in range(seq_length-2)]        \n",
    "        fa = a\n",
    "        a = [init_symbol] + a + [term_symbol] + [term_symbol for k in range(Ntest+Ntest_out-seq_length)]            \n",
    "        a_onehot = [one_hots[e] for e in a]\n",
    "        fa_onehot = [[0.0]*num_classes for k in range(seq_length-1)] + [one_hots[e] for e in fa] + [[0.0]*num_classes for k in range(Ntest+Ntest_out-2*seq_length+3)]\n",
    "        inp.append(np.array(a_onehot))\n",
    "        out.append(np.array(fa_onehot))        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = sess.run(mean_error_test, feed_dict)\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"N_out         - \" + str(N_out))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"Ntest_out     - \" + str(Ntest_out))\n",
    "print(\"ring 1 powers - \" + str(powers_ring1))\n",
    "print(\"ring 2 powers - \" + str(powers_ring2))\n",
    "print(\"# epochs      - \" + str(epoch))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"(css,mas,mcs) - (\" + str(controller_state_size) + \",\" + str(memory_address_size) + \",\" + str(memory_content_size) + \")\")\n",
    "#print(\"train percent - \" + str(training_percent))\n",
    "print(\"num_training  - \" + str(num_training) + \"/\" + str(num_classes**N))\n",
    "print(\"num_test      - \" + str(num_test) + \"/\" + str(num_classes**N))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"error         - \" + str(final_error))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
