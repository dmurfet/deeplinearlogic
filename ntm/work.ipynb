{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of the Linear Logic Recurrent Neural Network (LLRNN)\n",
    "#\n",
    "# Version 11.0\n",
    "\n",
    "###################\n",
    "# HYPERPARAMETERS #\n",
    "###################\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, mult_pattern_ntm\n",
    "task                  = 'copy' # copy, repeat copy, pattern i, mult pattern i, variable pattern i\n",
    "epoch                 = 200 # number of training epochs, default to 200\n",
    "num_classes           = 10 # number of symbols, INCLUDING initial and terminal symbols, default 10\n",
    "N                     = 30 # length of input sequences for training, default to 30\n",
    "Ntest                 = 35 # length of sequences for testing, default to 35\n",
    "batch_size            = 250 # default 250\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "num_training          = 10000 # default 10000\n",
    "num_test              = num_training\n",
    "term_symbol           = num_classes - 1\n",
    "init_symbol           = num_classes - 2\n",
    "div_symbol            = num_classes - 3\n",
    "learning_rate         = 1e-4 # default 1e-4\n",
    "memory_init_bias      = 1.0 # default 1.0\n",
    "use_curriculum        = True # default True\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "\n",
    "##################\n",
    "# MODEL SPECIFIC #\n",
    "##################\n",
    "\n",
    "ntm_memory_address_size   = 128 # number of memory locations, default 128\n",
    "ntm_memory_content_size   = 20 # size of vector stored at a memory location, default 20\n",
    "ntm_powers                = [0,-1,1] # powers of R used by controller, default [0,-1,1]\n",
    "\n",
    "pattern_ntm_powers               = [[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "pattern_ntm_powers_2_on_1        = [0,1,2] # allowed powers used by ring 2 to manipulate ring 1\n",
    "pattern_ntm_memory_address_sizes = [128, 20] # number of memory locations for the three rings\n",
    "pattern_ntm_memory_content_sizes = [20, 3] # size of content vector for each ring\n",
    "pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "mult_pattern_ntm_powers               = [[0,-1,1],[0,-1,1],[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "mult_pattern_ntm_powers_2_on_1        = [0,1,2] # allowed powers used by rings 2,3 to manipulate ring 1\n",
    "mult_pattern_ntm_memory_address_sizes = [128, 20, 20, 10] # number of memory locations for the rings\n",
    "mult_pattern_ntm_memory_content_sizes = [20, 3, 3, 2] # size of content vector for each ring\n",
    "mult_pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs\n",
    "\n",
    "assert use_model == 'ntm' or use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[1, 0, 2, 1, 0, 1, 8, 3, 5, 1, 0, 3, 0, 0, 4, 7, 0, 2]\n",
      "is mapped to\n",
      "[3, 5, 5, 0, 3, 3, 0, 0, 0, 7, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "# Default sampling from space of inputs\n",
    "def generate_input_seq_default(max_symbol,input_length):\n",
    "    return [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "\n",
    "generate_input_seq = generate_input_seq_default\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "#\n",
    "# In this task the input is simply copied to the output (although we\n",
    "# require the RNN to output the first output symbol after the last\n",
    "# input symbol has been read, so this effectively requires the system\n",
    "# to store the input and later retrieve it)\n",
    "\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "    seq_length_min = 7\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "#\n",
    "# In this task every digit of the input is repeated.\n",
    "#\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "\n",
    "if( task == 'repeat copy' ):\n",
    "    no_of_copies = 2\n",
    "    pattern = [0]*(no_of_copies - 1) + [1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = no_of_copies * (N - 2)\n",
    "    Ntest_out = no_of_copies * (Ntest - 2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 1\n",
    "if( task == 'pattern 1' ):\n",
    "    pattern = [0,1,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,c,c,d,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = (N - 2) + divmod(N - 2, 2)[0] # N - 2 plus the number of times 2 divides N - 2\n",
    "    Ntest_out = (Ntest - 2) + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 2\n",
    "if( task == 'pattern 2' ):\n",
    "    pattern = [0,2] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = N - 2 + divmod(N - 2, 2)[0]\n",
    "    Ntest_out = Ntest - 2 + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 3\n",
    "if( task == 'pattern 3' ):\n",
    "    pattern = [0,2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,b,b,d,c,c,e,d,d,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 4 + (N - 2 - 2) * 3\n",
    "    Ntest_out = 4 + (Ntest - 2 - 2) * 3\n",
    "    seq_length_min = 7\n",
    "\n",
    "################\n",
    "# PATTERN TASK 4\n",
    "if( task == 'pattern 4' ):\n",
    "    pattern = [0,2,1,2,-2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,d,f,d,c,c,e,f,h,f,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 7\n",
    "\n",
    "################\n",
    "# PATTERN TASK 5\n",
    "if( task == 'pattern 5' ):\n",
    "    pattern = [4,1,1,-4] # so (a,b,c,d,e,f,...) goes to (a,e,f,g,k,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 7\n",
    "\n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 1\n",
    "if( task == 'mult pattern 1' or task == 'mult pattern 2'):\n",
    "    pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "    pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 2\n",
    "if( task == 'mult pattern 2' ):\n",
    "    # Almost everything is the same as mult pattern 1, but in pattern 2 we \n",
    "    # make sure there is a div symbol somewhere in the sequence\n",
    "    def generate_input_seq_forcediv(max_symbol,input_length):\n",
    "        t = [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "        div_pos = random.randint(0,len(t)-1)\n",
    "        t[div_pos] = div_symbol\n",
    "        return t\n",
    "    \n",
    "    generate_input_seq = generate_input_seq_forcediv\n",
    "\n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 3\n",
    "if( task == 'mult pattern 3'):\n",
    "    pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "    pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    pattern3 = [0,2] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2,pattern3],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 4\n",
    "if( task == 'mult pattern 4'):\n",
    "    pattern1 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    pattern2 = [2,-1] # so (a,b,c,d,e,f,...) goes to (a,c,b,d,c,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "\n",
    "#########################\n",
    "# VARIABLE PATTERN TASK 1\n",
    "#\n",
    "# The input is a pattern together with a string to which we are supposed to apply the\n",
    "# pattern, separated by an initial symbol. There is no division symbol.\n",
    "\n",
    "def generate_input_seq_varpattern1(max_symbol,input_length):\n",
    "    varpatterns = [[1],[2],[0,1],[0,2],[1,2]]\n",
    "    vp = varpatterns[random.randint(0,len(varpatterns)-1)]\n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "if( task == 'variable pattern 1'):\n",
    "    generate_input_seq = generate_input_seq_varpattern1\n",
    "    func_to_learn = lambda s: learnfuncs.f_varpattern(s,init_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 10\n",
    "    \n",
    "#########################\n",
    "# VARIABLE PATTERN TASK 2\n",
    "\n",
    "def generate_input_seq_varpattern2(max_symbol,input_length):\n",
    "    varpatterns = [[1],[2]]\n",
    "    varpatterns = varpatterns + [[0,1],[0,2],[1,2]]\n",
    "    varpatterns = varpatterns + [[0,1,0],[0,1,1],[0,1,2],[0,2,0],[0,2,1],[0,2,2],[1,1,2],[1,2,2]]\n",
    "    varpatterns = varpatterns + [[0,0,0,1],[0,0,0,2],[0,0,1,2],[0,1,1,2],[0,1,0,2],[0,2,0,2]]\n",
    "    vp = varpatterns[random.randint(0,len(varpatterns)-1)]\n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "if( task == 'variable pattern 2'):\n",
    "    generate_input_seq = generate_input_seq_varpattern2\n",
    "    func_to_learn = lambda s: learnfuncs.f_varpattern(s,init_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 13\n",
    "\n",
    "#########################\n",
    "# VARIABLE PATTERN TASK 3\n",
    "#\n",
    "# In this task we randomly generate the pattern from the alphabet 0,1,2\n",
    "# We also generate longer sequences than in task 1 or 2. By default\n",
    "# we generate patterns between length 1 and 8\n",
    "\n",
    "def generate_input_seq_varpattern3(max_symbol,input_length):\n",
    "    while( True ):\n",
    "        vp_length = random.randint(1,8)\n",
    "        vp = [random.randint(0,2) for k in range(vp_length)]\n",
    "        \n",
    "        # We cannot allow patterns that are all zeros\n",
    "        if( reduce( lambda x,y : x + y, vp) > 0 ):\n",
    "            break\n",
    "    \n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "if( task == 'variable pattern 3'):\n",
    "    generate_input_seq = generate_input_seq_varpattern3\n",
    "    func_to_learn = lambda s: learnfuncs.f_varpattern(s,init_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 20\n",
    "\n",
    "# Make sure the given N is above the minimum sequence length\n",
    "assert N >= seq_length_min\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = generate_input_seq(num_classes-3,N-2)\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "\n",
    "def init_state_ntm(batch_size, css, mas, mcs):\n",
    "    state_size = css + 2*mas + mas * mcs\n",
    "    \n",
    "    ra = [0.0]*mas\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,mas]) + ra\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    init_read_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_write_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_memory = tf.truncated_normal([batch_size, mas*mcs], 0.0, 1e-6, dtype=tf.float32)\n",
    "    \n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "#############\n",
    "# PATTERN NTM\n",
    "\n",
    "def init_state_pattern_ntm(batch_size, css, mas, mcs):\n",
    "    # mas and mcs are arrays of address sizes and content sizes for rings\n",
    "    state_size = css\n",
    "    \n",
    "    init_address = []\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        state_size = state_size + mas[i] * mcs[i] # for memory vector\n",
    "        state_size = state_size + 2 * mas[i] # for addresses (read and write)\n",
    "    \n",
    "        ra = [0.0]*mas[i]\n",
    "        ra[0] = 1.0\n",
    "        init_address.append(np.zeros([batch_size,mas[i]]) + ra)\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    \n",
    "    tensor_list = [init_controller_state]\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        init_read_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        init_write_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        tensor_list = tensor_list + [init_read_address,init_write_address]\n",
    "        \n",
    "    for i in range(len(mas)):\n",
    "        # The first ring is initialised to zero, the rest differently\n",
    "        if( i == 0 ):\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "        else:\n",
    "            # This initialisation has the result of biasing the output of rings 2 and 3 to be\n",
    "            # \"no rotation\" and biasing ring 4 to say \"use ring 2\"\n",
    "            ra = [0.0]*mcs[i] \n",
    "            ra[0] = memory_init_bias\n",
    "            ra = np.zeros([batch_size,mas[i],mcs[i]]) + ra\n",
    "            ra = tf.constant(ra,dtype=tf.float32,shape=[batch_size,mas[i],mcs[i]])\n",
    "            ra = tf.reshape(ra,[batch_size,mas[i]*mcs[i]])\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32) + ra\n",
    "            #init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "            \n",
    "        tensor_list = tensor_list + [init_memory]\n",
    "    \n",
    "    state = tf.concat(tensor_list,1)\n",
    "\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "######################\n",
    "# MULTIPLE PATTERN NTM\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_55/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_54/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_53/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_52/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_51/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_50/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_49/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_48/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_47/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_46/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_45/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_44/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_43/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_42/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_41/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_40/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_39/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_38/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_37/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_36/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_35/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_34/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_33/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_32/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_31/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_30/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_29/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_28/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_27/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_26/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_25/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_24/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_23/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_22/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_21/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_20/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_19/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_18/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_17/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_16/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_15/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_14/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_13/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_11/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_9/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_7/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_5/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_3/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_1/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "read_addresses2 = []\n",
    "read_addresses3 = []\n",
    "read_addresses4 = []\n",
    "write_addresses = []\n",
    "write_addresses2 = []\n",
    "write_addresses3 = []\n",
    "write_addresses4 = []\n",
    "interps = []\n",
    "rnn_outputs = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "    \n",
    "for i in range(N + N_out):\n",
    "    \n",
    "    old_state = state\n",
    "\n",
    "    #### RUN MODEL ####\n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "    ###################\n",
    "\n",
    "    reuse = True\n",
    "    \n",
    "    #### SET UP NODES FOR LOGGING #####\n",
    "    if( use_model == 'ntm' ):\n",
    "        h0, curr_read, curr_write, _ = tf.split(old_state, [controller_state_size,ntm_memory_address_size,\n",
    "                                                        ntm_memory_address_size,-1], 1)\n",
    "\n",
    "    if( use_model == 'pattern_ntm' ):\n",
    "        mas = pattern_ntm_memory_address_sizes\n",
    "        mcs = pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(old_state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],mas[0] * mcs[0],mas[1] * mcs[1]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        m1_state = ret[5]\n",
    "        m2_state = ret[6]\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm' ):\n",
    "        mas = mult_pattern_ntm_memory_address_sizes\n",
    "        mcs = mult_pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(old_state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],                        \n",
    "                            mas[2],mas[2],mas[3],mas[3],mas[0] * mcs[0],mas[1] * mcs[1],\n",
    "                            mas[2] * mcs[2],mas[3] * mcs[3]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        curr_read3 = ret[5]\n",
    "        curr_write3 = ret[6]\n",
    "        curr_read4 = ret[7]\n",
    "        curr_write4 = ret[8]\n",
    "        m1_state = ret[9]\n",
    "        m2_state = ret[10]\n",
    "        m3_state = ret[11]\n",
    "        m4_state = ret[12]\n",
    "        \n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses2.append(curr_read2[0,:])\n",
    "        write_addresses2.append(curr_write2[0,:])\n",
    "        m2_state = tf.reshape(m2_state, [-1,mas[1],mcs[1]])\n",
    "        m2.append(tf.nn.softmax(m2_state[0,:]))\n",
    "        \n",
    "        with tf.variable_scope(\"NTM\",reuse=True):\n",
    "            W_interp = tf.get_variable(\"W_interp\", [controller_state_size,1])\n",
    "            B_interp = tf.get_variable(\"B_interp\", [1])\n",
    "            interp = tf.sigmoid(tf.matmul(h0,W_interp) + B_interp)\n",
    "            interp_matrix = tf.concat([interp,tf.ones_like(interp,dtype=tf.float32) - interp],axis=1) # shape [-1,2]\n",
    "            interps.append(interp_matrix[0,:])\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses3.append(curr_read3[0,:])\n",
    "        write_addresses3.append(curr_write3[0,:])\n",
    "        read_addresses4.append(curr_read4[0,:])\n",
    "        write_addresses4.append(curr_write4[0,:])\n",
    "        m3_state = tf.reshape(m3_state, [-1,mult_pattern_ntm_memory_address_sizes[2],mult_pattern_ntm_memory_content_sizes[2]])\n",
    "        m3.append(tf.nn.softmax(m3_state[0,:]))\n",
    "        m4_state = tf.reshape(m4_state, [-1,mult_pattern_ntm_memory_address_sizes[3],mult_pattern_ntm_memory_content_sizes[3]])\n",
    "        m4_state = m4_state[0,:]\n",
    "        m4_state = tf.concat([tf.nn.softmax(m4_state),tf.zeros([mult_pattern_ntm_memory_address_sizes[3],1])],1)\n",
    "        m4.append(m4_state)\n",
    "    ### END LOGGING ###\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# Note: prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "# Note: we use log_softmax to avoid precision issues with floats causing log(0) to create NaNs\n",
    "\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.log_softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * prediction[i]) for i in range(N + N_out)] # an array of numbers\n",
    "\n",
    "# Note: We allow the length of input sequences to vary between batches, which means\n",
    "# that the cross entropy needs to be masked to the relevant part of the output. The\n",
    "# relevant part consists of those positions that are not terminal symbols in the output\n",
    "# of _every_ input sequence in the batch. We detect such positions as follows. First,\n",
    "# we create a tensor term_detector which detects all the positions which are terminal symbols.\n",
    "# term_detector[i] is a boolean tensor which has False for those elements of the batch with\n",
    "# a terminal symbol in the output position i, and True otherwise.\n",
    "\n",
    "term_detector = [tf.not_equal(tf.argmax(targets[i],1),term_symbol) for i in range(N + N_out)]\n",
    "\n",
    "# We then convert False to 0.0 and True to 1.0, and compute the reduce_max, with the result\n",
    "# that mask is 1.0 in position i if and only if there was SOME element of the batch which\n",
    "# did NOT have a terminal symbol in position i\n",
    "\n",
    "mask = [tf.reduce_max(tf.cast(m, tf.float32)) for m in term_detector]\n",
    "ce_mask = [ce[i] * mask[i] for i in range(N + N_out)]\n",
    "cross_entropy = -tf.add_n(ce_mask)\n",
    "cross_entropy /= tf.add_n(mask)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate,decay=0.9,momentum=0.9)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N + N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "errors_mask = [errors[i] * mask[i] for i in range(N + N_out)]\n",
    "mean_error = tf.add_n(errors_mask)\n",
    "mean_error /= tf.add_n(mask)\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1, mean error - 0.756892\n",
      "Epoch - 2, mean error - 0.366811\n",
      "\n",
      "It took 68 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "###################\n",
    "# Note on sequences\n",
    "#\n",
    "# Our sequences are of varying length, in the alphabet {0,...,num_classes - 3}.\n",
    "# Each input sequence begins with an initial symbol and ends with a terminal symbol\n",
    "# (the value of which are num_classes - 2 and num_classes - 1 by default).\n",
    "#\n",
    "# Both input and output sequences are written on a \"tape\" of length N + N_out.\n",
    "# Input sequences are aligned at the BEGINNING of the tape, and all remaining space\n",
    "# is filled with terminal symbols. Output sequences are aligned at the END OF THE \n",
    "# MATCHING INPUT, with all remaining space filled with terminal symbols.\n",
    "#\n",
    "# Example: suppose N = N_out = 10, and num_classes = 10 so that init_symbol = 8\n",
    "# and term_symbol = 9. Then a sequence of length 8 (seq_length = 10 below) is\n",
    "#\n",
    "# a = [4, 4, 5, 6, 3, 3, 6, 7]\n",
    "#\n",
    "# which written on the tape is\n",
    "#\n",
    "# [8, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "#\n",
    "# If we are performing the copy task, so that the output sequence is also a, then\n",
    "# the output written on the tape will be (notice the alignment)\n",
    "#\n",
    "# [9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9]\n",
    "#\n",
    "\n",
    "def io_generator(max_symbol, input_length, total_length):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded pair of input and output sequence, with terminal and initial symbols.\n",
    "    \n",
    "    max_symbol - generate sequences in 0,...,max_symbol\n",
    "    input_length - length of input sequences, without initial and terminal symbols\n",
    "    total_length - length of the buffer, so that the sequences are padded to this length\n",
    "    \"\"\"\n",
    "    a = generate_input_seq(max_symbol,input_length)\n",
    "    fa = func_to_learn(a)\n",
    "    a = [init_symbol] + a + [term_symbol]\n",
    "    a = a + [term_symbol for k in range(total_length-len(a))]\n",
    "    a_onehot = [one_hots[e] for e in a]\n",
    "    \n",
    "    # If the output is too long to fit in the buffer, truncate it\n",
    "    if( len(fa) + input_length + 1 > total_length ):\n",
    "        fa = fa[:total_length-input_length-1]\n",
    "        \n",
    "    fa = [term_symbol for k in range(input_length+1)] + fa + \\\n",
    "                [term_symbol for k in range(total_length-(input_length+1)-len(fa))]\n",
    "    fa_onehot = [one_hots[e] for e in fa]\n",
    "    \n",
    "    return a, fa, np.array(a_onehot), np.array(fa_onehot)\n",
    "\n",
    "error_means = []\n",
    "epoch_error_means = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences. Each\n",
    "        # batch has a fixed length of the sequences. Recall that all input seqs\n",
    "        # have an initial and terminal symbol, so if seq_length = 10 then there\n",
    "        # are eight positions for the \"content\" symbols\n",
    "        \n",
    "        # Our version of curriculum training says: spend the first half\n",
    "        # of the epochs ramping up to the full training set. Assuming that\n",
    "        # epoch > N we divide allocate each integer in [seq_length_min,N]\n",
    "        # an equal portion of the first half of the epochs.\n",
    "        if( use_curriculum == True ):\n",
    "            if( 2 * i > epoch ):\n",
    "                seq_length_max = N\n",
    "            else:\n",
    "                curriculum_band = max(1,int(epoch/(2*(N - seq_length_min))))\n",
    "                seq_length_max = min(seq_length_min + int(i/curriculum_band),N)\n",
    "        else:\n",
    "            seq_length_max = N\n",
    "            \n",
    "        seq_length = random.randint(seq_length_min,seq_length_max)\n",
    "        \n",
    "        # Hack: if we are on the final batch of the final epoch, force\n",
    "        # it to use the full sequence length, so we get a good visualisation\n",
    "        if( i + 1 == epoch and j + 1 == no_of_batches ):\n",
    "            seq_length = N\n",
    "        \n",
    "        for z in range(batch_size):\n",
    "            a, fa, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=N+N_out)\n",
    "            \n",
    "            inp.append(a_onehot)\n",
    "            out.append(fa_onehot)\n",
    "            \n",
    "            # Record the first sequence in the last batch of the last epoch\n",
    "            if( i == epoch - 1 and j == no_of_batches - 1 and z == 0):\n",
    "                final_seq = a\n",
    "                final_seq_output = fa\n",
    "        \n",
    "        # An annoying thing here is that we cannot use a list as a key in a \n",
    "        # dictionary. The workaround we found on StackOverflow here:\n",
    "        # http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "        feed_dict = {}\n",
    "        \n",
    "        for d in range(N + N_out):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N + N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "\n",
    "        ##### Do gradient descent #####\n",
    "        mean_error_val,_ = sess.run([mean_error,minimize], feed_dict)\n",
    "        ###############################\n",
    "        \n",
    "        error_means.append(mean_error_val)\n",
    "    \n",
    "    epoch_error = np.mean(error_means[-no_of_batches:])\n",
    "    epoch_error_means.append(epoch_error)\n",
    "    \n",
    "    # Print the mean error of the final batch in the epoch\n",
    "    print_str = \"Epoch - \" + str(i+1) + \", mean error - \" + str(epoch_error)\n",
    "    \n",
    "    if( use_curriculum == True ):\n",
    "        print_str = print_str + \", training at max length - \" + str(seq_length_max)\n",
    "        \n",
    "    print(print_str)\n",
    "\n",
    "# For the final batch of the final epoch, we record the memory states as well\n",
    "seq_length_for_vis = seq_length - 2\n",
    "interps_val = sess.run(interps,feed_dict)\n",
    "m2_val, m3_val, m4_val = sess.run([m2,m3,m4],feed_dict)            \n",
    "r1_val, w1_val = sess.run([read_addresses,write_addresses],feed_dict)\n",
    "r2_val, w2_val = sess.run([read_addresses2,write_addresses2],feed_dict)\n",
    "r3_val, w3_val = sess.run([read_addresses3,write_addresses3],feed_dict)\n",
    "r4_val, w4_val = sess.run([read_addresses4,write_addresses4],feed_dict)\n",
    "errors_mask_val = sess.run(errors_mask,feed_dict)\n",
    "\n",
    "mask_val = sess.run(tf.cast(mask,tf.int64),feed_dict)\n",
    "predicted_seq = [tf.argmax(prediction[i], 1) for i in range(N + N_out)]\n",
    "predicted_seq_val = sess.run(predicted_seq,feed_dict)\n",
    "final_seq_pred_0 = [a[0] for a in predicted_seq_val]\n",
    "final_seq_pred = []\n",
    "\n",
    "for i in range(len(mask_val)):\n",
    "    if( mask_val[i] == 1.0 ):\n",
    "        final_seq_pred.append(final_seq_pred_0[i])\n",
    "    else:\n",
    "        final_seq_pred.append(9)\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took \" + str(int(time.time() - pre_train_time)) + \" seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length used for visualisations - 18\n",
      "\n",
      "Sequence used for visualisations is (Note: initial symbol is 8, terminal symbol is 9)\n",
      "[8, 1, 0, 2, 1, 0, 1, 0, 0, 8, 7, 3, 2, 2, 3, 1, 3, 4, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Correct output for this sequence:\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 3, 3, 2, 3, 3, 1, 1, 1, 3, 3, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Predicted output for this sequence\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Mask for output\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Error probabilities for final batch\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99599999, 0.97600001, 0.93599999, 0.796, 0.708, 0.57999998, 0.48800001, 0.44, 0.36399999, 0.31600001, 0.244, 0.176, 0.14399999, 0.13600001, 0.12, 0.108, 0.088, 0.079999998, 0.079999998, 0.071999997, 0.064000003, 0.059999999, 0.059999999, 0.059999999, 0.056000002, 0.035999998, 0.035999998, 0.032000002, 0.028000001, 0.028000001, 0.024, 0.024]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAQPCAYAAABGG5mEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPTqH8APMmN2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a65c210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 1 #\n",
    "###########################\n",
    "\n",
    "print(\"Sequence length used for visualisations - \" + str(seq_length_for_vis))\n",
    "print(\"\")\n",
    "print(\"Sequence used for visualisations is (Note: initial symbol is \" + str(init_symbol) + \", terminal symbol is \" + str(term_symbol) + \")\")\n",
    "print(final_seq)\n",
    "print(\"\")\n",
    "print(\"Correct output for this sequence:\")\n",
    "print(final_seq_output)\n",
    "print(\"\")\n",
    "print(\"Predicted output for this sequence\")\n",
    "print(final_seq_pred)\n",
    "print(\"\")\n",
    "print(\"Mask for output\")\n",
    "print(mask_val)\n",
    "print(\"\")\n",
    "print(\"Error probabilities for final batch\")\n",
    "print(errors_mask_val)\n",
    "print(\"\")\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 9, 13\n",
    "fig_num = 0\n",
    "\n",
    "# RING 1\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "plt.figure(fig_num)\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "ax1.imshow(np.stack(w1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax1.set_title('Write address (ring 1)')\n",
    "ax1.set_xlabel('position')\n",
    "ax1.set_ylabel('time')\n",
    "\n",
    "ax2.imshow(np.stack(r1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax2.set_title('Read address (ring 1)')\n",
    "ax2.set_xlabel('position')\n",
    "ax2.set_ylabel('time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 2 #\n",
    "###########################\n",
    "\n",
    "if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 2)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 2)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Assume that powers2_on_1 has three entries we can use as colour channels\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 2)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    max_xticks = 2\n",
    "    xloc = plt.MaxNLocator(max_xticks)\n",
    "\n",
    "    ax.imshow(np.stack(interps_val), cmap='bone', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title('Interpolation')\n",
    "    ax.set_xlabel('direct vs indirect')\n",
    "    ax.set_ylabel('time')\n",
    "    ax.xaxis.set_major_locator(xloc)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# VISUALISATIONS - OTHER RINGS #\n",
    "################################\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 3)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 3)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 3)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 4)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 4)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax6 = plt.subplot(1,1,1)    \n",
    "    ax6.imshow(np.stack(m4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax6.set_title('Memory contents (ring 4)')\n",
    "    ax6.set_xlabel('position')\n",
    "    ax6.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAUKCAYAAABblriAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a6bd110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# VISUALISATIONS - ERROR #\n",
    "##########################\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "\n",
    "plt.figure(fig_num)\n",
    "ax = plt.subplot(1,1,1)\n",
    "sc = pandas.Series(error_means)\n",
    "ma = sc.rolling(window=500).mean()\n",
    "ax.plot(sc.index, sc, color='lightgray')\n",
    "ax.plot(ma.index, ma, color='red')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(sc.index.min(), sc.index.max())\n",
    "ax.set_title('Error')\n",
    "ax.set_xlabel('batch')\n",
    "ax.set_ylabel('error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on sequences of length 23\n",
      "\n",
      "Batch - 1, Mean error - 0.412255\n",
      "Batch - 2, Mean error - 0.392936\n",
      "Batch - 3, Mean error - 0.396426\n",
      "Batch - 4, Mean error - 0.417447\n",
      "\n",
      "###########\n",
      "# Summary #\n",
      "###########\n",
      "\n",
      "model         - ntm\n",
      "task name     - variable pattern 3\n",
      "epochs        - 2\n",
      "num_classes   - 10\n",
      "N             - 20\n",
      "Ntest         - 25\n",
      "# weights     - 18958\n",
      "\n",
      "\n",
      "error train(test) - 0.366811 (0.404766)\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "# Set up test graph\n",
    "rnn_outputs_test = []\n",
    "reuse = True\n",
    "for i in range(Ntest + Ntest_out):\n",
    "    output, state = cell(inputs_test[i],state,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "\n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size])\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.log_softmax(logit) for logit in logits_test] \n",
    "term_detector = [tf.not_equal(tf.argmax(targets_test[i],1),term_symbol) for i in range(Ntest + Ntest_out)]\n",
    "mask = [tf.reduce_max(tf.cast(m, tf.float32)) for m in term_detector]\n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest + Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "errors_test_mask = [errors_test[i] * mask[i] for i in range(Ntest + Ntest_out)]\n",
    "mean_error_test = tf.add_n(errors_test_mask)\n",
    "mean_error_test /= tf.add_n(mask)\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "\n",
    "seq_length = Ntest\n",
    "print(\"Testing on sequences of length \" + str(seq_length-2))\n",
    "print(\"\")\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    for z in range(batch_size):\n",
    "        a, fa, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=Ntest+Ntest_out)\n",
    "            \n",
    "        inp.append(a_onehot)\n",
    "        out.append(fa_onehot)        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = sess.run(mean_error_test, feed_dict)\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"epochs        - \" + str(epoch))\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"error train(test) - \" + str(epoch_error_means[-1]) + \" (\" + str(final_error) + \")\")\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
