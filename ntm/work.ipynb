{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of linear logic recurrent neural network\n",
    "#\n",
    "# The architecture is a modified RNN, see the paper \"Linear logic and recurrent neural networks\".\n",
    "# Our inputs are sequences of symbols taken from an alphabet of size num_classes. The length\n",
    "# of the sequences is N. Our outputs are also sequences of length N from the same alphabet.\n",
    "#\n",
    "# Here \"symbol\" means a one hot vector.\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# GLOBAL FLAGS\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, pattern_ntm_alt\n",
    "task                  = 'copy' # copy, repeat copy, pattern\n",
    "epoch                 = 100 # number of training epochs, default to 200\n",
    "num_classes           = 258 # number of symbols, INCLUDING initial and terminal symbols\n",
    "N                     = 5 # length of input sequences for training, default to 20, INCLUDING initial and terminal symbols\n",
    "Ntest                 = 5 # length of sequences for testing, default to N, INCLUDING initial and terminal symbols\n",
    "batch_size            = 500 # default to 500 (too large does not fit on GPUs)\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "memory_address_size   = 128 # number of memory locations, default 20\n",
    "memory_content_size   = 20 # size of vector stored at a memory location, default 5\n",
    "powers_ring1          = [0,-1,1] # powers of R used on ring 1, default [0,-1,1]\n",
    "powers_ring2          = [0,-1,1] # powers of R used on ring 2, default [0,-1,1]\n",
    "model_optimizer       = 'rmsprop' # adam, rmsprop, default to rmsprop\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "\n",
    "training_percent      = 0.01 # percentage used for training, default 0.01\n",
    "num_training          = 10000 #int(training_percent * (num_classes-2)**N)\n",
    "num_test              = num_training\n",
    "\n",
    "init_symbol           = num_classes - 2\n",
    "term_symbol           = num_classes - 1\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[38, 70, 79, 39, 98]\n",
      "is mapped to\n",
      "[38, 70, 79, 39, 98]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "if( task == 'repeat copy' ):\n",
    "    pattern = [0,1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "##############\n",
    "# PATTERN TASK\n",
    "if( task == 'pattern' ):\n",
    "    pattern = [1,0,0,2,0]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = [random.randint(0,num_classes-3) for i in range(N)]\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "state_size = 0\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size = controller_state_size + 2*memory_address_size + memory_address_size * memory_content_size\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,memory_address_size,memory_content_size, powers_ring1)\n",
    "    \n",
    "    ra = [0.0]*memory_address_size\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,memory_address_size]) + ra\n",
    "    \n",
    "    # DEBUG at the moment the read and write addresses are not distributions, i.e. they do not\n",
    "    # sum to 1, but after one step the gamma sharpening will normalise them. We should probably start\n",
    "    # with things that sum to 1, though.\n",
    "    #init_controller_state = tf.truncated_normal([batch_size, controller_state_size], 0.0, 1e-6, dtype=tf.float32)\n",
    "    init_controller_state = tf.get_variable(\"init_ccs\", shape=[batch_size, controller_state_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    init_read_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size]) + \\\n",
    "                       tf.random_uniform([batch_size, memory_address_size], 0.0, 1e-6)\n",
    "    \n",
    "    init_write_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size]) + \\\n",
    "                       tf.random_uniform([batch_size, memory_address_size], 0.0, 1e-6)\n",
    "    \n",
    "    #init_memory = tf.truncated_normal([batch_size, memory_address_size*memory_content_size], 0.0, 1e-6, dtype=tf.float32)\n",
    "    init_memory = tf.get_variable(\"init_mem\", shape=[batch_size, memory_address_size*memory_content_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    \n",
    "#############\n",
    "# PATTERN NTM\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n",
    "    \n",
    "#################\n",
    "# PATTERN NTM ALT\n",
    "if( use_model == 'pattern_ntm_alt' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM_alt(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_11/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM/split_grad/concat:0' shape=(500, 2916) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "# inputs, we create N of them, each of shape [None,input_size], one for each position in the sequence\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "write_addresses = []\n",
    "gamma_writes = []\n",
    "gamma_reads = []\n",
    "ss = []\n",
    "\n",
    "for i in range(N):\n",
    "    # Store read and write addresses for later logging\n",
    "    h0, curr_read, curr_write, _ = tf.split(state, [controller_state_size,memory_address_size,memory_address_size,-1], 1)\n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    \n",
    "    # DEBUG, getting gammas\n",
    "    with tf.variable_scope(\"NTM\",reuse=True):\n",
    "        W_gamma_write = tf.get_variable(\"W_gamma_write\", [controller_state_size,1])\n",
    "        B_gamma_write = tf.get_variable(\"B_gamma_write\", [])\n",
    "        gamma_write = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_write) + B_gamma_write) # shape [batch_size,1]\n",
    "        \n",
    "        W_gamma_read = tf.get_variable(\"W_gamma_read\", [controller_state_size,1])\n",
    "        B_gamma_read = tf.get_variable(\"B_gamma_read\", [])\n",
    "        gamma_read = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_read) + B_gamma_read) # shape [batch_size,1]\n",
    "        \n",
    "        W_s = tf.get_variable(\"W_s\", [controller_state_size,len(powers_ring1)])\n",
    "        B_s = tf.get_variable(\"B_s\", [len(powers_ring1)])\n",
    "        s = tf.nn.softmax(tf.matmul(h0,W_s) + B_s) # shape [batch_size,len(powers)]\n",
    "\n",
    "    gamma_writes.append(gamma_write[0,:])\n",
    "    gamma_reads.append(gamma_read[0,:])\n",
    "    ss.append(s[0,:])\n",
    "    reuse = True\n",
    "\n",
    "# We only start recording the outputs of the controller once we have\n",
    "# finished feeding in the input. We feed terminal symbols as input in the second phase.\n",
    "\n",
    "term_symbol_tensor = tf.constant(np.zeros([batch_size,input_size]) + one_hots[term_symbol],\n",
    "                                 dtype=tf.float32,\n",
    "                                 shape=[batch_size,input_size])\n",
    "\n",
    "rnn_outputs = []\n",
    "for i in range(N_out):\n",
    "    output, state = cell(term_symbol_tensor,state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * tf.log(prediction[i])) for i in range(N_out)]\n",
    "\n",
    "if( model_optimizer == 'adam' ):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "elif( model_optimizer == 'rmsprop' ):\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-4,decay=0.9,momentum=0.9)\n",
    "\n",
    "cross_entropy = -tf.add_n(ce)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "mean_error = tf.scalar_mul(np.true_divide(1,N_out), tf.add_n(errors))\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.00698602]\n",
      "Write gamma - [ 1.05843496]\n",
      "w rotations - Tensor(\"strided_slice_4:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  1.00000083e+00   4.93420032e-07   8.95133496e-07   4.53636517e-07\n",
      "   4.85791418e-07   3.94982919e-07   3.72701869e-08   9.41893916e-07\n",
      "   7.32072010e-07   7.77888332e-08   9.57948828e-07   7.39212069e-08\n",
      "   9.36388517e-07   1.90272331e-08   3.88757343e-07   3.78291247e-07\n",
      "   5.75491299e-07   2.52853283e-07   6.97456585e-07   1.83493853e-07\n",
      "   9.47199453e-07   1.95515639e-07   3.61806144e-07   4.69858406e-07\n",
      "   3.97007476e-08   4.17454714e-07   8.50836898e-07   5.69133874e-07\n",
      "   1.08551504e-07   2.27541562e-07   4.98758084e-07   6.82631594e-07\n",
      "   6.15029080e-07   2.54361140e-07   6.29777333e-07   7.30479940e-07\n",
      "   5.42288433e-07   4.84526161e-08   8.57653959e-07   4.74545345e-07\n",
      "   8.85605687e-07   2.90829433e-07   1.20867014e-07   2.96695816e-07\n",
      "   9.38649634e-07   1.32296677e-07   7.82196310e-07   2.29629876e-07\n",
      "   5.19875869e-07   4.70716230e-07   9.31260615e-08   2.16178890e-07\n",
      "   5.85593227e-07   8.46160049e-07   5.90758304e-07   2.48073093e-07\n",
      "   8.48787636e-07   9.74254817e-07   8.51280447e-07   3.97824181e-07\n",
      "   1.36478306e-07   4.23842181e-07   4.16136260e-07   1.16436482e-07\n",
      "   7.37064852e-07   1.49590846e-07   7.08688390e-07   7.12023848e-07\n",
      "   9.21357412e-07   9.73926788e-08   9.21632306e-07   9.21810283e-07\n",
      "   8.03673174e-07   2.32272740e-07   1.08227489e-07   7.23517871e-07\n",
      "   2.71174201e-07   8.38561164e-07   1.83040143e-07   7.46142121e-07\n",
      "   3.48257885e-07   6.13297345e-07   4.86704607e-07   2.97935259e-07\n",
      "   2.53021715e-09   5.10821224e-07   2.38548864e-07   5.41344889e-08\n",
      "   5.48470496e-07   3.65980156e-07   8.23906305e-07   2.51026151e-08\n",
      "   8.33736522e-07   9.22734273e-07   6.97349890e-07   2.21254822e-07\n",
      "   3.71806266e-07   7.91192056e-10   2.85915149e-07   3.58799809e-07\n",
      "   5.53745394e-07   8.00594819e-07   5.66326491e-07   6.64738877e-07\n",
      "   3.87362718e-07   6.58003216e-07   5.91089737e-08   6.96917652e-07\n",
      "   7.74755620e-07   7.03414798e-07   2.19918959e-07   7.85320537e-07\n",
      "   3.31755984e-07   8.09465860e-07   1.01200222e-07   3.92496702e-07\n",
      "   9.97161578e-07   7.07306754e-07   8.09251333e-07   7.98767928e-07\n",
      "   6.34610657e-08   8.75190835e-07   2.76328933e-07   7.41926556e-07\n",
      "   7.42872260e-07   4.64006888e-07   8.98468500e-08   9.17018781e-07]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_9:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.13273698e-01   2.96415329e-01   7.84064525e-07   7.80702635e-07\n",
      "   6.99848783e-07   6.19205821e-07   7.27173529e-07   7.76987008e-07\n",
      "   7.51575499e-07   7.88907698e-07   6.54721987e-07   8.18877709e-07\n",
      "   6.39786947e-07   6.97221139e-07   6.14460532e-07   7.08429297e-07\n",
      "   6.74539706e-07   7.41128190e-07   6.61246816e-07   7.98613769e-07\n",
      "   6.93312018e-07   7.22068535e-07   6.55178326e-07   6.12815995e-07\n",
      "   6.34865103e-07   7.15989984e-07   7.88252237e-07   7.17292949e-07\n",
      "   6.23512676e-07   6.26022370e-07   7.24504332e-07   7.82629002e-07\n",
      "   7.27931138e-07   7.33953300e-07   7.59431202e-07   7.96084407e-07\n",
      "   6.82530754e-07   7.34841819e-07   7.13633085e-07   8.58546230e-07\n",
      "   7.47056561e-07   6.80090238e-07   5.96764664e-07   7.26408132e-07\n",
      "   6.96720235e-07   7.94487903e-07   6.65614493e-07   7.33739000e-07\n",
      "   6.86063800e-07   6.47633442e-07   6.03801880e-07   6.39021039e-07\n",
      "   7.69492601e-07   8.17819057e-07   7.47904835e-07   7.72941405e-07\n",
      "   8.42988243e-07   9.32133446e-07   8.40103553e-07   6.95211725e-07\n",
      "   6.40698829e-07   6.45500791e-07   6.28809062e-07   7.02439365e-07\n",
      "   6.40060421e-07   7.51496032e-07   7.52411836e-07   8.81467770e-07\n",
      "   7.50803792e-07   8.14081659e-07   8.21003312e-07   9.25254085e-07\n",
      "   7.91013235e-07   6.55602037e-07   6.70242059e-07   6.60714988e-07\n",
      "   7.95149447e-07   6.86725457e-07   7.80068603e-07   6.91127354e-07\n",
      "   7.66093251e-07   7.22560685e-07   7.05187290e-07   5.96919620e-07\n",
      "   6.21134859e-07   6.03942681e-07   6.01248303e-07   6.27813506e-07\n",
      "   6.43047485e-07   7.80608218e-07   6.67517099e-07   7.69655628e-07\n",
      "   7.95685821e-07   8.90266790e-07   7.71657483e-07   6.89869410e-07\n",
      "   5.68081816e-07   5.87716386e-07   5.91350499e-07   6.85178861e-07\n",
      "   7.77203809e-07   8.00568330e-07   8.20307662e-07   7.44628892e-07\n",
      "   7.68833104e-07   6.50798484e-07   7.22313700e-07   7.49093431e-07\n",
      "   8.46036187e-07   7.49566709e-07   7.73049123e-07   6.99833322e-07\n",
      "   8.08739003e-07   6.75053229e-07   6.91777927e-07   7.50589948e-07\n",
      "   8.35955973e-07   9.02948841e-07   8.72474175e-07   7.39112750e-07\n",
      "   7.80306493e-07   6.79346783e-07   8.00064583e-07   7.83526446e-07\n",
      "   7.99747681e-07   6.80015773e-07   7.41352210e-07   3.90220076e-01]\n",
      "Argmax - 127\n",
      "\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_14:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.34421605e-01   2.20793635e-01   9.94177088e-02   1.75944251e-06\n",
      "   1.70464716e-06   1.67563678e-06   1.70439318e-06   1.75308776e-06\n",
      "   1.77010600e-06   1.73938099e-06   1.74450577e-06   1.71450404e-06\n",
      "   1.71538431e-06   1.65505833e-06   1.66776556e-06   1.66740574e-06\n",
      "   1.70394173e-06   1.69667862e-06   1.72547436e-06   1.72345108e-06\n",
      "   1.73629439e-06   1.69387044e-06   1.66579071e-06   1.63286063e-06\n",
      "   1.64949461e-06   1.70836643e-06   1.74433899e-06   1.71516990e-06\n",
      "   1.65544611e-06   1.65196366e-06   1.70718351e-06   1.74791489e-06\n",
      "   1.74770582e-06   1.73869432e-06   1.76070637e-06   1.75243929e-06\n",
      "   1.73473768e-06   1.71126214e-06   1.76024366e-06   1.77914899e-06\n",
      "   1.76587230e-06   1.67949815e-06   1.66003895e-06   1.67456869e-06\n",
      "   1.73325554e-06   1.72614682e-06   1.72729585e-06   1.69760199e-06\n",
      "   1.69130533e-06   1.64829885e-06   1.62795016e-06   1.66275743e-06\n",
      "   1.73875151e-06   1.78221637e-06   1.77799188e-06   1.78351513e-06\n",
      "   1.84369117e-06   1.87676437e-06   1.83102361e-06   1.72865020e-06\n",
      "   1.66008817e-06   1.63910477e-06   1.65437893e-06   1.66042992e-06\n",
      "   1.69131340e-06   1.71414786e-06   1.78725088e-06   1.80213078e-06\n",
      "   1.81174642e-06   1.79452343e-06   1.84702094e-06   1.85325075e-06\n",
      "   1.79869517e-06   1.70481871e-06   1.66250697e-06   1.70054250e-06\n",
      "   1.72011505e-06   1.74845718e-06   1.72415753e-06   1.74128741e-06\n",
      "   1.72879288e-06   1.73217916e-06   1.68112285e-06   1.63966422e-06\n",
      "   1.60809384e-06   1.60876505e-06   1.60922787e-06   1.62287051e-06\n",
      "   1.67542930e-06   1.70324802e-06   1.73322724e-06   1.74230649e-06\n",
      "   1.81264761e-06   1.82579538e-06   1.78879588e-06   1.68370582e-06\n",
      "   1.61410935e-06   1.58192370e-06   1.61564367e-06   1.67871497e-06\n",
      "   1.75251512e-06   1.79791141e-06   1.79271262e-06   1.77642141e-06\n",
      "   1.72813873e-06   1.70977580e-06   1.70544683e-06   1.76645710e-06\n",
      "   1.78684627e-06   1.78813389e-06   1.74487991e-06   1.75401999e-06\n",
      "   1.73534158e-06   1.72426007e-06   1.70207068e-06   1.75403704e-06\n",
      "   1.82545045e-06   1.87188391e-06   1.84590476e-06   1.79490905e-06\n",
      "   1.73859212e-06   1.74607862e-06   1.75481341e-06   1.79329072e-06\n",
      "   1.76126161e-06   1.73676881e-06   1.06949948e-01   2.38204688e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.15460467]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_19:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  2.70745218e-01   2.28770003e-01   1.15899459e-01   3.49064320e-02\n",
      "   2.71591762e-06   2.69303519e-06   2.70674536e-06   2.74011109e-06\n",
      "   2.75570460e-06   2.75116463e-06   2.73447313e-06   2.72492161e-06\n",
      "   2.69887846e-06   2.67923724e-06   2.66286861e-06   2.67679070e-06\n",
      "   2.68886038e-06   2.70644955e-06   2.71448471e-06   2.72718785e-06\n",
      "   2.72028933e-06   2.70104329e-06   2.66665643e-06   2.64845562e-06\n",
      "   2.65878384e-06   2.69680231e-06   2.72369493e-06   2.70937221e-06\n",
      "   2.67515998e-06   2.66735560e-06   2.69815223e-06   2.73320848e-06\n",
      "   2.74506033e-06   2.74729155e-06   2.75045340e-06   2.75033926e-06\n",
      "   2.73443516e-06   2.73202681e-06   2.74766126e-06   2.76866785e-06\n",
      "   2.74748663e-06   2.70436794e-06   2.67034829e-06   2.68454482e-06\n",
      "   2.71043450e-06   2.72859597e-06   2.71874205e-06   2.70602800e-06\n",
      "   2.68187273e-06   2.65771314e-06   2.64390360e-06   2.67016298e-06\n",
      "   2.72314060e-06   2.76549099e-06   2.78057109e-06   2.79703045e-06\n",
      "   2.83089025e-06   2.85276769e-06   2.81982352e-06   2.74622994e-06\n",
      "   2.67830660e-06   2.65014774e-06   2.65026665e-06   2.66607958e-06\n",
      "   2.68612598e-06   2.72499074e-06   2.76513856e-06   2.79907476e-06\n",
      "   2.80348604e-06   2.81400571e-06   2.82986275e-06   2.83636518e-06\n",
      "   2.79282654e-06   2.72631496e-06   2.68701501e-06   2.69198586e-06\n",
      "   2.72034208e-06   2.73177125e-06   2.73684145e-06   2.73164028e-06\n",
      "   2.73372052e-06   2.71722683e-06   2.68781264e-06   2.64558776e-06\n",
      "   2.61902096e-06   2.60831757e-06   2.61231639e-06   2.63155448e-06\n",
      "   2.66394341e-06   2.70101236e-06   2.72473812e-06   2.75724938e-06\n",
      "   2.79104643e-06   2.81109715e-06   2.77381855e-06   2.70197302e-06\n",
      "   2.62975345e-06   2.60175329e-06   2.62004164e-06   2.67561882e-06\n",
      "   2.73818023e-06   2.78024959e-06   2.78990069e-06   2.76910077e-06\n",
      "   2.73991691e-06   2.71473891e-06   2.72265061e-06   2.75004049e-06\n",
      "   2.77967001e-06   2.77596109e-06   2.76211676e-06   2.74555146e-06\n",
      "   2.73863839e-06   2.72197258e-06   2.72316902e-06   2.75420325e-06\n",
      "   2.81221651e-06   2.84838893e-06   2.84126349e-06   2.79765936e-06\n",
      "   2.75998104e-06   2.74539411e-06   2.76150399e-06   2.77100958e-06\n",
      "   2.76571882e-06   2.81018298e-02   1.03874370e-01   2.17372939e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.10977864]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_24:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  2.41987497e-01   2.00293735e-01   1.17238037e-01   4.39953394e-02\n",
      "   9.18450393e-03   3.70337762e-06   3.71433748e-06   3.73631110e-06\n",
      "   3.74953356e-06   3.74603837e-06   3.73504349e-06   3.71784540e-06\n",
      "   3.69838335e-06   3.67820553e-06   3.67157577e-06   3.67688062e-06\n",
      "   3.69136706e-06   3.70415910e-06   3.71633973e-06   3.72095542e-06\n",
      "   3.71489386e-06   3.69360077e-06   3.66886388e-06   3.65638903e-06\n",
      "   3.66889935e-06   3.69573695e-06   3.71113310e-06   3.70069483e-06\n",
      "   3.68095766e-06   3.67971279e-06   3.70184262e-06   3.72765567e-06\n",
      "   3.74224396e-06   3.74733099e-06   3.74910110e-06   3.74432466e-06\n",
      "   3.73729745e-06   3.73765192e-06   3.75041782e-06   3.75524905e-06\n",
      "   3.73749253e-06   3.70333305e-06   3.68379324e-06   3.68939641e-06\n",
      "   3.70950306e-06   3.71989358e-06   3.71640931e-06   3.70044654e-06\n",
      "   3.67930215e-06   3.65876804e-06   3.65625579e-06   3.68132055e-06\n",
      "   3.72354521e-06   3.75914510e-06   3.78187860e-06   3.80406073e-06\n",
      "   3.82914732e-06   3.83499355e-06   3.80225197e-06   3.74134402e-06\n",
      "   3.68584983e-06   3.65712845e-06   3.65530013e-06   3.66846371e-06\n",
      "   3.69397776e-06   3.72833688e-06   3.76596859e-06   3.79120479e-06\n",
      "   3.80551887e-06   3.81629798e-06   3.82747567e-06   3.81893096e-06\n",
      "   3.78052277e-06   3.72958266e-06   3.69861868e-06   3.70012617e-06\n",
      "   3.71640522e-06   3.73006060e-06   3.73320927e-06   3.73325793e-06\n",
      "   3.72692443e-06   3.71079818e-06   3.68030442e-06   3.64693256e-06\n",
      "   3.62180049e-06   3.61206958e-06   3.61753223e-06   3.63736081e-06\n",
      "   3.66792369e-06   3.69908844e-06   3.72939485e-06   3.76004095e-06\n",
      "   3.78868594e-06   3.79229255e-06   3.75800482e-06   3.69512941e-06\n",
      "   3.63848835e-06   3.61505522e-06   3.63421168e-06   3.68241695e-06\n",
      "   3.73596367e-06   3.77207607e-06   3.77959941e-06   3.76387857e-06\n",
      "   3.73830540e-06   3.72365344e-06   3.72967497e-06   3.75272180e-06\n",
      "   3.77009451e-06   3.77160904e-06   3.75948071e-06   3.74701040e-06\n",
      "   3.73414673e-06   3.72629802e-06   3.73323473e-06   3.76585604e-06\n",
      "   3.80912411e-06   3.83588849e-06   3.82739017e-06   3.79545986e-06\n",
      "   3.76430626e-06   3.75438731e-06   3.76011053e-06   3.76617504e-06\n",
      "   9.83447861e-03   4.72179838e-02   1.23639949e-01   2.06165105e-01]\n",
      "Argmax - 0\n",
      "\n",
      "Epoch - 1, Mean error of final batch in epoch - 0.956667\n",
      "Epoch - 2, Mean error of final batch in epoch - 0.849333\n",
      "Epoch - 3, Mean error of final batch in epoch - 0.713333\n",
      "Epoch - 4, Mean error of final batch in epoch - 0.644\n",
      "Epoch - 5, Mean error of final batch in epoch - 0.557333\n",
      "Epoch - 6, Mean error of final batch in epoch - 0.493333\n",
      "Epoch - 7, Mean error of final batch in epoch - 0.474\n",
      "Epoch - 8, Mean error of final batch in epoch - 0.44\n",
      "Epoch - 9, Mean error of final batch in epoch - 0.381333\n",
      "Epoch - 10, Mean error of final batch in epoch - 0.346667\n",
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.21465564]\n",
      "Write gamma - [ 1.21845078]\n",
      "w rotations - Tensor(\"strided_slice_4:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  1.00000072e+00   8.28144323e-07   2.09788325e-07   3.49200491e-07\n",
      "   8.56294378e-07   3.23652039e-08   6.61153820e-07   4.79700304e-07\n",
      "   5.90048671e-07   2.50552404e-07   9.05084846e-07   7.87262650e-07\n",
      "   2.31881614e-07   6.83069800e-07   6.47931472e-07   4.77749609e-07\n",
      "   3.28181756e-07   9.03208729e-07   4.65734011e-08   5.58891202e-07\n",
      "   1.11223457e-08   7.52887743e-08   1.98332188e-07   1.75108312e-07\n",
      "   5.99811813e-07   8.69087671e-07   3.82153971e-08   2.89119953e-07\n",
      "   1.43806815e-07   3.65967395e-07   8.84506449e-07   8.79913216e-07\n",
      "   5.57429800e-08   7.60477803e-07   8.58622172e-07   4.80933181e-07\n",
      "   9.29185148e-07   8.63563173e-07   3.50087646e-07   6.42651912e-07\n",
      "   8.04635022e-07   8.33415982e-07   1.55964727e-07   4.15676823e-07\n",
      "   2.63500340e-07   5.37537339e-08   5.36914797e-07   6.46315698e-07\n",
      "   5.04477157e-07   3.50238565e-07   4.04192207e-07   3.34290633e-07\n",
      "   5.11258577e-07   9.40092548e-07   9.95337814e-07   1.43407945e-07\n",
      "   9.55928726e-07   2.76021353e-07   8.21085337e-07   8.41086887e-07\n",
      "   2.22057224e-07   4.69399566e-07   7.75810577e-07   2.16984148e-07\n",
      "   7.69082078e-07   6.54164694e-07   8.50733045e-07   3.57757216e-07\n",
      "   7.03285934e-07   4.99178782e-07   6.83499707e-07   4.03358683e-07\n",
      "   1.26196142e-07   6.76969421e-07   8.97931557e-07   1.33981473e-07\n",
      "   8.61831211e-07   3.41875904e-07   8.87502551e-07   9.19244883e-07\n",
      "   4.48606841e-07   4.37281500e-07   1.43176194e-07   1.15809918e-07\n",
      "   8.49513981e-07   1.37912394e-07   8.66954295e-08   4.60929755e-07\n",
      "   8.11508755e-07   8.28108782e-08   3.79489052e-07   5.63481933e-07\n",
      "   8.67265442e-08   3.55738507e-07   5.15863633e-07   1.50467272e-07\n",
      "   7.25840209e-07   9.50583569e-07   8.14274188e-07   5.17352809e-08\n",
      "   7.98738597e-07   3.67862953e-07   7.30275417e-07   2.48773347e-07\n",
      "   8.48751426e-07   1.83844562e-09   9.15832970e-07   8.41397991e-07\n",
      "   1.71622872e-07   2.38786214e-07   6.06039407e-07   3.35954070e-07\n",
      "   9.91061825e-07   3.99327632e-07   5.34062849e-07   6.35041260e-07\n",
      "   1.79061288e-07   5.85611247e-07   4.85685348e-07   6.82375799e-07\n",
      "   2.59456868e-07   6.40292171e-07   3.37797417e-08   4.34813387e-07\n",
      "   1.10859872e-07   8.44828833e-07   6.76267859e-07   6.85042608e-07]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_9:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.65652978e-01   2.73225784e-01   9.63582920e-08   1.00929761e-07\n",
      "   9.50584536e-08   1.00900387e-07   9.50050278e-08   1.07573939e-07\n",
      "   9.66025979e-08   1.08376611e-07   1.16574782e-07   1.11950406e-07\n",
      "   1.05879472e-07   1.05255175e-07   1.09812056e-07   9.94692257e-08\n",
      "   1.07996328e-07   9.63660298e-08   9.94146205e-08   7.89573988e-08\n",
      "   7.66629782e-08   6.97825300e-08   7.39922257e-08   8.81004212e-08\n",
      "   1.07983929e-07   1.01441863e-07   9.05326303e-08   7.48535882e-08\n",
      "   8.25856716e-08   1.00714203e-07   1.21532452e-07   1.08994399e-07\n",
      "   1.05083529e-07   1.09680400e-07   1.18156066e-07   1.22548840e-07\n",
      "   1.25197957e-07   1.18408408e-07   1.10037632e-07   1.11506949e-07\n",
      "   1.24362529e-07   1.08687772e-07   9.68336096e-08   8.44702157e-08\n",
      "   8.00220690e-08   8.42792218e-08   9.66981162e-08   1.07096405e-07\n",
      "   1.00872320e-07   9.45949239e-08   9.05966289e-08   9.49201535e-08\n",
      "   1.11211925e-07   1.30318540e-07   1.16448213e-07   1.16319825e-07\n",
      "   1.00339392e-07   1.15348932e-07   1.16249439e-07   1.11283853e-07\n",
      "   1.00541691e-07   1.02423165e-07   1.00876882e-07   1.07716957e-07\n",
      "   1.07668555e-07   1.23321001e-07   1.11663255e-07   1.11777702e-07\n",
      "   1.04420074e-07   1.11951806e-07   1.04321835e-07   9.22187340e-08\n",
      "   9.36072624e-08   1.10008230e-07   1.06951347e-07   1.10879910e-07\n",
      "   9.92619178e-08   1.17101457e-07   1.22238077e-07   1.22099166e-07\n",
      "   1.08202229e-07   8.83104576e-08   7.88297001e-08   9.23060384e-08\n",
      "   9.25348544e-08   8.71619221e-08   8.02366955e-08   1.00053640e-07\n",
      "   9.78023635e-08   9.31240720e-08   9.03519464e-08   8.87722180e-08\n",
      "   8.68701946e-08   8.83809506e-08   8.86785259e-08   9.83542776e-08\n",
      "   1.13642606e-07   1.30325276e-07   1.08464960e-07   1.04550601e-07\n",
      "   9.62450102e-08   1.11653172e-07   9.80908865e-08   1.09969541e-07\n",
      "   9.16356839e-08   1.07342302e-07   1.12578391e-07   1.12039828e-07\n",
      "   9.23362151e-08   8.95178687e-08   9.39809084e-08   1.13911291e-07\n",
      "   1.09577577e-07   1.11310548e-07   1.04359714e-07   9.71049019e-08\n",
      "   9.78702204e-08   9.63550733e-08   1.08713891e-07   9.97320555e-08\n",
      "   1.02969523e-07   8.67410890e-08   8.93579468e-08   7.79511495e-08\n",
      "   9.87789903e-08   1.08091697e-07   1.20792194e-07   3.61108392e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.09185946]\n",
      "Write gamma - [ 1.4980824]\n",
      "w rotations - Tensor(\"strided_slice_14:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.44513655e-01   2.39137650e-01   7.30449855e-02   1.09830387e-06\n",
      "   1.09774442e-06   1.09792984e-06   1.09914413e-06   1.10171231e-06\n",
      "   1.10192752e-06   1.10685028e-06   1.11324550e-06   1.11173870e-06\n",
      "   1.10722658e-06   1.10626070e-06   1.10622727e-06   1.10392750e-06\n",
      "   1.10307349e-06   1.09999053e-06   1.09405914e-06   1.08379481e-06\n",
      "   1.07565882e-06   1.07239032e-06   1.07576363e-06   1.08846586e-06\n",
      "   1.10111944e-06   1.10070346e-06   1.08993743e-06   1.08057054e-06\n",
      "   1.08427901e-06   1.10020426e-06   1.11312670e-06   1.11136319e-06\n",
      "   1.10697624e-06   1.11013230e-06   1.11669181e-06   1.12180055e-06\n",
      "   1.12288546e-06   1.11828012e-06   1.11244935e-06   1.11373674e-06\n",
      "   1.11741065e-06   1.11018687e-06   1.09720327e-06   1.08667996e-06\n",
      "   1.08198856e-06   1.08567326e-06   1.09547409e-06   1.10283622e-06\n",
      "   1.10104520e-06   1.09527309e-06   1.09245582e-06   1.09712801e-06\n",
      "   1.11082352e-06   1.12208272e-06   1.11998577e-06   1.11277427e-06\n",
      "   1.10769895e-06   1.11138718e-06   1.11479790e-06   1.11015879e-06\n",
      "   1.10367728e-06   1.10144651e-06   1.10262044e-06   1.10573615e-06\n",
      "   1.11090617e-06   1.11648546e-06   1.11466215e-06   1.11002237e-06\n",
      "   1.10786550e-06   1.10815495e-06   1.10361714e-06   1.09561313e-06\n",
      "   1.09662346e-06   1.10482415e-06   1.10847179e-06   1.10718872e-06\n",
      "   1.10606391e-06   1.11329393e-06   1.12069131e-06   1.11900385e-06\n",
      "   1.10749738e-06   1.09144992e-06   1.08412462e-06   1.08861263e-06\n",
      "   1.09117821e-06   1.08696975e-06   1.08621191e-06   1.09413077e-06\n",
      "   1.09725750e-06   1.09363862e-06   1.09061375e-06   1.08864606e-06\n",
      "   1.08756444e-06   1.08790175e-06   1.09054065e-06   1.09891505e-06\n",
      "   1.11300096e-06   1.12101918e-06   1.11332531e-06   1.10366932e-06\n",
      "   1.10163899e-06   1.10447479e-06   1.10413089e-06   1.10270867e-06\n",
      "   1.09977532e-06   1.10412782e-06   1.11092038e-06   1.10780366e-06\n",
      "   1.09685777e-06   1.09109169e-06   1.09693428e-06   1.10750852e-06\n",
      "   1.11096688e-06   1.10921007e-06   1.10451629e-06   1.09906853e-06\n",
      "   1.09719917e-06   1.09927782e-06   1.10333622e-06   1.10268877e-06\n",
      "   1.09847258e-06   1.09150335e-06   1.08606559e-06   1.08534221e-06\n",
      "   1.09507323e-06   1.10819178e-06   7.76658729e-02   2.65502304e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.84812629]\n",
      "Write gamma - [ 2.18949914]\n",
      "w rotations - Tensor(\"strided_slice_19:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.84727508e-01   2.30854079e-01   4.92666848e-02   1.50841649e-03\n",
      "   6.53786358e-09   6.53896981e-09   6.54493348e-09   6.55481935e-09\n",
      "   6.55987131e-09   6.58137989e-09   6.60578525e-09   6.60094646e-09\n",
      "   6.58350485e-09   6.57773880e-09   6.57573596e-09   6.56701094e-09\n",
      "   6.56093402e-09   6.54594379e-09   6.51709753e-09   6.47276588e-09\n",
      "   6.43678844e-09   6.42313314e-09   6.44103215e-09   6.49535803e-09\n",
      "   6.54652554e-09   6.54499432e-09   6.50088428e-09   6.46443610e-09\n",
      "   6.48240173e-09   6.54863896e-09   6.60173560e-09   6.59939481e-09\n",
      "   6.58476385e-09   6.59774546e-09   6.62586430e-09   6.64813671e-09\n",
      "   6.65183775e-09   6.63239463e-09   6.61000055e-09   6.61383837e-09\n",
      "   6.62323307e-09   6.59147270e-09   6.53520393e-09   6.48840270e-09\n",
      "   6.46864340e-09   6.48521725e-09   6.52631948e-09   6.55641363e-09\n",
      "   6.55030918e-09   6.52717214e-09   6.51704291e-09   6.54047527e-09\n",
      "   6.59843957e-09   6.64437749e-09   6.63827571e-09   6.60837340e-09\n",
      "   6.58882016e-09   6.60144250e-09   6.61268773e-09   6.59395738e-09\n",
      "   6.56714416e-09   6.55660459e-09   6.56152821e-09   6.57634835e-09\n",
      "   6.59974519e-09   6.62119470e-09   6.61472832e-09   6.59593669e-09\n",
      "   6.58605126e-09   6.58323529e-09   6.56237953e-09   6.53220544e-09\n",
      "   6.53666810e-09   6.56856658e-09   6.58497212e-09   6.58158239e-09\n",
      "   6.58129284e-09   6.61097932e-09   6.64007471e-09   6.63085320e-09\n",
      "   6.57921939e-09   6.51185150e-09   6.48040510e-09   6.49414256e-09\n",
      "   6.50299281e-09   6.48891074e-09   6.48885123e-09   6.51845644e-09\n",
      "   6.53141541e-09   6.51832366e-09   6.50455689e-09   6.49538379e-09\n",
      "   6.49074927e-09   6.49298570e-09   6.50756693e-09   6.54716903e-09\n",
      "   6.60647625e-09   6.63765043e-09   6.60842669e-09   6.56884724e-09\n",
      "   6.55840671e-09   6.56725785e-09   6.56662102e-09   6.55960886e-09\n",
      "   6.55107479e-09   6.56917543e-09   6.59371668e-09   6.57945431e-09\n",
      "   6.53542420e-09   6.51288756e-09   6.53709087e-09   6.57979493e-09\n",
      "   6.59646204e-09   6.58912436e-09   6.56820909e-09   6.54529808e-09\n",
      "   6.53712817e-09   6.54601795e-09   6.56112720e-09   6.55834542e-09\n",
      "   6.53880639e-09   6.50861853e-09   6.48534471e-09   6.48587628e-09\n",
      "   6.52795729e-09   2.13126116e-03   6.02465235e-02   2.71265090e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 2.64831424]\n",
      "Write gamma - [ 2.59133911]\n",
      "w rotations - Tensor(\"strided_slice_24:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  5.00108480e-01   1.71521306e-01   9.69383772e-03   5.86015158e-05\n",
      "   1.77100077e-08   3.73627832e-13   3.73632820e-13   3.73639948e-13\n",
      "   3.73646697e-13   3.73663313e-13   3.73678844e-13   3.73675320e-13\n",
      "   3.73663692e-13   3.73658705e-13   3.73655832e-13   3.73649625e-13\n",
      "   3.73643255e-13   3.73629784e-13   3.73605118e-13   3.73571481e-13\n",
      "   3.73544701e-13   3.73536488e-13   3.73553727e-13   3.73594737e-13\n",
      "   3.73629242e-13   3.73625826e-13   3.73594195e-13   3.73571643e-13\n",
      "   3.73589045e-13   3.73637563e-13   3.73673857e-13   3.73674236e-13\n",
      "   3.73667216e-13   3.73677814e-13   3.73698685e-13   3.73714704e-13\n",
      "   3.73715815e-13   3.73701287e-13   3.73686948e-13   3.73688900e-13\n",
      "   3.73690391e-13   3.73664126e-13   3.73621544e-13   3.73586633e-13\n",
      "   3.73573703e-13   3.73587934e-13   3.73617939e-13   3.73638213e-13\n",
      "   3.73633470e-13   3.73617776e-13   3.73613223e-13   3.73634690e-13\n",
      "   3.73677543e-13   3.73708524e-13   3.73703970e-13   3.73682910e-13\n",
      "   3.73670821e-13   3.73678464e-13   3.73683479e-13   3.73669330e-13\n",
      "   3.73650492e-13   3.73642821e-13   3.73647077e-13   3.73659626e-13\n",
      "   3.73677733e-13   3.73691421e-13   3.73686406e-13   3.73673315e-13\n",
      "   3.73665644e-13   3.73660277e-13   3.73643363e-13   3.73624417e-13\n",
      "   3.73629296e-13   3.73651034e-13   3.73662771e-13   3.73661849e-13\n",
      "   3.73665644e-13   3.73687436e-13   3.73705813e-13   3.73695107e-13\n",
      "   3.73654070e-13   3.73605552e-13   3.73583651e-13   3.73590888e-13\n",
      "   3.73595116e-13   3.73587364e-13   3.73590509e-13   3.73609997e-13\n",
      "   3.73618156e-13   3.73609265e-13   3.73598830e-13   3.73591647e-13\n",
      "   3.73588476e-13   3.73591539e-13   3.73606040e-13   3.73639135e-13\n",
      "   3.73681907e-13   3.73700853e-13   3.73680037e-13   3.73652769e-13\n",
      "   3.73644827e-13   3.73649299e-13   3.73648540e-13   3.73643174e-13\n",
      "   3.73640057e-13   3.73653690e-13   3.73667758e-13   3.73654829e-13\n",
      "   3.73624254e-13   3.73610946e-13   3.73629784e-13   3.73659464e-13\n",
      "   3.73671526e-13   3.73665427e-13   3.73649083e-13   3.73632738e-13\n",
      "   3.73627399e-13   3.73634202e-13   3.73643553e-13   3.73640219e-13\n",
      "   3.73624146e-13   3.73601323e-13   3.73585223e-13   3.73589777e-13\n",
      "   1.54473895e-07   3.14272300e-04   2.68730111e-02   2.91430354e-01]\n",
      "Argmax - 0\n",
      "\n",
      "Epoch - 11, Mean error of final batch in epoch - 0.304\n",
      "Epoch - 12, Mean error of final batch in epoch - 0.239333\n",
      "Epoch - 13, Mean error of final batch in epoch - 0.216667\n",
      "Epoch - 14, Mean error of final batch in epoch - 0.136667\n",
      "Epoch - 15, Mean error of final batch in epoch - 0.101333\n",
      "Epoch - 16, Mean error of final batch in epoch - 0.096\n",
      "Epoch - 17, Mean error of final batch in epoch - 0.0613333\n",
      "Epoch - 18, Mean error of final batch in epoch - 0.03\n",
      "Epoch - 19, Mean error of final batch in epoch - 0.0333333\n",
      "Epoch - 20, Mean error of final batch in epoch - 0.0233333\n",
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.42083395]\n",
      "Write gamma - [ 1.28676689]\n",
      "w rotations - Tensor(\"strided_slice_4:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  1.00000012e+00   6.74409137e-07   1.14849328e-07   3.51773622e-07\n",
      "   4.10687335e-07   7.00726389e-07   2.84655812e-07   9.35001822e-07\n",
      "   7.64536253e-07   8.64594014e-08   9.09719347e-07   4.80420113e-07\n",
      "   9.57880502e-07   3.69534490e-07   2.53596198e-07   4.56261517e-07\n",
      "   7.49838932e-07   6.08722928e-07   6.34005687e-07   4.05477408e-07\n",
      "   6.52992242e-07   9.83758241e-07   5.55518625e-07   4.59515093e-07\n",
      "   2.88014412e-08   6.09445237e-07   2.32802265e-07   4.77548724e-07\n",
      "   5.24780148e-07   4.59530241e-07   7.74822013e-07   9.74292448e-07\n",
      "   4.49588669e-07   2.14106791e-07   2.79700402e-07   7.82708753e-07\n",
      "   1.17695329e-08   5.71732414e-07   7.53004556e-08   8.13453426e-07\n",
      "   2.14165809e-07   3.39916824e-07   1.59461024e-07   3.06883095e-07\n",
      "   8.86263138e-07   7.54452685e-07   7.28297209e-08   1.56141525e-07\n",
      "   4.02261016e-08   5.72029364e-07   7.68465966e-08   2.35370038e-07\n",
      "   6.67361746e-07   4.86062277e-07   6.27858185e-07   8.35888613e-07\n",
      "   3.59438417e-07   8.83823134e-07   2.43290771e-07   6.38359666e-07\n",
      "   6.93934908e-07   5.57373312e-07   8.42471024e-07   7.24030031e-07\n",
      "   4.92698689e-07   8.92610217e-07   8.87476062e-07   2.14768647e-08\n",
      "   3.50053313e-07   7.60121111e-07   1.98385479e-07   4.83449810e-07\n",
      "   7.44078648e-07   7.01082797e-07   2.65327458e-07   1.93030836e-08\n",
      "   4.31451923e-07   6.97422649e-07   1.92462807e-07   6.13062866e-07\n",
      "   2.84410959e-07   7.77081226e-08   4.63101145e-07   2.81511543e-08\n",
      "   1.63506982e-07   8.12802568e-07   1.60645239e-08   8.97158259e-07\n",
      "   7.74370434e-08   8.19273566e-07   5.55063480e-08   4.63262779e-08\n",
      "   2.13770988e-07   6.73913947e-09   6.05486491e-07   1.66500328e-07\n",
      "   5.58525315e-08   5.82855591e-07   1.20926614e-07   6.56469695e-07\n",
      "   9.22755476e-07   4.88055093e-07   5.79000471e-07   8.92357946e-07\n",
      "   9.26651964e-08   3.76397622e-07   1.08624938e-07   2.83154122e-07\n",
      "   3.55151400e-07   8.70464817e-07   5.79158325e-07   2.93561698e-07\n",
      "   7.29048253e-08   7.66651596e-08   9.24731864e-07   9.96118729e-07\n",
      "   7.11390953e-07   5.32381307e-07   5.32280581e-07   7.15034730e-07\n",
      "   9.66401899e-07   8.42654728e-08   7.17705120e-07   6.49952312e-07\n",
      "   5.49345941e-07   3.34391245e-07   1.47940156e-07   7.70372878e-07]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_9:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.58077884e-01   2.74419934e-01   3.86869914e-08   3.66593333e-08\n",
      "   4.37874164e-08   4.26413749e-08   4.91226153e-08   5.10104918e-08\n",
      "   4.64775312e-08   4.67917225e-08   4.45651551e-08   5.44826975e-08\n",
      "   4.79964442e-08   4.37274750e-08   3.86539938e-08   4.39979004e-08\n",
      "   4.82184106e-08   4.98983930e-08   4.55336924e-08   4.61315608e-08\n",
      "   5.15594678e-08   5.28717727e-08   4.93384462e-08   3.76370721e-08\n",
      "   3.87144468e-08   3.67382818e-08   4.12025223e-08   4.10279135e-08\n",
      "   4.33930936e-08   4.73373731e-08   5.37183276e-08   5.26160626e-08\n",
      "   4.44333459e-08   3.66705919e-08   4.16848884e-08   3.86863732e-08\n",
      "   4.14116919e-08   3.40516131e-08   4.32374847e-08   3.96060962e-08\n",
      "   4.12918872e-08   3.42857831e-08   3.51962370e-08   4.28490630e-08\n",
      "   5.04488433e-08   4.56235689e-08   3.64227475e-08   2.90960109e-08\n",
      "   3.52199017e-08   3.43658400e-08   3.56160648e-08   3.81277019e-08\n",
      "   4.30320632e-08   4.72363588e-08   5.00437274e-08   4.78285571e-08\n",
      "   5.09337710e-08   4.39548380e-08   4.64813859e-08   4.55541169e-08\n",
      "   4.87585083e-08   5.14876994e-08   5.22207735e-08   5.05339521e-08\n",
      "   5.16385512e-08   5.44998890e-08   4.67757921e-08   3.96987048e-08\n",
      "   4.02550917e-08   4.16158095e-08   4.24391082e-08   4.36847820e-08\n",
      "   4.97232193e-08   4.59912783e-08   3.65434261e-08   3.42672521e-08\n",
      "   4.04591169e-08   4.15823642e-08   4.34347456e-08   3.91726438e-08\n",
      "   3.66339883e-08   3.56077798e-08   3.27630900e-08   3.29692966e-08\n",
      "   3.86037833e-08   3.79133205e-08   4.62003982e-08   3.82617351e-08\n",
      "   4.68797694e-08   3.76144449e-08   3.54490872e-08   2.97419511e-08\n",
      "   2.91191302e-08   3.58218024e-08   3.55993137e-08   3.47777345e-08\n",
      "   3.56642680e-08   3.52297320e-08   4.18461177e-08   4.76005866e-08\n",
      "   5.11202600e-08   4.94045693e-08   5.01857400e-08   4.43987958e-08\n",
      "   4.10286134e-08   3.28573471e-08   3.46235716e-08   3.50049731e-08\n",
      "   4.46101609e-08   4.83301328e-08   4.61209595e-08   3.63368002e-08\n",
      "   3.07227772e-08   3.94285529e-08   5.17931049e-08   5.83640265e-08\n",
      "   5.26372830e-08   4.70285499e-08   4.75795900e-08   5.35978053e-08\n",
      "   4.67568277e-08   4.63346979e-08   4.42880612e-08   4.89264451e-08\n",
      "   4.38847536e-08   3.75270588e-08   4.10750296e-08   3.67496908e-01]\n",
      "Argmax - 127\n",
      "\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 2.47190475]\n",
      "w rotations - Tensor(\"strided_slice_14:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.38701814e-01   2.27763891e-01   8.73265713e-02   1.03907439e-06\n",
      "   1.04107971e-06   1.04460253e-06   1.04742969e-06   1.04906542e-06\n",
      "   1.04786989e-06   1.04596347e-06   1.04778701e-06   1.04946059e-06\n",
      "   1.04878688e-06   1.04359822e-06   1.04156186e-06   1.04329013e-06\n",
      "   1.04718958e-06   1.04806452e-06   1.04694834e-06   1.04725621e-06\n",
      "   1.05004779e-06   1.05137633e-06   1.04720539e-06   1.04151536e-06\n",
      "   1.03771117e-06   1.03842603e-06   1.03960201e-06   1.04158153e-06\n",
      "   1.04355968e-06   1.04765127e-06   1.05125866e-06   1.05064805e-06\n",
      "   1.04483161e-06   1.04034643e-06   1.03915556e-06   1.04023502e-06\n",
      "   1.03844673e-06   1.03871309e-06   1.03921161e-06   1.04107858e-06\n",
      "   1.03875220e-06   1.03662592e-06   1.03681646e-06   1.04230867e-06\n",
      "   1.04660808e-06   1.04456956e-06   1.03726245e-06   1.03293030e-06\n",
      "   1.03291075e-06   1.03483899e-06   1.03575610e-06   1.03850448e-06\n",
      "   1.04245999e-06   1.04651360e-06   1.04842468e-06   1.04922810e-06\n",
      "   1.04794844e-06   1.04671631e-06   1.04529590e-06   1.04657056e-06\n",
      "   1.04833293e-06   1.05068034e-06   1.05140259e-06   1.05123104e-06\n",
      "   1.05191612e-06   1.05139281e-06   1.04721084e-06   1.04196624e-06\n",
      "   1.04030801e-06   1.04126912e-06   1.04237608e-06   1.04476635e-06\n",
      "   1.04667117e-06   1.04452329e-06   1.03880973e-06   1.03651178e-06\n",
      "   1.03865534e-06   1.04158596e-06   1.04157414e-06   1.03971831e-06\n",
      "   1.03703519e-06   1.03504249e-06   1.03359116e-06   1.03427521e-06\n",
      "   1.03649359e-06   1.04021206e-06   1.04131050e-06   1.04295520e-06\n",
      "   1.04153037e-06   1.03985212e-06   1.03448235e-06   1.03126001e-06\n",
      "   1.03097454e-06   1.03349691e-06   1.03531829e-06   1.03514333e-06\n",
      "   1.03513355e-06   1.03700143e-06   1.04114315e-06   1.04657465e-06\n",
      "   1.04940773e-06   1.05002459e-06   1.04825813e-06   1.04520711e-06\n",
      "   1.03978687e-06   1.03579680e-06   1.03403090e-06   1.03731475e-06\n",
      "   1.04241269e-06   1.04642254e-06   1.04407854e-06   1.03781917e-06\n",
      "   1.03470097e-06   1.03982529e-06   1.04947765e-06   1.05460902e-06\n",
      "   1.05282788e-06   1.04882645e-06   1.04887647e-06   1.04972196e-06\n",
      "   1.04868707e-06   1.04578885e-06   1.04604362e-06   1.04597052e-06\n",
      "   1.04365859e-06   1.04036428e-06   9.80869606e-02   2.47992516e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 5.66976213]\n",
      "Write gamma - [ 7.76631308]\n",
      "w rotations - Tensor(\"strided_slice_19:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  5.13383210e-01   2.02088356e-01   2.03218181e-02   4.33594278e-06\n",
      "   6.67355169e-14   6.70152681e-14   6.72444549e-14   6.73758128e-14\n",
      "   6.72852751e-14   6.71387587e-14   6.72762762e-14   6.74087183e-14\n",
      "   6.73527870e-14   6.69495858e-14   6.67824967e-14   6.69156774e-14\n",
      "   6.72207312e-14   6.72967270e-14   6.72139549e-14   6.72392304e-14\n",
      "   6.74567959e-14   6.75596325e-14   6.72331182e-14   6.67794474e-14\n",
      "   6.64747188e-14   6.65208245e-14   6.66158006e-14   6.67735452e-14\n",
      "   6.69371446e-14   6.72622833e-14   6.75497866e-14   6.75029287e-14\n",
      "   6.70471030e-14   6.66860569e-14   6.65847043e-14   6.66608763e-14\n",
      "   6.65277973e-14   6.65440603e-14   6.65859579e-14   6.67259623e-14\n",
      "   6.65499150e-14   6.63817891e-14   6.63996852e-14   6.68266237e-14\n",
      "   6.71675375e-14   6.70107687e-14   6.64396381e-14   6.60900845e-14\n",
      "   6.60800353e-14   6.62281102e-14   6.63077178e-14   6.65262523e-14\n",
      "   6.68426631e-14   6.71672055e-14   6.73263664e-14   6.73911949e-14\n",
      "   6.72930136e-14   6.71925352e-14   6.70823802e-14   6.71791927e-14\n",
      "   6.73219415e-14   6.75084446e-14   6.75702034e-14   6.75601475e-14\n",
      "   6.76115319e-14   6.75660767e-14   6.72343379e-14   6.68182957e-14\n",
      "   6.66788537e-14   6.67495912e-14   6.68408606e-14   6.70300743e-14\n",
      "   6.71790504e-14   6.70099962e-14   6.65634946e-14   6.63763274e-14\n",
      "   6.65383547e-14   6.67679684e-14   6.67719393e-14   6.66256601e-14\n",
      "   6.64126414e-14   6.62511970e-14   6.61365561e-14   6.61883132e-14\n",
      "   6.63651940e-14   6.66566479e-14   6.67534943e-14   6.68798648e-14\n",
      "   6.67725627e-14   6.66314809e-14   6.62123419e-14   6.59524993e-14\n",
      "   6.59262955e-14   6.61200898e-14   6.62651493e-14   6.62567603e-14\n",
      "   6.62586644e-14   6.64077829e-14   6.67379834e-14   6.71699363e-14\n",
      "   6.74034328e-14   6.74556643e-14   6.73164324e-14   6.70684076e-14\n",
      "   6.66387247e-14   6.63168115e-14   6.61770850e-14   6.64307680e-14\n",
      "   6.68356361e-14   6.71527585e-14   6.69735941e-14   6.64837041e-14\n",
      "   6.62377529e-14   6.66359193e-14   6.73979779e-14   6.78166765e-14\n",
      "   6.76867349e-14   6.73740035e-14   6.73682776e-14   6.74316424e-14\n",
      "   6.73495344e-14   6.71246777e-14   6.71361431e-14   6.71273475e-14\n",
      "   6.69444629e-14   1.73064780e-06   2.48290002e-02   2.39371568e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 4.25744534]\n",
      "Write gamma - [ 3.51788139]\n",
      "w rotations - Tensor(\"strided_slice_24:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  9.96520102e-01   7.32411456e-04   1.46055737e-11   2.99521045e-32\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.13033844e-30   7.32068017e-11   2.74753640e-03]\n",
      "Argmax - 0\n",
      "\n",
      "Epoch - 21, Mean error of final batch in epoch - 0.0286667\n",
      "Epoch - 22, Mean error of final batch in epoch - 0.014\n",
      "Epoch - 23, Mean error of final batch in epoch - 0.00666667\n",
      "Epoch - 24, Mean error of final batch in epoch - 0.004\n",
      "Epoch - 25, Mean error of final batch in epoch - 0.00333333\n",
      "Epoch - 26, Mean error of final batch in epoch - 0.00666667\n",
      "Epoch - 27, Mean error of final batch in epoch - 0.00266667\n",
      "Epoch - 28, Mean error of final batch in epoch - 0.000666667\n",
      "Epoch - 29, Mean error of final batch in epoch - 0.000666667\n",
      "Epoch - 30, Mean error of final batch in epoch - 0.000666667\n",
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.59293914]\n",
      "Write gamma - [ 1.32676446]\n",
      "w rotations - Tensor(\"strided_slice_4:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  1.00000024e+00   9.87997169e-07   6.58404842e-09   1.08841895e-07\n",
      "   6.09355084e-07   3.83060808e-07   7.27230770e-07   6.41840714e-08\n",
      "   8.89914133e-07   6.30277384e-07   7.89481405e-08   7.58668307e-07\n",
      "   6.41363158e-07   1.81704767e-08   6.92855224e-07   5.42379041e-07\n",
      "   7.67173674e-07   9.73694000e-07   1.82942870e-07   5.75235106e-07\n",
      "   7.15502608e-07   7.43141641e-07   8.18499814e-07   7.37749076e-07\n",
      "   4.27929990e-07   1.92117326e-07   6.08781932e-07   7.24633196e-07\n",
      "   6.17904163e-07   2.62619494e-07   5.02244347e-07   5.86936949e-07\n",
      "   4.43763746e-08   2.85086031e-07   2.24914672e-07   2.73174891e-07\n",
      "   8.70929924e-08   8.07253571e-07   6.77304513e-07   1.09076979e-07\n",
      "   4.10021670e-07   7.31049056e-07   5.41568966e-07   4.62536462e-07\n",
      "   4.46948064e-07   5.88698981e-07   6.66517508e-07   5.46451190e-07\n",
      "   4.13843878e-07   4.51306221e-07   7.77578009e-07   6.96325174e-07\n",
      "   7.66884114e-07   8.26460450e-07   4.10977947e-07   3.26847328e-07\n",
      "   3.53403692e-07   9.13800250e-07   7.56068005e-07   7.40333292e-07\n",
      "   6.17862952e-08   9.74917953e-07   3.68661517e-07   3.82741206e-07\n",
      "   5.70391080e-07   6.27063059e-07   7.62442710e-07   7.72613419e-07\n",
      "   8.46856381e-07   2.45958205e-07   7.00532212e-07   7.65500886e-07\n",
      "   6.03110209e-07   4.40841092e-07   8.16931617e-07   2.89289460e-07\n",
      "   9.36405911e-07   4.92694141e-07   5.61519983e-07   9.28753025e-07\n",
      "   9.86996952e-07   2.12626450e-08   7.86238786e-07   3.74856342e-07\n",
      "   5.02811929e-07   4.66340538e-07   7.58968568e-08   6.79018740e-07\n",
      "   8.64999436e-07   5.17291426e-07   8.66425864e-07   8.44054682e-07\n",
      "   4.84204520e-07   7.89129615e-07   4.09767495e-07   5.23571977e-08\n",
      "   9.65678396e-07   8.66562232e-07   5.86774092e-07   8.00752900e-07\n",
      "   4.29705267e-07   3.37432027e-07   5.07218260e-07   1.94221258e-07\n",
      "   5.54523126e-07   9.95026880e-07   4.38552007e-07   4.38615444e-07\n",
      "   9.09801486e-07   6.60120236e-07   7.50102970e-07   4.70751274e-07\n",
      "   7.47811768e-09   7.34380478e-07   1.22615816e-07   8.96373365e-07\n",
      "   7.46265869e-07   4.54629429e-07   8.85074030e-07   6.98302870e-07\n",
      "   9.80491905e-07   6.15972283e-07   1.48652077e-07   4.79547509e-07\n",
      "   3.44196678e-07   8.42157931e-07   1.12204674e-07   8.35332628e-07]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "w rotations - Tensor(\"strided_slice_9:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  4.21083659e-01   2.54516423e-01   2.22753549e-08   2.08614050e-08\n",
      "   2.43403662e-08   2.80832531e-08   2.47424712e-08   2.70893334e-08\n",
      "   2.86017006e-08   2.71952967e-08   2.55916373e-08   2.75323551e-08\n",
      "   2.59836899e-08   2.45957530e-08   2.57541704e-08   3.04872394e-08\n",
      "   3.33587877e-08   3.05088435e-08   2.73629759e-08   2.70454095e-08\n",
      "   3.11994270e-08   3.30298349e-08   3.33076358e-08   3.05130499e-08\n",
      "   2.51920778e-08   2.42162219e-08   2.74939183e-08   3.05077350e-08\n",
      "   2.74363501e-08   2.52614303e-08   2.58780748e-08   2.40507454e-08\n",
      "   2.14511040e-08   1.98585504e-08   2.11320597e-08   1.98444958e-08\n",
      "   2.37766500e-08   2.83301365e-08   2.73395333e-08   2.35220057e-08\n",
      "   2.51425902e-08   2.86486053e-08   2.83157178e-08   2.62168705e-08\n",
      "   2.66568829e-08   2.85101809e-08   2.92423348e-08   2.75599437e-08\n",
      "   2.58255337e-08   2.78527832e-08   3.06014876e-08   3.25662093e-08\n",
      "   3.32004362e-08   3.08981924e-08   2.66373128e-08   2.34218209e-08\n",
      "   2.74199543e-08   3.17603899e-08   3.38709043e-08   2.72367551e-08\n",
      "   2.78145613e-08   2.73470899e-08   2.76328880e-08   2.53132146e-08\n",
      "   2.76068324e-08   3.04580645e-08   3.22481704e-08   3.38758248e-08\n",
      "   2.98156628e-08   2.81163697e-08   2.90443953e-08   3.14023154e-08\n",
      "   2.89611854e-08   2.93039086e-08   2.76906249e-08   3.02034309e-08\n",
      "   2.94436617e-08   2.99818623e-08   3.06327017e-08   3.52198235e-08\n",
      "   3.04215604e-08   2.75600858e-08   2.53613024e-08   2.74024039e-08\n",
      "   2.56751775e-08   2.31880062e-08   2.39199416e-08   2.85053048e-08\n",
      "   3.15424913e-08   3.21960094e-08   3.31158674e-08   3.23317622e-08\n",
      "   3.11055501e-08   2.86540054e-08   2.42869973e-08   2.55225299e-08\n",
      "   3.11387112e-08   3.40693944e-08   3.23600133e-08   2.95997165e-08\n",
      "   2.67300067e-08   2.47986573e-08   2.34152502e-08   2.43247165e-08\n",
      "   2.91132185e-08   3.13477493e-08   2.88713871e-08   2.89328330e-08\n",
      "   3.15193809e-08   3.29675949e-08   2.99217398e-08   2.42631657e-08\n",
      "   2.37373161e-08   2.28925270e-08   2.77406063e-08   2.99686143e-08\n",
      "   3.13315525e-08   3.09327319e-08   3.16923234e-08   3.50744429e-08\n",
      "   3.36193331e-08   2.81935435e-08   2.40234161e-08   2.31087416e-08\n",
      "   2.77661147e-08   2.59317545e-08   2.78661840e-08   3.24396104e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 1.]\n",
      "Write gamma - [ 2.98484206]\n",
      "w rotations - Tensor(\"strided_slice_14:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  3.33626866e-01   2.30483487e-01   8.87137130e-02   1.02234571e-06\n",
      "   1.02420393e-06   1.02557044e-06   1.02653280e-06   1.02662796e-06\n",
      "   1.02748993e-06   1.02703746e-06   1.02664546e-06   1.02622562e-06\n",
      "   1.02594515e-06   1.02532238e-06   1.02674562e-06   1.02963190e-06\n",
      "   1.03130731e-06   1.03035654e-06   1.02822605e-06   1.02836441e-06\n",
      "   1.03021011e-06   1.03234970e-06   1.03217803e-06   1.02964020e-06\n",
      "   1.02660135e-06   1.02548245e-06   1.02719218e-06   1.02833553e-06\n",
      "   1.02767467e-06   1.02608760e-06   1.02494312e-06   1.02371882e-06\n",
      "   1.02171350e-06   1.02069419e-06   1.02014280e-06   1.02143099e-06\n",
      "   1.02374361e-06   1.02629247e-06   1.02632293e-06   1.02524461e-06\n",
      "   1.02557738e-06   1.02718809e-06   1.02762385e-06   1.02695947e-06\n",
      "   1.02697015e-06   1.02796912e-06   1.02831336e-06   1.02745605e-06\n",
      "   1.02695287e-06   1.02790136e-06   1.03014543e-06   1.03195418e-06\n",
      "   1.03210527e-06   1.03019534e-06   1.02695481e-06   1.02570107e-06\n",
      "   1.02729473e-06   1.03079628e-06   1.03086450e-06   1.02960439e-06\n",
      "   1.02733134e-06   1.02747117e-06   1.02665433e-06   1.02673050e-06\n",
      "   1.02759554e-06   1.02990998e-06   1.03201728e-06   1.03186755e-06\n",
      "   1.03055163e-06   1.02887680e-06   1.02934985e-06   1.02966192e-06\n",
      "   1.02979141e-06   1.02853301e-06   1.02893205e-06   1.02895126e-06\n",
      "   1.02975071e-06   1.02987281e-06   1.03175330e-06   1.03194191e-06\n",
      "   1.03104003e-06   1.02771753e-06   1.02665501e-06   1.02600313e-06\n",
      "   1.02534455e-06   1.02416038e-06   1.02501258e-06   1.02775516e-06\n",
      "   1.03056300e-06   1.03213313e-06   1.03241075e-06   1.03207810e-06\n",
      "   1.03061109e-06   1.02796935e-06   1.02607692e-06   1.02677177e-06\n",
      "   1.02999445e-06   1.03236493e-06   1.03193418e-06   1.02950526e-06\n",
      "   1.02697663e-06   1.02489514e-06   1.02406011e-06   1.02542106e-06\n",
      "   1.02803335e-06   1.02963895e-06   1.02962315e-06   1.02961417e-06\n",
      "   1.03095317e-06   1.03134903e-06   1.02902754e-06   1.02593538e-06\n",
      "   1.02351771e-06   1.02461956e-06   1.02663807e-06   1.02950014e-06\n",
      "   1.03059642e-06   1.03118521e-06   1.03238642e-06   1.03329444e-06\n",
      "   1.03224534e-06   1.02860906e-06   1.02505146e-06   1.02479862e-06\n",
      "   1.02542037e-06   1.02706395e-06   1.04590200e-01   2.42459446e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 5.37713385]\n",
      "Write gamma - [ 8.48305321]\n",
      "w rotations - Tensor(\"strided_slice_19:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  5.47152519e-01   1.96238816e-01   1.30229993e-02   2.42904048e-06\n",
      "   1.61832897e-16   1.62160951e-16   1.62385560e-16   1.62430267e-16\n",
      "   1.62608952e-16   1.62519815e-16   1.62424828e-16   1.62326612e-16\n",
      "   1.62253224e-16   1.62135407e-16   1.62465843e-16   1.63121287e-16\n",
      "   1.63506687e-16   1.63300038e-16   1.62834845e-16   1.62858059e-16\n",
      "   1.63280609e-16   1.63760758e-16   1.63721529e-16   1.63138731e-16\n",
      "   1.62442390e-16   1.62184270e-16   1.62546258e-16   1.62804894e-16\n",
      "   1.62659959e-16   1.62298898e-16   1.62018199e-16   1.61717132e-16\n",
      "   1.61262738e-16   1.61012400e-16   1.60898276e-16   1.61192117e-16\n",
      "   1.61731875e-16   1.62305039e-16   1.62333361e-16   1.62109229e-16\n",
      "   1.62185409e-16   1.62537668e-16   1.62644236e-16   1.62509319e-16\n",
      "   1.62515143e-16   1.62732010e-16   1.62808269e-16   1.62624317e-16\n",
      "   1.62517538e-16   1.62740890e-16   1.63255171e-16   1.63674466e-16\n",
      "   1.63707593e-16   1.63260518e-16   1.62528086e-16   1.62236932e-16\n",
      "   1.62602744e-16   1.63371387e-16   1.63418953e-16   1.63122042e-16\n",
      "   1.62622570e-16   1.62609931e-16   1.62439293e-16   1.62455122e-16\n",
      "   1.62669713e-16   1.63201583e-16   1.63681573e-16   1.63662316e-16\n",
      "   1.63357901e-16   1.62988713e-16   1.63069896e-16   1.63144726e-16\n",
      "   1.63160449e-16   1.62899471e-16   1.62967008e-16   1.62987019e-16\n",
      "   1.63159033e-16   1.63220470e-16   1.63625709e-16   1.63680806e-16\n",
      "   1.63448176e-16   1.62714248e-16   1.62433523e-16   1.62271819e-16\n",
      "   1.62107826e-16   1.61858441e-16   1.62057639e-16   1.62688017e-16\n",
      "   1.63344481e-16   1.63722522e-16   1.63799575e-16   1.63713602e-16\n",
      "   1.63361831e-16   1.62754403e-16   1.62324216e-16   1.62486621e-16\n",
      "   1.63212436e-16   1.63757859e-16   1.63667902e-16   1.63111414e-16\n",
      "   1.62512747e-16   1.62024830e-16   1.61836153e-16   1.62146498e-16\n",
      "   1.62740996e-16   1.63119209e-16   1.63138188e-16   1.63153355e-16\n",
      "   1.63443650e-16   1.63517063e-16   1.62988118e-16   1.62267253e-16\n",
      "   1.61725523e-16   1.61951098e-16   1.62431458e-16   1.63082549e-16\n",
      "   1.63363909e-16   1.63520346e-16   1.63796730e-16   1.63994168e-16\n",
      "   1.63735916e-16   1.62900238e-16   1.62090223e-16   1.61994853e-16\n",
      "   1.62144208e-16   3.05468711e-06   1.96340308e-02   2.23946139e-01]\n",
      "Argmax - 0\n",
      "\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma  - [ 4.12484741]\n",
      "Write gamma - [ 3.55724216]\n",
      "w rotations - Tensor(\"strided_slice_24:0\", shape=(3,), dtype=float32)\n",
      "Write address -\n",
      "[  9.99309421e-01   1.68742728e-04   1.85093267e-14   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   6.19146065e-13   5.21842507e-04]\n",
      "Argmax - 0\n",
      "\n",
      "Epoch - 31, Mean error of final batch in epoch - 0.000666667\n",
      "Epoch - 32, Mean error of final batch in epoch - 0.00133333\n",
      "Epoch - 33, Mean error of final batch in epoch - 0.000666667\n",
      "Epoch - 34, Mean error of final batch in epoch - 0.000666667\n",
      "Epoch - 35, Mean error of final batch in epoch - 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba211914dda1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Do gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged_summaries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Write out TensorBoard logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "# An annoying thing here is that we cannot use a list as a key in a \n",
    "# dictionary. The workaround we found on StackOverflow here:\n",
    "# http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "\n",
    "# epoch is a global var\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences\n",
    "        for z in range(batch_size):\n",
    "            # construct a sequence from 0,...,num_classes - 3 then append initial and terminal symbols\n",
    "            a = [random.randint(0,num_classes-3) for k in range(N-2)]\n",
    "            fa = func_to_learn(a)\n",
    "            a = [init_symbol] + a + [term_symbol]\n",
    "            a_onehot = [one_hots[e] for e in a]\n",
    "            fa_onehot = [one_hots[e] for e in fa]\n",
    "            inp.append(np.array(a_onehot))\n",
    "            out.append(np.array(fa_onehot))        \n",
    "        \n",
    "        feed_dict = {}\n",
    "        for d in range(N):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "        \n",
    "        # for the first batch in an epoch, we have some logging\n",
    "        if( j == 0 and i % 10 == 0 ):\n",
    "            ss_val, gamma_reads_val, gamma_writes_val, read_addresses_val, write_addresses_val = sess.run([ss, gamma_reads,gamma_writes,read_addresses,write_addresses],feed_dict)\n",
    "    \n",
    "            s = 0\n",
    "            for r in range(len(write_addresses_val)):\n",
    "                print(\"\")\n",
    "                print(\"Step \" + str(s) + \" of the RNN run on the first input of first batch of this epoch\")\n",
    "                print(\"Read gamma  - \" + str(gamma_reads_val[r]))\n",
    "                print(\"Write gamma - \" + str(gamma_writes_val[r]))\n",
    "                print(\"w rotations - \" + str(ss_val[r]))\n",
    "                print(\"Write address -\")\n",
    "                print(write_addresses_val[r])\n",
    "                print(\"Argmax - \" + str(write_addresses_val[r].argmax()))\n",
    "                print(\"\")\n",
    "                s = s + 1\n",
    "        \n",
    "        # Do gradient descent\n",
    "        summary,_ = sess.run([merged_summaries,minimize], feed_dict)\n",
    "        \n",
    "        # Write out TensorBoard logs\n",
    "        file_writer.add_summary(summary)\n",
    "    current_mean = np.mean(sess.run(errors, feed_dict))\n",
    "    print(\"Epoch - \" + str(i+1) + \", Mean error of final batch in epoch - \" + str(current_mean))\n",
    "    \n",
    "    # DEBUG\n",
    "    #with tf.variable_scope(\"NTM\",reuse=True):\n",
    "    #    H = tf.get_variable(\"H\", [controller_state_size,controller_state_size])\n",
    "    #    print(sess.run(H))\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took\", time.time() - pre_train_time, \"seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4f63f171ee55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Restore the weights from training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# DEBUG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Note that all the weights will be loaded from the saved training session\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest_out)]\n",
    "state_test = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n",
    "\n",
    "# Set up test graph\n",
    "reuse = True\n",
    "for i in range(Ntest):\n",
    "    output, state = cell(inputs_test[i],state_test,'NTM',reuse)\n",
    "\n",
    "rnn_outputs_test = []\n",
    "for i in range(Ntest_out):\n",
    "    output, state = cell(tf.zeros([batch_size,input_size]),state_test,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "    \n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.softmax(logit) for logit in logits_test] \n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "# DEBUG\n",
    "#with tf.variable_scope(\"NTM\",reuse=True):\n",
    "#    H = tf.get_variable(\"H\", [controller_state_size,controller_state_size])\n",
    "#    print(sess.run(H))\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "#print(\"Number of batches: \" + str(no_of_batches))\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    # We sample each batch on the fly from the set of all sequences\n",
    "    for z in range(batch_size):\n",
    "        a = [random.randint(0,num_classes-3) for k in range(Ntest-2)]\n",
    "        fa = func_to_learn(a)\n",
    "        a = [init_symbol] + a + [term_symbol]\n",
    "        a_onehot = [one_hots[e] for e in a]\n",
    "        fa_onehot = [one_hots[e] for e in fa]\n",
    "        inp.append(np.array(a_onehot))\n",
    "        out.append(np.array(fa_onehot))        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = np.mean(sess.run(errors_test, feed_dict))\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "# The first three digits of this should match the printout for the\n",
    "# first three test output sequences given earlier\n",
    "#data = sess.run([tf.argmax(targets[0],1), tf.argmax(prediction[0],1)],feed_dict)\n",
    "\n",
    "#print(\"First digits of test outputs (actual)\")\n",
    "#print(data[0])\n",
    "#print(\"First digits of test outputs (predicted)\")\n",
    "#print(data[1])\n",
    "\n",
    "# print the mean of the errors in each digit for the test set.\n",
    "#incorrects = sess.run(errors, feed_dict)\n",
    "# print(incorrects)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"N_out         - \" + str(N_out))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"Ntest_out     - \" + str(Ntest_out))\n",
    "print(\"ring 1 powers - \" + str(powers_ring1))\n",
    "print(\"ring 2 powers - \" + str(powers_ring2))\n",
    "print(\"# epochs      - \" + str(epoch))\n",
    "print(\"optimizer     - \" + str(model_optimizer))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"(css,mas,mcs) - (\" + str(controller_state_size) + \",\" + str(memory_address_size) + \",\" + str(memory_content_size) + \")\")\n",
    "print(\"train percent - \" + str(training_percent))\n",
    "print(\"num_training  - \" + str(num_training) + \"/\" + str(num_classes**N))\n",
    "print(\"num_test      - \" + str(num_test) + \"/\" + str(num_classes**N))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"error         - \" + str(final_error))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
