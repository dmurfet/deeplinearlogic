{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of the Linear Logic Recurrent Neural Network (LLRNN)\n",
    "#\n",
    "# Version 10.0\n",
    "\n",
    "###################\n",
    "# HYPERPARAMETERS #\n",
    "###################\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, mult_pattern_ntm\n",
    "task                  = 'copy' # copy, repeat copy, pattern i, mult pattern i, variable pattern i\n",
    "epoch                 = 100 # number of training epochs, default to 100\n",
    "num_classes           = 10 # number of symbols, INCLUDING initial and terminal symbols, default 10\n",
    "N                     = 30 # length of input sequences for training, default to 30\n",
    "Ntest                 = 35 # length of sequences for testing, default to 35\n",
    "batch_size            = 250 # default 250\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "num_training          = 10000 # default 10000\n",
    "num_test              = num_training\n",
    "term_symbol           = num_classes - 1\n",
    "init_symbol           = num_classes - 2\n",
    "div_symbol            = num_classes - 3\n",
    "learning_rate         = 1e-4 # default 1e-4\n",
    "memory_init_bias      = 1.0 # default 1.0\n",
    "use_curriculum        = True # default True\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "\n",
    "##################\n",
    "# MODEL SPECIFIC #\n",
    "##################\n",
    "\n",
    "ntm_memory_address_size   = 128 # number of memory locations, default 128\n",
    "ntm_memory_content_size   = 20 # size of vector stored at a memory location, default 20\n",
    "ntm_powers                = [0,-1,1] # powers of R used by controller, default [0,-1,1]\n",
    "\n",
    "pattern_ntm_powers               = [[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "pattern_ntm_powers_2_on_1        = [0,1,2] # allowed powers used by ring 2 to manipulate ring 1\n",
    "pattern_ntm_memory_address_sizes = [128, 20] # number of memory locations for the three rings\n",
    "pattern_ntm_memory_content_sizes = [20, 3] # size of content vector for each ring\n",
    "pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "mult_pattern_ntm_powers               = [[0,-1,1],[0,-1,1],[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "mult_pattern_ntm_powers_2_on_1        = [0,1,2] # allowed powers used by rings 2,3 to manipulate ring 1\n",
    "mult_pattern_ntm_memory_address_sizes = [128, 20, 20, 10] # number of memory locations for the rings\n",
    "mult_pattern_ntm_memory_content_sizes = [20, 3, 3, 2] # size of content vector for each ring\n",
    "mult_pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs\n",
    "\n",
    "assert use_model == 'ntm' or use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[0, 1, 8, 2, 5, 5, 0, 7, 4, 4, 6, 5, 5, 1, 3, 2, 3, 5]\n",
      "is mapped to\n",
      "[2, 2, 5, 5, 5, 5, 0, 0, 7, 7, 4, 4, 4, 4, 6, 6, 5, 5, 5, 5, 1, 1, 3, 3, 2, 2, 3, 3, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "# Default sampling from space of inputs\n",
    "def generate_input_seq_default(max_symbol,input_length):\n",
    "    return [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "\n",
    "generate_input_seq = generate_input_seq_default\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "#\n",
    "# In this task the input is simply copied to the output (although we\n",
    "# require the RNN to output the first output symbol after the last\n",
    "# input symbol has been read, so this effectively requires the system\n",
    "# to store the input and later retrieve it)\n",
    "\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "    seq_length_min = 7\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "#\n",
    "# In this task every digit of the input is repeated.\n",
    "#\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "\n",
    "if( task == 'repeat copy' ):\n",
    "    no_of_copies = 2\n",
    "    pattern = [0]*(no_of_copies - 1) + [1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = no_of_copies * (N - 2)\n",
    "    Ntest_out = no_of_copies * (Ntest - 2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 1\n",
    "if( task == 'pattern 1' ):\n",
    "    pattern = [0,1,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,c,c,d,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = (N - 2) + divmod(N - 2, 2)[0] # N - 2 plus the number of times 2 divides N - 2\n",
    "    Ntest_out = (Ntest - 2) + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 2\n",
    "if( task == 'pattern 2' ):\n",
    "    pattern = [0,2] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = N - 2 + divmod(N - 2, 2)[0]\n",
    "    Ntest_out = Ntest - 2 + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 7\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 3\n",
    "if( task == 'pattern 3' ):\n",
    "    pattern = [0,2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,b,b,d,c,c,e,d,d,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 4 + (N - 2 - 2) * 3\n",
    "    Ntest_out = 4 + (Ntest - 2 - 2) * 3\n",
    "    seq_length_min = 7\n",
    "\n",
    "################\n",
    "# PATTERN TASK 4\n",
    "if( task == 'pattern 4' ):\n",
    "    pattern = [0,2,1,2,-2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,d,f,d,c,c,e,f,h,f,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 7\n",
    "\n",
    "################\n",
    "# PATTERN TASK 5\n",
    "if( task == 'pattern 5' ):\n",
    "    pattern = [4,1,1,-4] # so (a,b,c,d,e,f,...) goes to (a,e,f,g,k,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 7\n",
    "\n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 1\n",
    "if( task == 'mult pattern 1' or task == 'mult pattern 2'):\n",
    "    pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "    pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 2\n",
    "if( task == 'mult pattern 2' ):\n",
    "    # Almost everything is the same as mult pattern 1, but in pattern 2 we \n",
    "    # make sure there is a div symbol somewhere in the sequence\n",
    "    def generate_input_seq_forcediv(max_symbol,input_length):\n",
    "        t = [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "        div_pos = random.randint(0,len(t)-1)\n",
    "        t[div_pos] = div_symbol\n",
    "        return t\n",
    "    \n",
    "    generate_input_seq = generate_input_seq_forcediv\n",
    "\n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 3\n",
    "if( task == 'mult pattern 3'):\n",
    "    pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "    pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    pattern3 = [0,2] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2,pattern3],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "    \n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 4\n",
    "if( task == 'mult pattern 4'):\n",
    "    pattern1 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    pattern2 = [2,-1] # so (a,b,c,d,e,f,...) goes to (a,c,b,d,c,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,[pattern1,pattern2],div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 7\n",
    "\n",
    "#########################\n",
    "# VARIABLE PATTERN TASK 1\n",
    "#\n",
    "# The input is a pattern together with a string to which we are supposed to apply the\n",
    "# pattern, separated by an initial symbol. There is no division symbol.\n",
    "\n",
    "def generate_input_seq_varpattern1(max_symbol,input_length):\n",
    "    varpatterns = [[1],[2],[0,1],[0,2],[1,2]]\n",
    "    vp = varpatterns[random.randint(0,len(varpatterns)-1)]\n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "if( task == 'variable pattern 1'):\n",
    "    generate_input_seq = generate_input_seq_varpattern1\n",
    "    func_to_learn = lambda s: learnfuncs.f_varpattern(s,init_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 10\n",
    "    \n",
    "#########################\n",
    "# VARIABLE PATTERN TASK 2\n",
    "\n",
    "def generate_input_seq_varpattern2(max_symbol,input_length):\n",
    "    varpatterns = [[1],[2]]\n",
    "    varpatterns = varpatterns + [[0,1],[0,2],[1,2]]\n",
    "    varpatterns = varpatterns + [[0,1,0],[0,1,1],[0,1,2],[0,2,0],[0,2,1],[0,2,2],[1,1,2],[1,2,2]]\n",
    "    varpatterns = varpatterns + [[0,0,0,1],[0,0,0,2],[0,0,1,2],[0,1,1,2],[0,1,0,2],[0,2,0,2]]\n",
    "    vp = varpatterns[random.randint(0,len(varpatterns)-1)]\n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "if( task == 'variable pattern 2'):\n",
    "    generate_input_seq = generate_input_seq_varpattern1\n",
    "    func_to_learn = lambda s: learnfuncs.f_varpattern(s,init_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 13\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = generate_input_seq(num_classes-3,N-2)\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "\n",
    "def init_state_ntm(batch_size, css, mas, mcs):\n",
    "    state_size = css + 2*mas + mas * mcs\n",
    "    \n",
    "    ra = [0.0]*mas\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,mas]) + ra\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    init_read_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_write_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_memory = tf.truncated_normal([batch_size, mas*mcs], 0.0, 1e-6, dtype=tf.float32)\n",
    "    \n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "#############\n",
    "# PATTERN NTM\n",
    "\n",
    "def init_state_pattern_ntm(batch_size, css, mas, mcs):\n",
    "    # mas and mcs are arrays of address sizes and content sizes for rings\n",
    "    state_size = css\n",
    "    \n",
    "    init_address = []\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        state_size = state_size + mas[i] * mcs[i] # for memory vector\n",
    "        state_size = state_size + 2 * mas[i] # for addresses (read and write)\n",
    "    \n",
    "        ra = [0.0]*mas[i]\n",
    "        ra[0] = 1.0\n",
    "        init_address.append(np.zeros([batch_size,mas[i]]) + ra)\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    \n",
    "    tensor_list = [init_controller_state]\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        init_read_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        init_write_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        tensor_list = tensor_list + [init_read_address,init_write_address]\n",
    "        \n",
    "    for i in range(len(mas)):\n",
    "        # The first ring is initialised to zero, the rest differently\n",
    "        if( i == 0 ):\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "        else:\n",
    "            # This initialisation has the result of biasing the output of rings 2 and 3 to be\n",
    "            # \"no rotation\" and biasing ring 4 to say \"use ring 2\"\n",
    "            ra = [0.0]*mcs[i] \n",
    "            ra[0] = memory_init_bias\n",
    "            ra = np.zeros([batch_size,mas[i],mcs[i]]) + ra\n",
    "            ra = tf.constant(ra,dtype=tf.float32,shape=[batch_size,mas[i],mcs[i]])\n",
    "            ra = tf.reshape(ra,[batch_size,mas[i]*mcs[i]])\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32) + ra\n",
    "            #init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "            \n",
    "        tensor_list = tensor_list + [init_memory]\n",
    "    \n",
    "    state = tf.concat(tensor_list,1)\n",
    "\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "######################\n",
    "# MULTIPLE PATTERN NTM\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_55/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_54/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_53/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_52/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_51/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_50/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_49/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_48/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_47/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_46/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_45/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_44/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_43/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_42/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_41/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_40/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_39/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_38/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_37/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_36/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_35/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_34/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_33/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_32/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_31/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_30/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_29/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_28/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_27/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_26/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_25/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_24/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_23/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_22/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_21/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_20/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_19/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_18/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_17/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_16/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_15/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_14/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_13/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_11/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_9/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_7/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_5/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_3/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_1/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "read_addresses2 = []\n",
    "read_addresses3 = []\n",
    "read_addresses4 = []\n",
    "write_addresses = []\n",
    "write_addresses2 = []\n",
    "write_addresses3 = []\n",
    "write_addresses4 = []\n",
    "interps = []\n",
    "rnn_outputs = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "    \n",
    "for i in range(N + N_out):\n",
    "    \n",
    "    old_state = state\n",
    "\n",
    "    #### RUN MODEL ####\n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "    ###################\n",
    "\n",
    "    reuse = True\n",
    "    \n",
    "    #### SET UP NODES FOR LOGGING #####\n",
    "    if( use_model == 'ntm' ):\n",
    "        h0, curr_read, curr_write, _ = tf.split(old_state, [controller_state_size,ntm_memory_address_size,\n",
    "                                                        ntm_memory_address_size,-1], 1)\n",
    "\n",
    "    if( use_model == 'pattern_ntm' ):\n",
    "        mas = pattern_ntm_memory_address_sizes\n",
    "        mcs = pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(old_state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],mas[0] * mcs[0],mas[1] * mcs[1]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        m1_state = ret[5]\n",
    "        m2_state = ret[6]\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm' ):\n",
    "        mas = mult_pattern_ntm_memory_address_sizes\n",
    "        mcs = mult_pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(old_state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],                        \n",
    "                            mas[2],mas[2],mas[3],mas[3],mas[0] * mcs[0],mas[1] * mcs[1],\n",
    "                            mas[2] * mcs[2],mas[3] * mcs[3]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        curr_read3 = ret[5]\n",
    "        curr_write3 = ret[6]\n",
    "        curr_read4 = ret[7]\n",
    "        curr_write4 = ret[8]\n",
    "        m1_state = ret[9]\n",
    "        m2_state = ret[10]\n",
    "        m3_state = ret[11]\n",
    "        m4_state = ret[12]\n",
    "        \n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses2.append(curr_read2[0,:])\n",
    "        write_addresses2.append(curr_write2[0,:])\n",
    "        m2_state = tf.reshape(m2_state, [-1,mas[1],mcs[1]])\n",
    "        m2.append(tf.nn.softmax(m2_state[0,:]))\n",
    "        \n",
    "        with tf.variable_scope(\"NTM\",reuse=True):\n",
    "            W_interp = tf.get_variable(\"W_interp\", [controller_state_size,1])\n",
    "            B_interp = tf.get_variable(\"B_interp\", [1])\n",
    "            interp = tf.sigmoid(tf.matmul(h0,W_interp) + B_interp)\n",
    "            interp_matrix = tf.concat([interp,tf.ones_like(interp,dtype=tf.float32) - interp],axis=1) # shape [-1,2]\n",
    "            interps.append(interp_matrix[0,:])\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses3.append(curr_read3[0,:])\n",
    "        write_addresses3.append(curr_write3[0,:])\n",
    "        read_addresses4.append(curr_read4[0,:])\n",
    "        write_addresses4.append(curr_write4[0,:])\n",
    "        m3_state = tf.reshape(m3_state, [-1,mult_pattern_ntm_memory_address_sizes[2],mult_pattern_ntm_memory_content_sizes[2]])\n",
    "        m3.append(tf.nn.softmax(m3_state[0,:]))\n",
    "        m4_state = tf.reshape(m4_state, [-1,mult_pattern_ntm_memory_address_sizes[3],mult_pattern_ntm_memory_content_sizes[3]])\n",
    "        m4_state = m4_state[0,:]\n",
    "        m4_state = tf.concat([tf.nn.softmax(m4_state),tf.zeros([mult_pattern_ntm_memory_address_sizes[3],1])],1)\n",
    "        m4.append(m4_state)\n",
    "    ### END LOGGING ###\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# Note: prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "# Note: we use log_softmax to avoid precision issues with floats causing log(0) to create NaNs\n",
    "\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.log_softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * prediction[i]) for i in range(N + N_out)] # an array of numbers\n",
    "\n",
    "# Note: We allow the length of input sequences to vary between batches, which means\n",
    "# that the cross entropy needs to be masked to the relevant part of the output. The\n",
    "# relevant part consists of those positions that are not terminal symbols in the output\n",
    "# of _every_ input sequence in the batch. We detect such positions as follows. First,\n",
    "# we create a tensor term_detector which detects all the positions which are terminal symbols.\n",
    "# term_detector[i] is a boolean tensor which has False for those elements of the batch with\n",
    "# a terminal symbol in the output position i, and True otherwise.\n",
    "\n",
    "term_detector = [tf.not_equal(tf.argmax(targets[i],1),term_symbol) for i in range(N + N_out)]\n",
    "\n",
    "# We then convert False to 0.0 and True to 1.0, and compute the reduce_max, with the result\n",
    "# that mask is 1.0 in position i if and only if there was SOME element of the batch which\n",
    "# did NOT have a terminal symbol in position i\n",
    "\n",
    "mask = [tf.reduce_max(tf.cast(m, tf.float32)) for m in term_detector]\n",
    "ce_mask = [ce[i] * mask[i] for i in range(N + N_out)]\n",
    "cross_entropy = -tf.add_n(ce_mask)\n",
    "cross_entropy /= tf.add_n(mask)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate,decay=0.9,momentum=0.9)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N + N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "errors_mask = [errors[i] * mask[i] for i in range(N + N_out)]\n",
    "mean_error = tf.add_n(errors_mask)\n",
    "mean_error /= tf.add_n(mask)\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1, mean error - 0.810849\n",
      "Epoch - 2, mean error - 0.509073\n",
      "\n",
      "It took 72 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "###################\n",
    "# Note on sequences\n",
    "#\n",
    "# Our sequences are of varying length, in the alphabet {0,...,num_classes - 3}.\n",
    "# Each input sequence begins with an initial symbol and ends with a terminal symbol\n",
    "# (the value of which are num_classes - 2 and num_classes - 1 by default).\n",
    "#\n",
    "# Both input and output sequences are written on a \"tape\" of length N + N_out.\n",
    "# Input sequences are aligned at the BEGINNING of the tape, and all remaining space\n",
    "# is filled with terminal symbols. Output sequences are aligned at the END OF THE \n",
    "# MATCHING INPUT, with all remaining space filled with terminal symbols.\n",
    "#\n",
    "# Example: suppose N = N_out = 10, and num_classes = 10 so that init_symbol = 8\n",
    "# and term_symbol = 9. Then a sequence of length 8 (seq_length = 10 below) is\n",
    "#\n",
    "# a = [4, 4, 5, 6, 3, 3, 6, 7]\n",
    "#\n",
    "# which written on the tape is\n",
    "#\n",
    "# [8, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "#\n",
    "# If we are performing the copy task, so that the output sequence is also a, then\n",
    "# the output written on the tape will be (notice the alignment)\n",
    "#\n",
    "# [9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9]\n",
    "#\n",
    "\n",
    "def io_generator(max_symbol, input_length, total_length):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded pair of input and output sequence, with terminal and initial symbols.\n",
    "    \n",
    "    max_symbol - generate sequences in 0,...,max_symbol\n",
    "    input_length - length of input sequences, without initial and terminal symbols\n",
    "    total_length - length of the buffer, so that the sequences are padded to this length\n",
    "    \"\"\"\n",
    "    a = generate_input_seq(max_symbol,input_length)\n",
    "    fa = func_to_learn(a)\n",
    "    a = [init_symbol] + a + [term_symbol]\n",
    "    a = a + [term_symbol for k in range(total_length-len(a))]\n",
    "    a_onehot = [one_hots[e] for e in a]\n",
    "    \n",
    "    # If the output is too long to fit in the buffer, truncate it\n",
    "    if( len(fa) + input_length + 1 > total_length ):\n",
    "        fa = fa[:total_length-input_length-1]\n",
    "        \n",
    "    fa = [term_symbol for k in range(input_length+1)] + fa + \\\n",
    "                [term_symbol for k in range(total_length-(input_length+1)-len(fa))]\n",
    "    fa_onehot = [one_hots[e] for e in fa]\n",
    "    \n",
    "    return a, fa, np.array(a_onehot), np.array(fa_onehot)\n",
    "\n",
    "error_means = []\n",
    "epoch_error_means = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences. Each\n",
    "        # batch has a fixed length of the sequences. Recall that all input seqs\n",
    "        # have an initial and terminal symbol, so if seq_length = 10 then there\n",
    "        # are eight positions for the \"content\" symbols\n",
    "        \n",
    "        # Our version of curriculum training says: spend the first half\n",
    "        # of the epochs ramping up to the full training set. Assuming that\n",
    "        # epoch > N we divide allocate each integer in [seq_length_min,N]\n",
    "        # an equal portion of the first half of the epochs.\n",
    "        if( use_curriculum == True ):\n",
    "            if( 2 * i > epoch ):\n",
    "                seq_length_max = N\n",
    "            else:\n",
    "                curriculum_band = max(1,int(epoch/(2*(N - seq_length_min))))\n",
    "                seq_length_max = min(seq_length_min + int(i/curriculum_band),N)\n",
    "        else:\n",
    "            seq_length_max = N\n",
    "            \n",
    "        seq_length = random.randint(seq_length_min,seq_length_max)\n",
    "        \n",
    "        # Hack: if we are on the final batch of the final epoch, force\n",
    "        # it to use the full sequence length, so we get a good visualisation\n",
    "        if( i + 1 == epoch and j + 1 == no_of_batches ):\n",
    "            seq_length = N\n",
    "        \n",
    "        for z in range(batch_size):\n",
    "            a, fa, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=N+N_out)\n",
    "            \n",
    "            inp.append(a_onehot)\n",
    "            out.append(fa_onehot)\n",
    "            \n",
    "            # Record the first sequence in the last batch of the last epoch\n",
    "            if( i == epoch - 1 and j == no_of_batches - 1 and z == 0):\n",
    "                final_seq = a\n",
    "                final_seq_output = fa\n",
    "        \n",
    "        # An annoying thing here is that we cannot use a list as a key in a \n",
    "        # dictionary. The workaround we found on StackOverflow here:\n",
    "        # http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "        feed_dict = {}\n",
    "        \n",
    "        for d in range(N + N_out):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N + N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "\n",
    "        ##### Do gradient descent #####\n",
    "        mean_error_val,_ = sess.run([mean_error,minimize], feed_dict)\n",
    "        ###############################\n",
    "        \n",
    "        error_means.append(mean_error_val)\n",
    "    \n",
    "    epoch_error = np.mean(error_means[-no_of_batches:])\n",
    "    epoch_error_means.append(epoch_error)\n",
    "    \n",
    "    # Print the mean error of the final batch in the epoch\n",
    "    print_str = \"Epoch - \" + str(i+1) + \", mean error - \" + str(epoch_error)\n",
    "    \n",
    "    if( use_curriculum == True ):\n",
    "        print_str = print_str + \", training at max length - \" + str(seq_length_max)\n",
    "        \n",
    "    print(print_str)\n",
    "\n",
    "# For the final batch of the final epoch, we record the memory states as well\n",
    "seq_length_for_vis = seq_length - 2\n",
    "interps_val = sess.run(interps,feed_dict)\n",
    "m2_val, m3_val, m4_val = sess.run([m2,m3,m4],feed_dict)            \n",
    "r1_val, w1_val = sess.run([read_addresses,write_addresses],feed_dict)\n",
    "r2_val, w2_val = sess.run([read_addresses2,write_addresses2],feed_dict)\n",
    "r3_val, w3_val = sess.run([read_addresses3,write_addresses3],feed_dict)\n",
    "r4_val, w4_val = sess.run([read_addresses4,write_addresses4],feed_dict)\n",
    "errors_mask_val = sess.run(errors_mask,feed_dict)\n",
    "\n",
    "mask_val = sess.run(tf.cast(mask,tf.int64),feed_dict)\n",
    "predicted_seq = [tf.argmax(prediction[i], 1) for i in range(N + N_out)]\n",
    "predicted_seq_val = sess.run(predicted_seq,feed_dict)\n",
    "final_seq_pred_0 = [a[0] for a in predicted_seq_val]\n",
    "final_seq_pred = []\n",
    "\n",
    "for i in range(len(mask_val)):\n",
    "    if( mask_val[i] == 1.0 ):\n",
    "        final_seq_pred.append(final_seq_pred_0[i])\n",
    "    else:\n",
    "        final_seq_pred.append(9)\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took \" + str(int(time.time() - pre_train_time)) + \" seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length used for visualisations - 18\n",
      "\n",
      "Sequence used for visualisations is (Note: initial symbol is 8, terminal symbol is 9)\n",
      "[8, 1, 8, 4, 6, 1, 6, 1, 7, 3, 5, 0, 5, 2, 1, 1, 6, 3, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Correct output for this sequence:\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 6, 1, 6, 1, 7, 3, 5, 0, 5, 2, 1, 1, 6, 3, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Predicted output for this sequence\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Mask for output\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      "\n",
      "Error probabilities for final batch\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98799998, 0.99599999, 0.98400003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.77999997, 0.77999997, 0.57599998, 0.57599998, 0.57599998, 0.57599998, 0.57599998, 0.57599998, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAQPCAYAAABGG5mEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d36a590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 1 #\n",
    "###########################\n",
    "\n",
    "print(\"Sequence length used for visualisations - \" + str(seq_length_for_vis))\n",
    "print(\"\")\n",
    "print(\"Sequence used for visualisations is (Note: initial symbol is \" + str(init_symbol) + \", terminal symbol is \" + str(term_symbol) + \")\")\n",
    "print(final_seq)\n",
    "print(\"\")\n",
    "print(\"Correct output for this sequence:\")\n",
    "print(final_seq_output)\n",
    "print(\"\")\n",
    "print(\"Predicted output for this sequence\")\n",
    "print(final_seq_pred)\n",
    "print(\"\")\n",
    "print(\"Mask for output\")\n",
    "print(mask_val)\n",
    "print(\"\")\n",
    "print(\"Error probabilities for final batch\")\n",
    "print(errors_mask_val)\n",
    "print(\"\")\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 9, 13\n",
    "fig_num = 0\n",
    "\n",
    "# RING 1\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "plt.figure(fig_num)\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "ax1.imshow(np.stack(w1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax1.set_title('Write address (ring 1)')\n",
    "ax1.set_xlabel('position')\n",
    "ax1.set_ylabel('time')\n",
    "\n",
    "ax2.imshow(np.stack(r1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax2.set_title('Read address (ring 1)')\n",
    "ax2.set_xlabel('position')\n",
    "ax2.set_ylabel('time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 2 #\n",
    "###########################\n",
    "\n",
    "if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 2)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 2)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Assume that powers2_on_1 has three entries we can use as colour channels\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 2)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    max_xticks = 2\n",
    "    xloc = plt.MaxNLocator(max_xticks)\n",
    "\n",
    "    ax.imshow(np.stack(interps_val), cmap='bone', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title('Interpolation')\n",
    "    ax.set_xlabel('direct vs indirect')\n",
    "    ax.set_ylabel('time')\n",
    "    ax.xaxis.set_major_locator(xloc)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# VISUALISATIONS - OTHER RINGS #\n",
    "################################\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 3)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 3)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 3)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 4)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 4)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax6 = plt.subplot(1,1,1)    \n",
    "    ax6.imshow(np.stack(m4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax6.set_title('Memory contents (ring 4)')\n",
    "    ax6.set_xlabel('position')\n",
    "    ax6.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAUKCAYAAABblriAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1940889d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# VISUALISATIONS - ERROR #\n",
    "##########################\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "\n",
    "plt.figure(fig_num)\n",
    "ax = plt.subplot(1,1,1)\n",
    "sc = pandas.Series(error_means)\n",
    "ma = sc.rolling(window=500).mean()\n",
    "ax.plot(sc.index, sc, color='lightgray')\n",
    "ax.plot(ma.index, ma, color='red')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(sc.index.min(), sc.index.max())\n",
    "ax.set_title('Error')\n",
    "ax.set_xlabel('batch')\n",
    "ax.set_ylabel('error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on sequences of length 23\n",
      "\n",
      "Batch - 1, Mean error - 0.5407\n",
      "Batch - 2, Mean error - 0.4995\n",
      "Batch - 3, Mean error - 0.5473\n",
      "Batch - 4, Mean error - 0.5421\n",
      "\n",
      "###########\n",
      "# Summary #\n",
      "###########\n",
      "\n",
      "model         - ntm\n",
      "task name     - variable pattern 2\n",
      "epochs        - 2\n",
      "num_classes   - 10\n",
      "N             - 20\n",
      "Ntest         - 25\n",
      "# weights     - 18958\n",
      "\n",
      "\n",
      "error train(test) - 0.509073 (0.5324)\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "# Set up test graph\n",
    "rnn_outputs_test = []\n",
    "reuse = True\n",
    "for i in range(Ntest + Ntest_out):\n",
    "    output, state = cell(inputs_test[i],state,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "\n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size])\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.log_softmax(logit) for logit in logits_test] \n",
    "term_detector = [tf.not_equal(tf.argmax(targets_test[i],1),term_symbol) for i in range(Ntest + Ntest_out)]\n",
    "mask = [tf.reduce_max(tf.cast(m, tf.float32)) for m in term_detector]\n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest + Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "errors_test_mask = [errors_test[i] * mask[i] for i in range(Ntest + Ntest_out)]\n",
    "mean_error_test = tf.add_n(errors_test_mask)\n",
    "mean_error_test /= tf.add_n(mask)\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "\n",
    "seq_length = Ntest\n",
    "print(\"Testing on sequences of length \" + str(seq_length-2))\n",
    "print(\"\")\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    for z in range(batch_size):\n",
    "        a, fa, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=Ntest+Ntest_out)\n",
    "            \n",
    "        inp.append(a_onehot)\n",
    "        out.append(fa_onehot)        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = sess.run(mean_error_test, feed_dict)\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"epochs        - \" + str(epoch))\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"error train(test) - \" + str(epoch_error_means[-1]) + \" (\" + str(final_error) + \")\")\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
