{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of linear logic recurrent neural network\n",
    "#\n",
    "# The architecture is a modified RNN, see the paper \"Linear logic and recurrent neural networks\".\n",
    "# Our inputs are sequences of symbols taken from an alphabet of size num_classes. The length\n",
    "# of the sequences is N. Our outputs are also sequences of length N from the same alphabet.\n",
    "#\n",
    "# Here \"symbol\" means a one hot vector.\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# GLOBAL FLAGS\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, pattern_ntm_alt\n",
    "task                  = 'copy' # copy, repeat copy, pattern\n",
    "epoch                 = 200 # number of training epochs, default to 200\n",
    "num_classes           = 4 # number of symbols, INCLUDING initial and terminal symbols\n",
    "N                     = 22 # length of input sequences for training, default to 20, INCLUDING initial and terminal symbols\n",
    "Ntest                 = 22 # length of sequences for testing, default to N, INCLUDING initial and terminal symbols\n",
    "batch_size            = 500 # default to 500 (too large does not fit on GPUs)\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "memory_address_size   = 20 # number of memory locations, default 20\n",
    "memory_content_size   = 5 # size of vector stored at a memory location, default 5\n",
    "powers_ring1          = [0,-1,1] # powers of R used on ring 1, default [0,-1,1]\n",
    "powers_ring2          = [0,-1,1] # powers of R used on ring 2, default [0,-1,1]\n",
    "model_optimizer       = 'rmsprop' # adam, rmsprop, default to rmsprop\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "\n",
    "training_percent      = 0.01 # percentage used for training, default 0.01\n",
    "num_training          = int(training_percent * (num_classes-2)**N)\n",
    "num_test              = num_training\n",
    "\n",
    "init_symbol           = num_classes - 2\n",
    "term_symbol           = num_classes - 1\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "is mapped to\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "if( task == 'repeat copy' ):\n",
    "    pattern = [0,1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "##############\n",
    "# PATTERN TASK\n",
    "if( task == 'pattern' ):\n",
    "    pattern = [1,0,0,2,0]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 2 * (N - 2)\n",
    "    Ntest_out = 2 * (Ntest - 2)\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = [random.randint(0,num_classes-3) for i in range(N)]\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "state_size = 0\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size = controller_state_size + 2*memory_address_size + memory_address_size * memory_content_size\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,memory_address_size,memory_content_size, powers_ring1)\n",
    "    \n",
    "    ra = [0.0]*memory_address_size\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,memory_address_size]) + ra\n",
    "    \n",
    "    # DEBUG at the moment the read and write addresses are not distributions, i.e. they do not\n",
    "    # sum to 1, but after one step the gamma sharpening will normalise them. We should probably start\n",
    "    # with things that sum to 1, though.\n",
    "    init_controller_state = tf.truncated_normal([batch_size, controller_state_size], 0.0, 1e-6, dtype=tf.float32)\n",
    "    # was tf.truncated_normal([batch_size, controller_state_size], 0.0, 1e-6, dtype=tf.float32)\n",
    "    init_read_address = tf.random_uniform([batch_size, memory_address_size], 0.0, 1e-6) + \\\n",
    "                        tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size])\n",
    "    # was was tf.truncated_normal([batch_size, memory_address_size], 0.0, 0.01, dtype=tf.float32)\n",
    "    # was tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size])\n",
    "    init_write_address = tf.random_uniform([batch_size, memory_address_size], 0.0, 1e-6) + \\\n",
    "                        tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size])\n",
    "    # was tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,memory_address_size])\n",
    "    init_memory = tf.truncated_normal([batch_size, memory_address_size*memory_content_size], 0.0, 1e-6, dtype=tf.float32)\n",
    "    # was tf.constant(1e-6,dtype=tf.float32,shape=[batch_size,memory_address_size*memory_content_size])\n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    # DEBUG we got convergence with 0.01 and e,a both on softmax\n",
    "    \n",
    "#############\n",
    "# PATTERN NTM\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n",
    "    \n",
    "#################\n",
    "# PATTERN NTM ALT\n",
    "if( use_model == 'pattern_ntm_alt' ):\n",
    "    state_size = controller_state_size + 4*memory_address_size + \\\n",
    "                memory_address_size * memory_content_size + \\\n",
    "                memory_address_size * len(powers_ring1)\n",
    "\n",
    "    cell = ntm.PatternNTM_alt(state_size,input_size,controller_state_size,\n",
    "                          memory_address_size,memory_content_size, powers_ring1, powers_ring2)\n",
    "    \n",
    "    state = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_63/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_62/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_61/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_60/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_59/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_58/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_57/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_56/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_55/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_54/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_53/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_52/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_51/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_50/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_49/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_48/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_47/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_46/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_45/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_44/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_42/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_40/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_38/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_36/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_34/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_32/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_30/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_28/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_26/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_24/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_22/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_20/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_18/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_16/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_14/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(500, 240) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "# inputs, we create N of them, each of shape [None,input_size], one for each position in the sequence\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "write_addresses = []\n",
    "gamma_writes = []\n",
    "gamma_reads = []\n",
    "\n",
    "for i in range(N):\n",
    "    # Store read and write addresses for later logging\n",
    "    h0, curr_read, curr_write, _ = tf.split(state, [controller_state_size,memory_address_size,memory_address_size,-1], 1)\n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    \n",
    "    # DEBUG, getting gammas\n",
    "    with tf.variable_scope(\"NTM\",reuse=True):\n",
    "        W_gamma_write = tf.get_variable(\"W_gamma_write\", [controller_state_size,1])\n",
    "        B_gamma_write = tf.get_variable(\"B_gamma_write\", [])\n",
    "        gamma_write = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_write) + B_gamma_write) # shape [batch_size,1]\n",
    "        \n",
    "        W_gamma_read = tf.get_variable(\"W_gamma_read\", [controller_state_size,1])\n",
    "        B_gamma_read = tf.get_variable(\"B_gamma_read\", [])\n",
    "        gamma_read = 1.0 + tf.nn.relu(tf.matmul(h0,W_gamma_read) + B_gamma_read) # shape [batch_size,1]\n",
    "\n",
    "    gamma_writes.append(gamma_write[0,:])\n",
    "    gamma_reads.append(gamma_read[0,:])\n",
    "    reuse = True\n",
    "\n",
    "# We only start recording the outputs of the controller once we have\n",
    "# finished feeding in the input. We feed terminal symbols as input in the second phase.\n",
    "\n",
    "term_symbol_tensor = tf.constant(np.zeros([batch_size,input_size]) + one_hots[term_symbol],\n",
    "                                 dtype=tf.float32,\n",
    "                                 shape=[batch_size,input_size])\n",
    "\n",
    "rnn_outputs = []\n",
    "for i in range(N_out):\n",
    "    output, state = cell(term_symbol_tensor,state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * tf.log(prediction[i])) for i in range(N_out)]\n",
    "\n",
    "if( model_optimizer == 'adam' ):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "elif( model_optimizer == 'rmsprop' ):\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-4,decay=0.9,momentum=0.9)\n",
    "\n",
    "cross_entropy = -tf.add_n(ce)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "mean_error = tf.scalar_mul(np.true_divide(1,N_out), tf.add_n(errors))\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.00000000e+00   3.53630782e-07   7.19669231e-07   8.73835063e-07\n",
      "   7.09095616e-07   5.31813726e-07   7.70769816e-07   9.66190100e-07\n",
      "   7.61036063e-07   8.75353237e-07   7.20856292e-07   3.66230836e-07\n",
      "   2.00890653e-07   5.62357172e-07   6.30552904e-07   1.22041939e-07\n",
      "   8.03492640e-07   3.04279553e-07   8.25753432e-07   2.92869800e-07]\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.27658629]\n",
      "Write gamma - [ 1.2013042]\n",
      "Write address -\n",
      "[  3.33330035e-01   3.33329529e-01   6.49037702e-07   7.67524512e-07\n",
      "   7.04906654e-07   6.70551970e-07   7.56249335e-07   8.32655871e-07\n",
      "   8.67516462e-07   7.85739530e-07   6.54139171e-07   4.29320892e-07\n",
      "   3.76488515e-07   4.64595047e-07   4.38312355e-07   5.18689717e-07\n",
      "   4.09933591e-07   6.44501029e-07   4.74295661e-07   3.33329916e-01]\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.23580325]\n",
      "Write address -\n",
      "[  3.61383140e-01   2.16453984e-01   8.40715021e-02   5.55979902e-08\n",
      "   5.56913093e-08   5.55923094e-08   6.00208452e-08   6.62360691e-08\n",
      "   6.68841764e-08   6.06869932e-08   4.67534207e-08   3.45094513e-08\n",
      "   2.97967677e-08   3.03490530e-08   3.41874546e-08   3.27204539e-08\n",
      "   3.85351306e-08   3.78292917e-08   1.01449341e-01   2.36641258e-01]\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.01360309]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  2.88419276e-01   2.22121730e-01   8.24562013e-02   1.79491583e-02\n",
      "   1.61471891e-09   1.67560066e-09   1.80673065e-09   1.93581107e-09\n",
      "   1.93176097e-09   1.68006986e-09   1.30169941e-09   9.68724767e-10\n",
      "   8.02068467e-10   8.03737132e-10   8.26483770e-10   9.24607557e-10\n",
      "   9.53915058e-10   2.67847031e-02   1.07681349e-01   2.54587561e-01]\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.1053797]\n",
      "Write address -\n",
      "[  2.54217863e-01   2.17355862e-01   1.33588344e-01   4.47195657e-02\n",
      "   8.77885520e-03   1.68074266e-09   1.77696857e-09   1.87159999e-09\n",
      "   1.86671878e-09   1.70241421e-09   1.39809053e-09   1.08720211e-09\n",
      "   8.84023688e-10   8.08978218e-10   8.41488046e-10   8.84419982e-10\n",
      "   7.13253673e-03   3.52265052e-02   1.07235014e-01   1.91745475e-01]\n",
      "\n",
      "Step 5 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  2.30214804e-01   2.21600428e-01   1.47095293e-01   6.73485249e-02\n",
      "   1.74385738e-02   2.41590315e-03   2.57953825e-10   2.69641254e-10\n",
      "   2.69356509e-10   2.47920851e-10   2.08065801e-10   1.63637645e-10\n",
      "   1.30330052e-10   1.14944734e-10   1.13630723e-10   1.04342564e-03\n",
      "   8.22569896e-03   3.55797857e-02   9.38126743e-02   1.75224915e-01]\n",
      "\n",
      "Step 6 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.06611884]\n",
      "Write address -\n",
      "[  2.09515601e-01   2.02760354e-01   1.48526847e-01   7.92001262e-02\n",
      "   2.95760892e-02   6.68229302e-03   7.99213885e-04   2.65691996e-10\n",
      "   2.63210398e-10   2.43409515e-10   2.08316545e-10   1.68638631e-10\n",
      "   1.36869710e-10   1.19651872e-10   3.03760724e-04   2.78913975e-03\n",
      "   1.38129890e-02   4.34833616e-02   9.82490629e-02   1.64301217e-01]\n",
      "\n",
      "Step 7 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.95360377e-01   1.94462553e-01   1.50637120e-01   8.94931331e-02\n",
      "   3.91555578e-02   1.19833080e-02   2.22636829e-03   2.10253784e-04\n",
      "   6.88987895e-11   6.38856537e-11   5.52846900e-11   4.53821633e-11\n",
      "   3.69903760e-11   5.70769589e-05   6.78618730e-04   4.17786604e-03\n",
      "   1.63058732e-02   4.55693640e-02   9.53286067e-02   1.54353917e-01]\n",
      "\n",
      "Step 8 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.5730114]\n",
      "Write address -\n",
      "[  1.74000055e-01   1.86050355e-01   1.60888150e-01   1.10877231e-01\n",
      "   5.96501306e-02   2.40408350e-02   6.85719028e-03   1.20892900e-03\n",
      "   1.08589273e-04   6.47328371e-11   5.77212687e-11   4.87969248e-11\n",
      "   1.15597240e-05   1.53478293e-04   1.06630870e-03   4.82688146e-03\n",
      "   1.59688331e-02   4.05333713e-02   8.15838650e-02   1.32174224e-01]\n",
      "\n",
      "Step 9 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.82308733e-01   2.17212573e-01   1.93480954e-01   1.27079919e-01\n",
      "   5.99517860e-02   1.95734370e-02   4.14444553e-03   5.17924724e-04\n",
      "   3.11157564e-05   6.49670312e-07   2.76256646e-16   5.56966517e-09\n",
      "   3.74684248e-07   9.18061505e-06   1.17632721e-04   9.39257618e-04\n",
      "   5.06738899e-03   1.94701180e-02   5.48240282e-02   1.15270510e-01]\n",
      "\n",
      "Step 10 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.20532167]\n",
      "Write address -\n",
      "[  1.54943153e-01   1.95494741e-01   1.93534464e-01   1.48382023e-01\n",
      "   8.63865390e-02   3.70534360e-02   1.12282149e-02   2.24810489e-03\n",
      "   2.69585667e-04   1.57979612e-05   3.26490266e-07   6.85766253e-08\n",
      "   1.75947446e-06   2.41010803e-05   2.09756967e-04   1.26347831e-03\n",
      "   5.56651037e-03   1.85561739e-02   4.78860736e-02   9.69357193e-02]\n",
      "\n",
      "Step 11 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.50305212e-01   1.96328968e-01   1.99191630e-01   1.55419394e-01\n",
      "   9.17096585e-02   3.99219729e-02   1.23603549e-02   2.58368184e-03\n",
      "   3.36517522e-04   2.41891066e-05   7.57551334e-07   4.87126961e-08\n",
      "   9.32137596e-07   1.36148756e-05   1.29633001e-04   8.60555621e-04\n",
      "   4.15885029e-03   1.50748529e-02   4.17998321e-02   8.97793025e-02]\n",
      "\n",
      "Step 12 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 2.10803175]\n",
      "Write address -\n",
      "[  1.40649974e-01   1.79876730e-01   1.85707688e-01   1.53775960e-01\n",
      "   1.00925021e-01   5.15337698e-02   1.99270882e-02   5.61388116e-03\n",
      "   1.09089632e-03   1.34702714e-04   9.34594391e-06   5.65069229e-07\n",
      "   4.19652361e-06   4.17505362e-05   2.93342309e-04   1.52150181e-03\n",
      "   6.01650123e-03   1.85571481e-02   4.53780554e-02   8.89419243e-02]\n",
      "\n",
      "Step 13 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.49470866e-01   2.35430270e-01   2.48395279e-01   1.73957214e-01\n",
      "   7.94816315e-02   2.30612773e-02   4.08460246e-03   4.17579431e-04\n",
      "   2.27598030e-05   5.90379557e-07   6.17548856e-09   4.51662839e-11\n",
      "   5.95390903e-10   4.03449008e-08   1.49289497e-06   3.19329847e-05\n",
      "   4.15286107e-04   3.40802502e-03   1.81294307e-02   6.36917055e-02]\n",
      "\n",
      "Step 14 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.84489727]\n",
      "Write address -\n",
      "[  1.21058136e-01   1.93292812e-01   2.27773756e-01   1.94900751e-01\n",
      "   1.17918573e-01   4.87639979e-02   1.32367080e-02   2.24471651e-03\n",
      "   2.23281648e-04   1.19732022e-05   3.07863388e-07   3.32568062e-09\n",
      "   7.73316788e-09   2.90995501e-07   6.42445320e-06   8.77428392e-05\n",
      "   7.75445136e-04   4.60582413e-03   1.90068223e-02   5.60924560e-02]\n",
      "\n",
      "Step 15 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.04518747]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.21128060e-01   2.38154039e-01   2.84762293e-01   2.03565404e-01\n",
      "   8.46220478e-02   1.97024308e-02   2.44616764e-03   1.51753702e-04\n",
      "   4.30862201e-06   4.96480297e-08   1.96698907e-10   2.30686076e-13\n",
      "   5.92381829e-13   1.86095042e-10   2.49445034e-08   1.54176428e-06\n",
      "   4.73561813e-05   7.71231484e-04   7.03813229e-03   3.76051441e-02]\n",
      "\n",
      "Step 16 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 2.1852529]\n",
      "Write address -\n",
      "[  1.34069234e-01   2.21197560e-01   2.48182446e-01   1.89436957e-01\n",
      "   9.66098458e-02   3.16800512e-02   6.31534634e-03   7.13331217e-04\n",
      "   4.19566459e-05   1.15911314e-06   1.31917304e-08   5.22009554e-11\n",
      "   5.59592372e-11   7.53949525e-09   4.71913864e-07   1.48391446e-05\n",
      "   2.51689606e-04   2.45385175e-03   1.45228934e-02   5.45083210e-02]\n",
      "\n",
      "Step 17 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.00629807]\n",
      "Write gamma - [ 1.02666509]\n",
      "Write address -\n",
      "[  1.41289636e-01   2.98180133e-01   3.12711924e-01   1.64152130e-01\n",
      "   4.24008705e-02   5.15194004e-03   2.71891651e-04   5.52246047e-06\n",
      "   3.66216248e-08   6.44151329e-11   2.33090067e-14   1.29348797e-18\n",
      "   1.94994719e-18   1.66641112e-14   3.24149145e-11   1.67989906e-08\n",
      "   2.69374937e-06   1.52342225e-04   3.38723115e-03   3.22936885e-02]\n",
      "\n",
      "Step 18 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 2.28395581]\n",
      "Write address -\n",
      "[  9.92540121e-02   2.06874356e-01   2.83776343e-01   2.36105844e-01\n",
      "   1.08506747e-01   2.55241375e-02   2.85027502e-03   1.37254247e-04\n",
      "   2.49883783e-06   1.44677790e-08   2.14759113e-11   6.29037753e-15\n",
      "   1.14313216e-15   2.72202118e-12   1.67011893e-09   3.08648453e-07\n",
      "   1.97806858e-05   4.98280628e-04   5.54664712e-03   3.09035219e-02]\n",
      "\n",
      "Step 19 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.42747355]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  6.47166148e-02   2.32570976e-01   3.68345916e-01   2.50726968e-01\n",
      "   6.86002448e-02   6.45538839e-03   1.67333652e-04   9.29532348e-07\n",
      "   8.32591329e-10   8.51997441e-14   6.52741146e-19   2.25506465e-25\n",
      "   2.74734176e-27   6.39234030e-21   9.70821307e-16   1.33519567e-11\n",
      "   2.25712959e-08   6.31647299e-06   4.01115394e-04   8.00820906e-03]\n",
      "\n",
      "Step 20 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.40591824]\n",
      "Write address -\n",
      "[  6.37620389e-02   1.70581728e-01   2.80934930e-01   2.79910654e-01\n",
      "   1.49816960e-01   3.66122164e-02   3.29570496e-03   8.42866866e-05\n",
      "   4.66760895e-07   4.17861523e-10   4.27574100e-14   3.27575930e-19\n",
      "   1.04755245e-21   1.59079312e-16   2.18815417e-12   3.70295949e-09\n",
      "   1.04255912e-06   6.78490032e-05   1.44947285e-03   1.34827616e-02]\n",
      "\n",
      "Step 21 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  8.00227821e-02   2.06648782e-01   3.02084714e-01   2.48166531e-01\n",
      "   1.14160791e-01   2.74394173e-02   2.77232332e-03   8.18924163e-05\n",
      "   4.52559789e-07   3.00965003e-10   1.55748319e-14   3.82550354e-20\n",
      "   3.95662432e-23   2.60061995e-17   9.00101066e-13   2.50943710e-09\n",
      "   9.01068631e-07   6.90315792e-05   1.69577787e-03   1.68566015e-02]\n",
      "Epoch - 1, Mean error of final batch in epoch - 0.0258\n",
      "Epoch - 2, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 3, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 4, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 5, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 6, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 7, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 8, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 9, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 10, Mean error of final batch in epoch - 0.0\n",
      "\n",
      "Step 0 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.01103008]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.00000024e+00   8.67959159e-07   4.58650476e-07   4.66978548e-07\n",
      "   1.81147698e-07   6.85122870e-07   4.39726122e-08   8.84170674e-07\n",
      "   6.83621977e-07   4.57684393e-07   9.55648943e-07   5.00165207e-08\n",
      "   6.84178929e-07   3.22434317e-07   1.27699252e-07   9.48682896e-07\n",
      "   3.91825438e-07   7.78434412e-07   7.73228862e-07   5.90301745e-08]\n",
      "\n",
      "Step 1 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.36547863]\n",
      "Write gamma - [ 1.1364429]\n",
      "Write address -\n",
      "[  3.34068924e-01   3.36955994e-01   5.99304258e-07   3.70139048e-07\n",
      "   4.43248780e-07   3.04382155e-07   5.36407697e-07   5.35078755e-07\n",
      "   6.76865284e-07   6.97624046e-07   4.89925242e-07   5.63791616e-07\n",
      "   3.51485880e-07   3.80261696e-07   4.63390592e-07   4.88851242e-07\n",
      "   7.06638787e-07   6.46444107e-07   5.40028111e-07   3.28966260e-01]\n",
      "\n",
      "Step 2 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.27433157]\n",
      "Write address -\n",
      "[  3.52582097e-01   2.25775182e-01   1.01497941e-01   7.90953933e-08\n",
      "   6.09016197e-08   7.08571335e-08   7.70470052e-08   1.00879419e-07\n",
      "   1.11709838e-07   1.08852689e-07   1.01027943e-07   7.90137094e-08\n",
      "   7.17154691e-08   6.54972752e-08   7.41997823e-08   9.49747303e-08\n",
      "   1.07337598e-07   1.10623425e-07   9.81529653e-02   2.21990496e-01]\n",
      "\n",
      "Step 3 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.01596284]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  2.85332561e-01   2.20422044e-01   8.07143077e-02   1.89584885e-02\n",
      "   1.23151722e-09   1.22706556e-09   1.56520863e-09   1.87406801e-09\n",
      "   2.09476680e-09   2.07469886e-09   1.77303150e-09   1.50271184e-09\n",
      "   1.24556221e-09   1.24092459e-09   1.45130752e-09   1.76958148e-09\n",
      "   2.03943218e-09   2.78275032e-02   1.08085141e-01   2.58660018e-01]\n",
      "\n",
      "Step 4 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.37123382]\n",
      "Write address -\n",
      "[  2.57797152e-01   2.28140742e-01   1.44919872e-01   4.90007810e-02\n",
      "   1.03819789e-02   1.29685540e-09   1.44155510e-09   1.74889081e-09\n",
      "   1.96991112e-09   2.02560124e-09   1.88438642e-09   1.59952340e-09\n",
      "   1.38545775e-09   1.28536881e-09   1.39949274e-09   1.64903879e-09\n",
      "   5.54275513e-03   2.85746288e-02   9.41266268e-02   1.81515440e-01]\n",
      "\n",
      "Step 5 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  2.26850003e-01   2.74660438e-01   1.96934074e-01   9.08231363e-02\n",
      "   1.90875009e-02   2.06743646e-03   1.43378473e-12   1.70985069e-12\n",
      "   2.09500668e-12   2.30691855e-12   2.25022128e-12   1.96398540e-12\n",
      "   1.59995953e-12   1.39615142e-12   1.39064454e-12   1.10915498e-04\n",
      "   1.49942946e-03   1.14126876e-02   4.65966985e-02   1.29957616e-01]\n",
      "\n",
      "Step 6 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.32555878]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.76848873e-01   2.35502884e-01   2.27357522e-01   1.42811313e-01\n",
      "   5.87338582e-02   1.17557216e-02   1.21274462e-03   1.60297687e-12\n",
      "   1.89937324e-12   2.17450667e-12   2.24255749e-12   2.07984606e-12\n",
      "   1.78435717e-12   1.51491677e-12   1.58572238e-05   2.44364433e-04\n",
      "   2.10220204e-03   1.06277773e-02   3.78758274e-02   9.49110389e-02]\n",
      "\n",
      "Step 7 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.0885191]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.32562399e-01   1.97626650e-01   2.22065166e-01   1.85606346e-01\n",
      "   1.05803460e-01   3.99901755e-02   7.69125577e-03   7.62395852e-04\n",
      "   1.74692910e-12   2.00992456e-12   2.17973708e-12   2.14574192e-12\n",
      "   1.93693217e-12   1.95302550e-06   3.40321712e-05   3.29529576e-04\n",
      "   1.98430219e-03   8.62409920e-03   2.77708843e-02   6.91473857e-02]\n",
      "\n",
      "Step 8 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.32971406]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  1.05279274e-01   1.64544463e-01   2.04150453e-01   1.96193159e-01\n",
      "   1.42069265e-01   7.25416839e-02   2.47395057e-02   4.50671231e-03\n",
      "   4.22083423e-04   1.88474583e-12   2.08163543e-12   2.13944921e-12\n",
      "   2.34889583e-07   4.72989404e-06   5.18113447e-05   3.64951324e-04\n",
      "   1.86673377e-03   7.25088175e-03   2.21469905e-02   5.38670458e-02]\n",
      "\n",
      "Step 9 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.47684252]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  7.91807920e-02   1.31480455e-01   1.78482339e-01   1.95568427e-01\n",
      "   1.68803796e-01   1.11192241e-01   5.26235998e-02   1.67737119e-02\n",
      "   2.94033112e-03   2.64747621e-04   1.96413719e-12   2.43738985e-08\n",
      "   5.53958046e-07   6.79559344e-06   5.47712079e-05   3.24361550e-04\n",
      "   1.48341199e-03   5.41934092e-03   1.60948113e-02   3.93054634e-02]\n",
      "\n",
      "Step 10 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.20052326]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  6.48140386e-02   1.09526195e-01   1.55127734e-01   1.82327494e-01\n",
      "   1.75204009e-01   1.34397611e-01   7.96279311e-02   3.44715938e-02\n",
      "   1.01529844e-02   1.69619895e-03   1.45419253e-04   8.72888535e-08\n",
      "   1.16236129e-06   1.02795420e-05   6.72621318e-05   3.43279797e-04\n",
      "   1.41387142e-03   4.79558809e-03   1.35753322e-02   3.23019028e-02]\n",
      "\n",
      "Step 11 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  5.91954440e-02   9.88903493e-02   1.40745252e-01   1.69474423e-01\n",
      "   1.70757771e-01   1.41696572e-01   9.46156755e-02   4.91925292e-02\n",
      "   1.89302973e-02   5.00299875e-03   7.77266745e-04   6.19914936e-05\n",
      "   2.37506879e-06   1.68408314e-05   9.36010329e-05   4.22088371e-04\n",
      "   1.57842925e-03   4.96712560e-03   1.32759605e-02   3.03030182e-02]\n",
      "\n",
      "Step 12 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.13880634]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  5.70896566e-02   9.31505114e-02   1.31235346e-01   1.58808231e-01\n",
      "   1.63744748e-01   1.42208695e-01   1.02370739e-01   5.97188398e-02\n",
      "   2.73427088e-02   9.36480612e-03   2.22794944e-03   3.21339263e-04\n",
      "   2.83537647e-05   2.85562928e-05   1.38071831e-04   5.56414016e-04\n",
      "   1.89821934e-03   5.54020610e-03   1.39300916e-02   3.02964840e-02]\n",
      "\n",
      "Step 13 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.23162615]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  5.43562509e-02   8.70793983e-02   1.21927537e-01   1.48629561e-01\n",
      "   1.56789705e-01   1.41921222e-01   1.08945452e-01   6.98001683e-02\n",
      "   3.65057699e-02   1.51044382e-02   4.71859146e-03   1.03624770e-03\n",
      "   1.48566178e-04   5.35453037e-05   1.88928461e-04   6.92021626e-04\n",
      "   2.18166970e-03   5.96721843e-03   1.42358961e-02   2.97178458e-02]\n",
      "\n",
      "Step 14 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.65161419]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[  5.07272370e-02   8.05554017e-02   1.12920225e-01   1.39293998e-01\n",
      "   1.50501296e-01   1.41493708e-01   1.14722773e-01   7.92652518e-02\n",
      "   4.59247530e-02   2.18258407e-02   8.24908633e-03   2.37069046e-03\n",
      "   4.93792701e-04   1.19300545e-04   2.32956299e-04   7.80465198e-04\n",
      "   2.31982768e-03   6.05092896e-03   1.39084151e-02   2.82440688e-02]\n",
      "\n",
      "Step 15 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.24326801]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.0493026   0.07693024  0.10688202  0.13189781  0.14404356  0.13849677\n",
      "  0.11643335  0.08481007  0.052884    0.02778098  0.01203026  0.00416872\n",
      "  0.00112199  0.00028999  0.00032126  0.00094148  0.00262883  0.00651441\n",
      "  0.01435205  0.02816961]\n",
      "\n",
      "Step 16 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.04932456  0.07543482  0.10341804  0.12684262  0.13876066  0.13483004\n",
      "  0.1157235   0.08710445  0.05696231  0.03197325  0.01516022  0.00594775\n",
      "  0.00189765  0.00056569  0.00046448  0.00115877  0.00304574  0.00720011\n",
      "  0.01524287  0.02894251]\n",
      "\n",
      "Step 17 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.55081868]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.05248139  0.0778033   0.10394335  0.1249245   0.13472058  0.12990713\n",
      "  0.11149408  0.08467084  0.0564709   0.03276276  0.01633513  0.00689743\n",
      "  0.0024527   0.0008515   0.00070142  0.00157214  0.00387057  0.00867774\n",
      "  0.01752991  0.0319327 ]\n",
      "\n",
      "Step 18 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.1690098]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.05654788  0.08089673  0.10486323  0.12299519  0.13026488  0.12422789\n",
      "  0.10628506  0.08120084  0.05507194  0.03291365  0.01717632  0.00775077\n",
      "  0.00304093  0.00122501  0.0010715   0.00220853  0.00507328  0.01073801\n",
      "  0.02060501  0.0358434 ]\n",
      "\n",
      "Step 19 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.74882579]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.05871499  0.08191432  0.10407478  0.12028398  0.12624212  0.1200399\n",
      "  0.10310072  0.07968074  0.0551476   0.0339793   0.01850758  0.00885487\n",
      "  0.00376892  0.00168497  0.00148753  0.00282852  0.00612603  0.01238209\n",
      "  0.02282977  0.03835136]\n",
      "\n",
      "Step 20 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.06312165  0.08509457  0.10497543  0.11840082  0.121933    0.11444256\n",
      "  0.09765862  0.07553849  0.0527612   0.03312404  0.01859594  0.00931353\n",
      "  0.00426736  0.00217212  0.00211969  0.00388145  0.00791678  0.01516694\n",
      "  0.02665036  0.0428655 ]\n",
      "\n",
      "Step 21 of the RNN run on the first input of first batch of this epoch\n",
      "Read gamma - [ 1.]\n",
      "Write gamma - [ 1.]\n",
      "Write address -\n",
      "[ 0.0660383   0.08672246  0.1046761   0.11604919  0.11804385  0.11000077\n",
      "  0.09372175  0.07282639  0.05145107  0.03292746  0.01901988  0.00992801\n",
      "  0.00485311  0.00273288  0.00281854  0.00496024  0.0096137   0.01761651\n",
      "  0.02976372  0.04623611]\n",
      "Epoch - 11, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 12, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 13, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 14, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 15, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 16, Mean error of final batch in epoch - 0.0\n",
      "Epoch - 17, Mean error of final batch in epoch - 0.0\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "# An annoying thing here is that we cannot use a list as a key in a \n",
    "# dictionary. The workaround we found on StackOverflow here:\n",
    "# http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "\n",
    "# epoch is a global var\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences\n",
    "        for z in range(batch_size):\n",
    "            # construct a sequence from 0,...,num_classes - 3 then append initial and terminal symbols\n",
    "            a = [random.randint(0,num_classes-3) for k in range(N-2)]\n",
    "            fa = func_to_learn(a)\n",
    "            a = [init_symbol] + a + [term_symbol]\n",
    "            a_onehot = [one_hots[e] for e in a]\n",
    "            fa_onehot = [one_hots[e] for e in fa]\n",
    "            inp.append(np.array(a_onehot))\n",
    "            out.append(np.array(fa_onehot))        \n",
    "        \n",
    "        feed_dict = {}\n",
    "        for d in range(N):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "        \n",
    "        # for the first batch in an epoch, we have some logging\n",
    "        if( j == 0 and i % 10 == 0 ):\n",
    "            gamma_reads_val, gamma_writes_val, read_addresses_val, write_addresses_val = sess.run([gamma_reads,gamma_writes,read_addresses,write_addresses],feed_dict)\n",
    "    \n",
    "            s = 0\n",
    "            for r in range(len(write_addresses_val)):\n",
    "                print(\"\")\n",
    "                print(\"Step \" + str(s) + \" of the RNN run on the first input of first batch of this epoch\")\n",
    "                print(\"Read gamma - \" + str(gamma_reads_val[r]))\n",
    "                print(\"Write gamma - \" + str(gamma_writes_val[r]))\n",
    "                print(\"Write address -\")\n",
    "                print(write_addresses_val[r])\n",
    "                s = s + 1\n",
    "        \n",
    "        # Do gradient descent\n",
    "        summary,_ = sess.run([merged_summaries,minimize], feed_dict)\n",
    "        \n",
    "        # Write out TensorBoard logs\n",
    "        file_writer.add_summary(summary)\n",
    "    current_mean = np.mean(sess.run(errors, feed_dict))\n",
    "    print(\"Epoch - \" + str(i+1) + \", Mean error of final batch in epoch - \" + str(current_mean))\n",
    "    \n",
    "    # DEBUG\n",
    "    #with tf.variable_scope(\"NTM\",reuse=True):\n",
    "    #    H = tf.get_variable(\"H\", [controller_state_size,controller_state_size])\n",
    "    #    print(sess.run(H))\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took\", time.time() - pre_train_time, \"seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Note that all the weights will be loaded from the saved training session\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest_out)]\n",
    "state_test = tf.truncated_normal([batch_size, state_size], 0.0, 0.01, dtype=tf.float32)\n",
    "\n",
    "# Set up test graph\n",
    "reuse = True\n",
    "for i in range(Ntest):\n",
    "    output, state = cell(inputs_test[i],state_test,'NTM',reuse)\n",
    "\n",
    "rnn_outputs_test = []\n",
    "for i in range(Ntest_out):\n",
    "    output, state = cell(tf.zeros([batch_size,input_size]),state_test,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "    \n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.softmax(logit) for logit in logits_test] \n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "# DEBUG\n",
    "#with tf.variable_scope(\"NTM\",reuse=True):\n",
    "#    H = tf.get_variable(\"H\", [controller_state_size,controller_state_size])\n",
    "#    print(sess.run(H))\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "#print(\"Number of batches: \" + str(no_of_batches))\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    # We sample each batch on the fly from the set of all sequences\n",
    "    for z in range(batch_size):\n",
    "        a = [random.randint(0,num_classes-3) for k in range(Ntest-2)]\n",
    "        fa = func_to_learn(a)\n",
    "        a = [init_symbol] + a + [term_symbol]\n",
    "        a_onehot = [one_hots[e] for e in a]\n",
    "        fa_onehot = [one_hots[e] for e in fa]\n",
    "        inp.append(np.array(a_onehot))\n",
    "        out.append(np.array(fa_onehot))        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = np.mean(sess.run(errors_test, feed_dict))\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "# The first three digits of this should match the printout for the\n",
    "# first three test output sequences given earlier\n",
    "#data = sess.run([tf.argmax(targets[0],1), tf.argmax(prediction[0],1)],feed_dict)\n",
    "\n",
    "#print(\"First digits of test outputs (actual)\")\n",
    "#print(data[0])\n",
    "#print(\"First digits of test outputs (predicted)\")\n",
    "#print(data[1])\n",
    "\n",
    "# print the mean of the errors in each digit for the test set.\n",
    "#incorrects = sess.run(errors, feed_dict)\n",
    "# print(incorrects)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"N_out         - \" + str(N_out))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"Ntest_out     - \" + str(Ntest_out))\n",
    "print(\"ring 1 powers - \" + str(powers_ring1))\n",
    "print(\"ring 2 powers - \" + str(powers_ring2))\n",
    "print(\"# epochs      - \" + str(epoch))\n",
    "print(\"optimizer     - \" + str(model_optimizer))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"(css,mas,mcs) - (\" + str(controller_state_size) + \",\" + str(memory_address_size) + \",\" + str(memory_content_size) + \")\")\n",
    "print(\"train percent - \" + str(training_percent))\n",
    "print(\"num_training  - \" + str(num_training) + \"/\" + str(num_classes**N))\n",
    "print(\"num_test      - \" + str(num_test) + \"/\" + str(num_classes**N))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"error         - \" + str(final_error))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
