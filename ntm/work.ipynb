{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "#\n",
    "# Implementation of the Linear Logic Recurrent Neural Network (LLRNN)\n",
    "#\n",
    "\n",
    "###################\n",
    "# HYPERPARAMETERS #\n",
    "###################\n",
    "\n",
    "use_model             = 'ntm' # ntm, pattern_ntm, mult_pattern_ntm\n",
    "task                  = 'copy' # copy, repeat copy, pattern i, mult pattern i\n",
    "epoch                 = 100 # number of training epochs, default to 100\n",
    "num_classes           = 10 # number of symbols, INCLUDING initial and terminal symbols, default 10\n",
    "N                     = 30 # length of input sequences for training, default to 30, INCLUDING initial and terminal symbols\n",
    "Ntest                 = 35 # length of sequences for testing, default to 35, INCLUDING initial and terminal symbols\n",
    "batch_size            = 250 # default 250\n",
    "controller_state_size = 100 # dimension of the internal state space of the controller, default 100\n",
    "LOG_DIR               = '/tmp/log' # default /tmp/log\n",
    "num_training          = 10000 # default 10000\n",
    "num_test              = num_training\n",
    "term_symbol           = num_classes - 1\n",
    "init_symbol           = num_classes - 2\n",
    "div_symbol            = num_classes - 3\n",
    "\n",
    "##################\n",
    "# MODEL SPECIFIC #\n",
    "##################\n",
    "\n",
    "ntm_memory_address_size   = 128 # number of memory locations, default 128\n",
    "ntm_memory_content_size   = 20 # size of vector stored at a memory location, default 20\n",
    "ntm_powers                = [0,-1,1] # powers of R used by controller, default [0,-1,1]\n",
    "\n",
    "pattern_ntm_powers               = [[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "pattern_ntm_powers_2_on_1        = [0,2,4] # allowed powers used by ring 2 to manipulate ring 1\n",
    "pattern_ntm_memory_address_sizes = [128, 128] # number of memory locations for the three rings\n",
    "pattern_ntm_memory_content_sizes = [20, 3] # size of content vector for each ring\n",
    "pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "mult_pattern_ntm_powers               = [[0,-1,1],[0,-1,1],[0,-1,1],[0,-1,1]] # powers used by controller on each ring resp.\n",
    "mult_pattern_ntm_powers_2_on_1        = [0,1,-1] # allowed powers used by rings 2,3 to manipulate ring 1\n",
    "mult_pattern_ntm_memory_address_sizes = [128, 20, 20, 10] # number of memory locations for the rings\n",
    "mult_pattern_ntm_memory_content_sizes = [20, 3, 3, 2] # size of content vector for each ring\n",
    "mult_pattern_ntm_direct_bias          = 1.0\n",
    "\n",
    "##########\n",
    "# NOTES\n",
    "#\n",
    "# 1. Always put the zero power first in powers_ring since the code assumes this is there\n",
    "# 2. The initial and terminal symbols are always from the end of the list of symbols, so they\n",
    "# are respectively num_classes - 2 and num_classes - 1. So the number of symbols which are\n",
    "# not initial or terminal is num_classes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# The next three lines are recommend by TF\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas\n",
    "import collections\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell_impl import _RNNCell as RNNCell\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "# Our libraries\n",
    "import ntm\n",
    "import seqhelper\n",
    "import learnfuncs\n",
    "\n",
    "assert use_model == 'ntm' or use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the chosen function, the sequence\n",
      "[4, 6, 4, 7, 4, 3, 6, 7]\n",
      "is mapped to\n",
      "[4, 6, 4, 4, 3, 3, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# SETUP TASKS\n",
    "#\n",
    "# Our sequences are of one-hot vectors, which we interpret as follows:\n",
    "#\n",
    "# [1.0, 0.0, 0.0] = 0\n",
    "# [0.0, 1.0, 0.0] = 1\n",
    "# [0.0, 0.0, 1.0] = 2 etc\n",
    "#\n",
    "# We write our sequences and functions referring to sequences of integers,\n",
    "# and then convert to one-hot vectors for integration with TF.\n",
    "\n",
    "# Below N_out and Ntest_out are the lengths of the outputs in both the training\n",
    "# and testing regimes respectively. Since outputs do not include the initial and terminal\n",
    "# symbols, these default to N - 2 and Ntest - 2 respectively.\n",
    "\n",
    "# Default sampling from space of inputs\n",
    "def generate_input_seq_default(max_symbol,input_length):\n",
    "    return [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "\n",
    "generate_input_seq = generate_input_seq_default\n",
    "\n",
    "###########\n",
    "# COPY TASK\n",
    "if( task == 'copy' ):\n",
    "    func_to_learn = learnfuncs.f_identity\n",
    "    N_out = N - 2\n",
    "    Ntest_out = Ntest - 2\n",
    "    seq_length_min = 4\n",
    "\n",
    "##################\n",
    "# REPEAT COPY TASK\n",
    "# put n zeros before the 1, for a copy task with n + 1 copies\n",
    "if( task == 'repeat copy' ):\n",
    "    no_of_copies = 2\n",
    "    pattern = [0]*(no_of_copies - 1) + [1]\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = no_of_copies * (N - 2)\n",
    "    Ntest_out = no_of_copies * (Ntest - 2)\n",
    "    seq_length_min = 4\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 1\n",
    "if( task == 'pattern 1' ):\n",
    "    # WARNING: for this task make sure seq_lengh_min is at least 4\n",
    "    pattern = [0,1,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,c,c,d,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = (N - 2) + divmod(N - 2, 2)[0] # N - 2 plus the number of times 2 divides N - 2\n",
    "    Ntest_out = (Ntest - 2) + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 4\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 2\n",
    "if( task == 'pattern 2' ):\n",
    "    # WARNING: for this task make sure seq_lengh_min is at least 4\n",
    "    pattern = [0,2] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = N - 2 + divmod(N - 2, 2)[0]\n",
    "    Ntest_out = Ntest - 2 + divmod(Ntest - 2, 2)[0]\n",
    "    seq_length_min = 4\n",
    "    \n",
    "################\n",
    "# PATTERN TASK 3\n",
    "if( task == 'pattern 3' ):\n",
    "    # WARNING: for this task make sure seq_lengh_min is at least 4\n",
    "    pattern = [0,2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,b,b,d,c,c,e,d,d,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = 4 + (N - 2 - 2) * 3\n",
    "    Ntest_out = 4 + (Ntest - 2 - 2) * 3\n",
    "    seq_length_min = 4\n",
    "\n",
    "################\n",
    "# PATTERN TASK 4\n",
    "if( task == 'pattern 4' ):\n",
    "    # WARNING: for this task make sure seq_lengh_min is at least 4\n",
    "    pattern = [0,2,1,2,-2,-1] # so (a,b,c,d,e,f,...) goes to (a,a,c,d,f,d,c,c,e,f,h,f,e,e,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 4\n",
    "\n",
    "################\n",
    "# PATTERN TASK 5\n",
    "if( task == 'pattern 5' ):\n",
    "    # WARNING: for this task make sure seq_lengh_min is at least 4\n",
    "    pattern = [4,1,1,-4] # so (a,b,c,d,e,f,...) goes to (a,e,f,g,k,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_repetitionpattern(s,pattern)\n",
    "    N_out = len(func_to_learn([0]*(N-2)))\n",
    "    Ntest_out = len(func_to_learn([0]*(Ntest-2)))\n",
    "    seq_length_min = 4\n",
    "\n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 1\n",
    "if( task == 'mult pattern 1' or task == 'mult pattern 2'):\n",
    "    pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "    pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,b,b,...)\n",
    "    func_to_learn = lambda s: learnfuncs.f_multpattern(s,pattern1,pattern2,div_symbol)\n",
    "    N_out = 2*(N-2)\n",
    "    Ntest_out = 2*(Ntest-2)\n",
    "    seq_length_min = 4\n",
    "    \n",
    "#########################\n",
    "# MULTIPLE PATTERN TASK 2\n",
    "if( task == 'mult pattern 2' ):\n",
    "    # Almost everything is the same as mult pattern 1, but in pattern 2 we \n",
    "    # make sure there is a div symbol somewhere in the sequence\n",
    "    def generate_input_seq_forcediv(max_symbol,input_length):\n",
    "        t = [random.randint(0,max_symbol) for k in range(input_length)]\n",
    "        div_pos = random.randint(0,len(t)-1)\n",
    "        t[div_pos] = div_symbol\n",
    "        return t\n",
    "    \n",
    "    generate_input_seq = generate_input_seq_forcediv\n",
    "\n",
    "# Give an example input/output pair\n",
    "a = [random.randint(0,num_classes-3) for i in range(N - 2)]\n",
    "fa = func_to_learn(a)\n",
    "\n",
    "print(\"Under the chosen function, the sequence\")\n",
    "print(a)\n",
    "print(\"is mapped to\")\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# INITIALISE STATE #\n",
    "####################\n",
    "\n",
    "one_hots = seqhelper.one_hot_vectors(num_classes)\n",
    "input_size = num_classes # dimension of the input space I\n",
    "\n",
    "#####\n",
    "# NTM\n",
    "\n",
    "def init_state_ntm(batch_size, css, mas, mcs):\n",
    "    state_size = css + 2*mas + mas * mcs\n",
    "    \n",
    "    ra = [0.0]*mas\n",
    "    ra[0] = 1.0\n",
    "    batch_address = np.zeros([batch_size,mas]) + ra\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    init_read_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_write_address = tf.constant(batch_address,dtype=tf.float32,shape=[batch_size,mas]) #+ tf.random_uniform([batch_size, mas], 0.0, 1e-6)\n",
    "    init_memory = tf.truncated_normal([batch_size, mas*mcs], 0.0, 1e-6, dtype=tf.float32)\n",
    "    \n",
    "    state = tf.concat([init_controller_state,init_read_address,init_write_address,init_memory],1)\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "#############\n",
    "# PATTERN NTM\n",
    "\n",
    "def init_state_pattern_ntm(batch_size, css, mas, mcs):\n",
    "    # mas and mcs are arrays of address sizes and content sizes for rings\n",
    "    state_size = css\n",
    "    \n",
    "    init_address = []\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        state_size = state_size + mas[i] * mcs[i] # for memory vector\n",
    "        state_size = state_size + 2 * mas[i] # for addresses (read and write)\n",
    "    \n",
    "        ra = [0.0]*mas[i]\n",
    "        ra[0] = 1.0\n",
    "        init_address.append(np.zeros([batch_size,mas[i]]) + ra)\n",
    "    \n",
    "    init_controller_state = tf.truncated_normal([batch_size, css], 0.0, 1e-6, dtype=tf.float32)    \n",
    "    \n",
    "    tensor_list = [init_controller_state]\n",
    "    \n",
    "    for i in range(len(mas)):\n",
    "        init_read_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        init_write_address = tf.constant(init_address[i],dtype=tf.float32,shape=[batch_size,mas[i]])\n",
    "        tensor_list = tensor_list + [init_read_address,init_write_address]\n",
    "        \n",
    "    for i in range(len(mas)):\n",
    "        # The first ring is initialised to zero, the rest differently\n",
    "        if( i == 0 ):\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "        else:\n",
    "            ra = [0.0]*mcs[i] \n",
    "            ra[0] = 1.0\n",
    "            ra = np.zeros([batch_size,mas[i],mcs[i]]) + ra\n",
    "            ra = tf.constant(ra,dtype=tf.float32,shape=[batch_size,mas[i],mcs[i]])\n",
    "            ra = tf.reshape(ra,[batch_size,mas[i]*mcs[i]])\n",
    "            init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32) + ra\n",
    "            #init_memory = tf.truncated_normal([batch_size, mas[i]*mcs[i]], 0.0, 1e-6, dtype=tf.float32)\n",
    "            \n",
    "        tensor_list = tensor_list + [init_memory]\n",
    "    \n",
    "    state = tf.concat(tensor_list,1)\n",
    "\n",
    "    return state_size, state\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "######################\n",
    "# MULTIPLE PATTERN NTM\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/NTM_25/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_24/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_23/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_22/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_21/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_20/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_19/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_18/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_17/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_16/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_15/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_14/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_13/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_12/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_11/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_10/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_9/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_8/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_7/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_6/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_5/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_4/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_3/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_2/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients/NTM_1/split_grad/concat:0' shape=(250, 2916) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DEFINE MODEL #\n",
    "################\n",
    "\n",
    "inputs = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "targets = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(N + N_out)]\n",
    "\n",
    "# Used in order to flag that we share weights across iterations.\n",
    "# Note that the training and test phases use all the same weights.\n",
    "reuse = False\n",
    "\n",
    "# Set up training graph\n",
    "read_addresses = []\n",
    "read_addresses2 = []\n",
    "read_addresses3 = []\n",
    "read_addresses4 = []\n",
    "write_addresses = []\n",
    "write_addresses2 = []\n",
    "write_addresses3 = []\n",
    "write_addresses4 = []\n",
    "interps = []\n",
    "rnn_outputs = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "    \n",
    "for i in range(N + N_out):\n",
    "    # Logging\n",
    "    if( use_model == 'ntm' ):\n",
    "        h0, curr_read, curr_write, _ = tf.split(state, [controller_state_size,ntm_memory_address_size,\n",
    "                                                        ntm_memory_address_size,-1], 1)\n",
    "\n",
    "    if( use_model == 'pattern_ntm' ):\n",
    "        mas = pattern_ntm_memory_address_sizes\n",
    "        mcs = pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],mas[0] * mcs[0],mas[1] * mcs[1]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        m1_state = ret[5]\n",
    "        m2_state = ret[6]\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm' ):\n",
    "        mas = mult_pattern_ntm_memory_address_sizes\n",
    "        mcs = mult_pattern_ntm_memory_content_sizes\n",
    "        \n",
    "        ret = tf.split(state, [controller_state_size,mas[0],mas[0],mas[1],mas[1],                        \n",
    "                            mas[2],mas[2],mas[3],mas[3],mas[0] * mcs[0],mas[1] * mcs[1],\n",
    "                            mas[2] * mcs[2],mas[3] * mcs[3]], 1)\n",
    "        \n",
    "        h0 = ret[0]\n",
    "        curr_read = ret[1]\n",
    "        curr_write = ret[2]\n",
    "        curr_read2 = ret[3]\n",
    "        curr_write2 = ret[4]\n",
    "        curr_read3 = ret[5]\n",
    "        curr_write3 = ret[6]\n",
    "        curr_read4 = ret[7]\n",
    "        curr_write4 = ret[8]\n",
    "        m1_state = ret[9]\n",
    "        m2_state = ret[10]\n",
    "        m3_state = ret[11]\n",
    "        m4_state = ret[12]\n",
    "\n",
    "    #### RUN MODEL ####\n",
    "    output, state = cell(inputs[i],state,'NTM',reuse)\n",
    "    rnn_outputs.append(output)\n",
    "    ###################\n",
    "    \n",
    "    # More logging\n",
    "    read_addresses.append(curr_read[0,:])\n",
    "    write_addresses.append(curr_write[0,:])\n",
    "    \n",
    "    if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses2.append(curr_read2[0,:])\n",
    "        write_addresses2.append(curr_write2[0,:])\n",
    "        m2_state = tf.reshape(m2_state, [-1,mas[1],mcs[1]])\n",
    "        m2.append(tf.nn.softmax(m2_state[0,:]))\n",
    "        \n",
    "        with tf.variable_scope(\"NTM\",reuse=True):\n",
    "            W_interp = tf.get_variable(\"W_interp\", [controller_state_size,1])\n",
    "            B_interp = tf.get_variable(\"B_interp\", [1])\n",
    "            interp = tf.sigmoid(tf.matmul(h0,W_interp) + B_interp)\n",
    "            interp_matrix = tf.concat([interp,tf.ones_like(interp,dtype=tf.float32) - interp],axis=1) # shape [-1,2]\n",
    "            interps.append(interp_matrix[0,:])\n",
    "        \n",
    "    if( use_model == 'mult_pattern_ntm'):\n",
    "        read_addresses3.append(curr_read3[0,:])\n",
    "        write_addresses3.append(curr_write3[0,:])\n",
    "        read_addresses4.append(curr_read4[0,:])\n",
    "        write_addresses4.append(curr_write4[0,:])\n",
    "        m3_state = tf.reshape(m3_state, [-1,mult_pattern_ntm_memory_address_sizes[2],mult_pattern_ntm_memory_content_sizes[2]])\n",
    "        m3.append(tf.nn.softmax(m3_state[0,:]))\n",
    "        m4_state = tf.reshape(m4_state, [-1,mult_pattern_ntm_memory_address_sizes[3],mult_pattern_ntm_memory_content_sizes[3]])\n",
    "        m4_state = m4_state[0,:]\n",
    "        m4_state = tf.nn.softmax(tf.concat([m4_state,tf.zeros([mult_pattern_ntm_memory_address_sizes[3],1])],1))\n",
    "        m4.append(m4_state)\n",
    "\n",
    "    reuse = True\n",
    "\n",
    "# Final fully connected layer\n",
    "with tf.variable_scope(\"final_layer\"):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size],initializer=init_ops.constant_initializer(0.0))\n",
    "\n",
    "# Note: prediction is a length N list of tensors of shape [None,input_size], where\n",
    "# the jth row of prediction[d] is, for the jth input sequence in the batch,\n",
    "# the probability distribution over symbols for the output symbol in position d.\n",
    "\n",
    "# Note: We allow the length of input sequences to vary between batches, which means\n",
    "# that the cross entropy needs to be masked to the relevant part of the output\n",
    "\n",
    "# Note: we use log_softmax to avoid precision issues with floats causing log(0) to create NaNs\n",
    "\n",
    "logits = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs]\n",
    "prediction = [tf.nn.log_softmax(logit) for logit in logits] \n",
    "ce = [tf.reduce_sum(targets[i] * prediction[i]) for i in range(N + N_out)] # an array of numbers\n",
    "mask = [tf.sign(tf.reduce_max(tf.abs(targets[i]))) for i in range(N + N_out)]\n",
    "ce_mask = [ce[i] * mask[i] for i in range(N + N_out)]\n",
    "cross_entropy = -tf.add_n(ce_mask)\n",
    "cross_entropy /= tf.add_n(mask) # DEBUG do we really need this?\n",
    "# NOTE: here in creating the mask we are assuming that batches have the same sequence length\n",
    "                    \n",
    "optimizer = tf.train.RMSPropOptimizer(1e-4,decay=0.9,momentum=0.9)\n",
    "minimize = optimizer.minimize(cross_entropy)\n",
    "mistakes = [tf.not_equal(tf.argmax(targets[i], 1), tf.argmax(prediction[i], 1)) for i in range(N + N_out)]\n",
    "errors = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes]\n",
    "\n",
    "# Summaries\n",
    "errors_mask = [errors[i] * mask[i] for i in range(N + N_out)]\n",
    "mean_error = tf.add_n(errors_mask)\n",
    "mean_error /= tf.add_n(mask)\n",
    "tf.summary.scalar('error', mean_error)\n",
    "\n",
    "# Initialise the model\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 0 r [0] w [0]\n",
      " Step 1 r [1] w [127]\n",
      " Step 2 r [0] w [0]\n",
      " Step 3 r [0] w [0]\n",
      " Step 4 r [0] w [0]\n",
      " Step 5 r [0] w [0]\n",
      " Step 6 r [0] w [1]\n",
      " Step 7 r [0] w [0]\n",
      " Step 8 r [0] w [0]\n",
      " Step 9 r [0] w [0]\n",
      " Step 10 r [0] w [0]\n",
      " Step 11 r [0] w [0]\n",
      " Step 12 r [0] w [0]\n",
      " Step 13 r [0] w [127]\n",
      " Step 14 r [0] w [127]\n",
      " Step 15 r [0] w [127]\n",
      " Step 16 r [1] w [127]\n",
      " Step 17 r [1] w [126]\n",
      " Step 18 r [1] w [126]\n",
      " Step 19 r [1] w [126]\n",
      " Step 20 r [1] w [125]\n",
      " Step 21 r [1] w [125]\n",
      " Step 22 r [1] w [125]\n",
      " Step 23 r [1] w [125]\n",
      " Step 24 r [1] w [125]\n",
      " Step 25 r [1] w [125]\n",
      "Epoch - 1, mean error - 0.86325\n",
      "Epoch - 2, mean error - 0.771667\n",
      "\n",
      "It took 32 seconds to train.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "random.seed()\n",
    "\n",
    "pre_train_time = time.time()\n",
    "\n",
    "# Training\n",
    "no_of_batches = int(num_training/batch_size)\n",
    "\n",
    "###################\n",
    "# Note on sequences\n",
    "#\n",
    "# Our sequences are of varying length, in the alphabet {0,...,num_classes - 3}.\n",
    "# Each input sequence begins with an initial symbol and ends with a terminal symbol\n",
    "# (the value of which are num_classes - 2 and num_classes - 1 by default). Output\n",
    "# sequences do not have either an initial nor a terminal symbol.\n",
    "#\n",
    "# Both input and output sequences are written on a \"tape\" of length N + N_out.\n",
    "# Input sequences are aligned at the BEGINNING of the tape, and all remaining space\n",
    "# is filled with terminal symbols. Output sequences are aligned at the END OF THE \n",
    "# MATCHING INPUT, with all remaining space filled with zero vectors.\n",
    "#\n",
    "# Example: suppose N = N_out = 10, and num_classes = 10 so that init_symbol = 8\n",
    "# and term_symbol = 9. Then a sequence of length 8 (seq_length = 10 below) is\n",
    "#\n",
    "# a = [4, 4, 5, 6, 3, 3, 6, 7]\n",
    "#\n",
    "# which written on the tape is\n",
    "#\n",
    "# [8, 4, 4, 5, 6, 3, 3, 6, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "#\n",
    "# If we are performing the copy task, so that the output sequence is also a, then\n",
    "# the output written on the tape will be (notice the alignment)\n",
    "#\n",
    "# [-, -, -, -, -, -, -, -, -, 4, 4, 5, 6, 3, 3, 6, 7, -, -, -]\n",
    "#\n",
    "# where - is a symbol whose encoding is the zero vector.\n",
    "\n",
    "def io_generator(max_symbol, input_length, total_length):\n",
    "    \"\"\"\n",
    "    Returns a one-hot encoded pair of input and output sequence, with terminal and initial symbols.\n",
    "    \n",
    "    max_symbol - generate sequences in 0,...,max_symbol\n",
    "    input_length - length of input sequences, without initial and terminal symbols\n",
    "    total_length - length of the buffer, so that the sequences are padded to this length\n",
    "    \"\"\"\n",
    "    a = generate_input_seq(max_symbol,input_length)\n",
    "    fa = func_to_learn(a)\n",
    "    a = [init_symbol] + a + [term_symbol]\n",
    "    a = a + [term_symbol for k in range(total_length-len(a))]\n",
    "    a_onehot = [one_hots[e] for e in a]\n",
    "    fa_onehot = [[0.0]*num_classes for k in range(input_length+1)] + \\\n",
    "                [one_hots[e] for e in fa] + \\\n",
    "                [[0.0]*num_classes for k in range(total_length-(input_length+1)-len(fa))]\n",
    "    return a, np.array(a_onehot), np.array(fa_onehot)\n",
    "\n",
    "error_means = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(no_of_batches):\n",
    "        inp = []\n",
    "        out = []\n",
    "\n",
    "        # We sample each batch on the fly from the set of all sequences. Each\n",
    "        # batch has a fixed length of the sequences. Recall that all input seqs\n",
    "        # have an initial and terminal symbol, so if seq_length = 10 then there\n",
    "        # are eight positions for the \"content\" symbols\n",
    "        seq_length = random.randint(seq_length_min,N)\n",
    "        \n",
    "        for z in range(batch_size):\n",
    "            a, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=N+N_out)\n",
    "            \n",
    "            inp.append(a_onehot)\n",
    "            out.append(fa_onehot)\n",
    "            \n",
    "            # Record the first sequence in the last batch of the last epoch\n",
    "            if( i == epoch - 1 and j == no_of_batches - 1 and z == 0):\n",
    "                final_seq = a\n",
    "        \n",
    "        # An annoying thing here is that we cannot use a list as a key in a \n",
    "        # dictionary. The workaround we found on StackOverflow here:\n",
    "        # http://stackoverflow.com/questions/33684657/issue-feeding-a-list-into-feed-dict-in-tensorflow)\n",
    "        feed_dict = {}\n",
    "        \n",
    "        for d in range(N + N_out):\n",
    "            in_node = inputs[d]\n",
    "            # inp has dimensions [batch_size, N, num_classes] and we want to extract\n",
    "            # the 2D Tensor of shape [batch_size, num_classes] obtained by setting the\n",
    "            # second coordinate to d\n",
    "            ti = []\n",
    "            for k in range(batch_size):\n",
    "                ti.append(inp[k][d])\n",
    "            feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "        for d in range(N + N_out):\n",
    "            out_node = targets[d]\n",
    "            to = []\n",
    "            for k in range(batch_size):\n",
    "                to.append(out[k][d])\n",
    "            feed_dict[out_node] = np.array(to)\n",
    "                \n",
    "        # for the final batch in every 25th epoch, we have some logging\n",
    "        if( j == no_of_batches - 1 and i % 25 == 0 ):\n",
    "            r1_val, w1_val = sess.run([read_addresses,write_addresses],feed_dict)\n",
    "            \n",
    "            if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm' ):\n",
    "                r2_val, w2_val = sess.run([read_addresses2,write_addresses2],feed_dict)\n",
    "            \n",
    "            if( use_model == 'mult_pattern_ntm' ):\n",
    "                r3_val, w3_val, r4_val, w4_val = sess.run([read_addresses3,write_addresses3,read_addresses4,write_addresses4],feed_dict)\n",
    "                \n",
    "            s = 0\n",
    "            for r in range(len(w1_val)):\n",
    "                print_str = \" Step \" + str(s) + \" r [\" + str(r1_val[r].argmax()) + \"]\" + \\\n",
    "                            \" w [\" + str(w1_val[r].argmax()) + \"]\"\n",
    "                    \n",
    "                if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "                    print_str = print_str + \" r2 [\" + str(r2_val[r].argmax()) + \"]\" + \\\n",
    "                          \" w2 [\" + str(w2_val[r].argmax()) + \"]\"     \n",
    "\n",
    "                if( use_model == 'mult_pattern_ntm' ):\n",
    "                    print_str = print_str + \" r3 [\" + str(r3_val[r].argmax()) + \"]\" + \\\n",
    "                          \" w3 [\" + str(w3_val[r].argmax()) + \"]\" + \\\n",
    "                          \" r4 [\" + str(r4_val[r].argmax()) + \"]\" + \" w4 [\" + str(w4_val[r].argmax()) + \"]\"\n",
    "\n",
    "                print(print_str)\n",
    "                                                            \n",
    "                s = s + 1\n",
    "        \n",
    "        # For the final batch of the final epoch, we record the memory states as well\n",
    "        if( j == no_of_batches - 1 and i == epoch - 1 ):\n",
    "            seq_length_for_vis = seq_length - 2\n",
    "            interps_val = sess.run(interps,feed_dict)\n",
    "            m2_val = sess.run(m2,feed_dict)\n",
    "            m3_val = sess.run(m3,feed_dict)\n",
    "            m4_val = sess.run(m4,feed_dict)\n",
    "        \n",
    "        ##### Do gradient descent #####\n",
    "        #summary,mean_error_val,_ = sess.run([merged_summaries,mean_error,minimize], feed_dict)\n",
    "        mean_error_val,_ = sess.run([mean_error,minimize], feed_dict)\n",
    "        ########\n",
    "        \n",
    "        error_means.append(mean_error_val)\n",
    "        \n",
    "        # Write out TensorBoard logs\n",
    "        #file_writer.add_summary(summary)\n",
    "    \n",
    "    # Print the mean error of the final batch in the epoch\n",
    "    print(\"Epoch - \" + str(i+1) + \", mean error - \" + str(np.mean(error_means[-no_of_batches:])))\n",
    "\n",
    "# Write out variables to disk\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess,\"/tmp/model.ckpt\")\n",
    "sess.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"It took \" + str(int(time.time() - pre_train_time)) + \" seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length used for visualisations - 5\n",
      "Sequence used is\n",
      "[8, 2, 2, 0, 2, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "Note: initialisation symbol is 8 and terminal symbol is 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAL8CAYAAAC2zccJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJqhiDniRJkiRVjEFPkiRJkirm/wMal9m05djnWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bd01e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 1 #\n",
    "###########################\n",
    "\n",
    "print(\"Sequence length used for visualisations - \" + str(seq_length_for_vis))\n",
    "print(\"Sequence used is\")\n",
    "print(final_seq)\n",
    "print(\"Note: initialisation symbol is \" + str(init_symbol) + \" and terminal symbol is \" + str(term_symbol))\n",
    "print(\"\")\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 9, 13\n",
    "fig_num = 0\n",
    "\n",
    "# RING 1\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "plt.figure(fig_num)\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "ax1.imshow(np.stack(w1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax1.set_title('Write address (ring 1)')\n",
    "ax1.set_xlabel('position')\n",
    "ax1.set_ylabel('time')\n",
    "\n",
    "ax2.imshow(np.stack(r1_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "ax2.set_title('Read address (ring 1)')\n",
    "ax2.set_xlabel('position')\n",
    "ax2.set_ylabel('time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# VISUALISATIONS - RING 2 #\n",
    "###########################\n",
    "\n",
    "if( use_model == 'pattern_ntm' or use_model == 'mult_pattern_ntm'):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 2)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 2)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Assume that powers2_on_1 has three entries we can use as colour channels\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m2_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 2)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    max_xticks = 2\n",
    "    xloc = plt.MaxNLocator(max_xticks)\n",
    "\n",
    "    ax.imshow(np.stack(interps_val), cmap='bone', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title('Interpolation')\n",
    "    ax.set_xlabel('direct vs indirect')\n",
    "    ax.set_ylabel('time')\n",
    "    ax.xaxis.set_major_locator(xloc)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# VISUALISATIONS - OTHER RINGS #\n",
    "################################\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 3)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 3)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax = plt.subplot(1,1,1)    \n",
    "    ax.imshow(np.stack(m3_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax.set_title('Memory contents (ring 3)')\n",
    "    ax.set_xlabel('position')\n",
    "    ax.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_num = fig_num + 1\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "\n",
    "    ax1.imshow(np.stack(w4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax1.set_title('Write address (ring 4)')\n",
    "    ax1.set_xlabel('position')\n",
    "    ax1.set_ylabel('time')\n",
    "\n",
    "    ax2.imshow(np.stack(r4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax2.set_title('Read address (ring 4)')\n",
    "    ax2.set_xlabel('position')\n",
    "    ax2.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    ax6 = plt.subplot(1,1,1)    \n",
    "    ax6.imshow(np.stack(m4_val), cmap='bone', interpolation='nearest', aspect='equal')\n",
    "    ax6.set_title('Memory contents (ring 4)')\n",
    "    ax6.set_xlabel('position')\n",
    "    ax6.set_ylabel('time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAUKCAYAAABblriAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njYg8AACARkQeAABAIyIPAACgkf8FbMZKg2oaRlIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1531171d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# VISUALISATIONS - ERROR #\n",
    "##########################\n",
    "\n",
    "fig_num = fig_num + 1\n",
    "\n",
    "plt.figure(fig_num)\n",
    "ax = plt.subplot(1,1,1)\n",
    "sc = pandas.Series(error_means)\n",
    "ma = sc.rolling(window=500).mean()\n",
    "ax.plot(sc.index, sc, color='lightgray')\n",
    "ax.plot(ma.index, ma, color='red')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(sc.index.min(), sc.index.max())\n",
    "ax.set_title('Error')\n",
    "ax.set_xlabel('batch')\n",
    "ax.set_ylabel('error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on sequences of length 13\n",
      "\n",
      "Batch - 1, Mean error - 0.786727\n",
      "Batch - 2, Mean error - 0.749636\n",
      "Batch - 3, Mean error - 0.807818\n",
      "Batch - 4, Mean error - 0.793455\n",
      "\n",
      "###########\n",
      "# Summary #\n",
      "###########\n",
      "\n",
      "model         - ntm\n",
      "task name     - mult pattern 2\n",
      "epochs        - 2\n",
      "num_classes   - 10\n",
      "N             - 10\n",
      "Ntest         - 15\n",
      "# weights     - 18958\n",
      "\n",
      "\n",
      "test error    - 0.784409\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# TESTING #\n",
    "###########\n",
    "\n",
    "# Restore the weights from training\n",
    "sess = tf.Session()\n",
    "saver.restore(sess,save_path)\n",
    "\n",
    "inputs_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "targets_test = [tf.placeholder(tf.float32, [None,input_size]) for _ in range(Ntest + Ntest_out)]\n",
    "\n",
    "if( use_model == 'ntm' ):\n",
    "    state_size, state = init_state_ntm(batch_size, controller_state_size, ntm_memory_address_size, ntm_memory_content_size)\n",
    "    cell = ntm.NTM(state_size,input_size,controller_state_size,ntm_memory_address_size,ntm_memory_content_size, ntm_powers)\n",
    "\n",
    "\n",
    "if( use_model == 'pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, pattern_ntm_memory_address_sizes, \n",
    "                                               pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.PatternNTM(state_size, input_size, controller_state_size, pattern_ntm_memory_address_sizes,\n",
    "                          pattern_ntm_memory_content_sizes, pattern_ntm_powers, pattern_ntm_powers_2_on_1, pattern_ntm_direct_bias)\n",
    "\n",
    "if( use_model == 'mult_pattern_ntm' ):\n",
    "    state_size, state = init_state_pattern_ntm(batch_size, controller_state_size, mult_pattern_ntm_memory_address_sizes, \n",
    "                                               mult_pattern_ntm_memory_content_sizes)\n",
    "    cell = ntm.MultPatternNTM(state_size, input_size, controller_state_size, mult_pattern_ntm_memory_address_sizes,\n",
    "                          mult_pattern_ntm_memory_content_sizes, mult_pattern_ntm_powers, mult_pattern_ntm_powers_2_on_1, \n",
    "                              mult_pattern_ntm_direct_bias)\n",
    "# Set up test graph\n",
    "rnn_outputs_test = []\n",
    "reuse = True\n",
    "for i in range(Ntest + Ntest_out):\n",
    "    output, state = cell(inputs_test[i],state,'NTM',reuse)\n",
    "    rnn_outputs_test.append(output)\n",
    "\n",
    "with tf.variable_scope(\"final_layer\",reuse=True):\n",
    "    E = tf.get_variable(\"E\",[controller_state_size,input_size])\n",
    "    F = tf.get_variable(\"F\",[input_size])\n",
    "\n",
    "logits_test = [tf.matmul(rnn_output, E) + F for rnn_output in rnn_outputs_test]\n",
    "prediction_test = [tf.nn.log_softmax(logit) for logit in logits_test] \n",
    "mask = [tf.sign(tf.reduce_max(tf.abs(targets_test[i]))) for i in range(Ntest + Ntest_out)]\n",
    "mistakes_test = [tf.not_equal(tf.argmax(targets_test[i], 1), tf.argmax(prediction_test[i], 1)) for i in range(Ntest + Ntest_out)]\n",
    "errors_test = [tf.reduce_mean(tf.cast(m, tf.float32)) for m in mistakes_test]\n",
    "errors_test_mask = [errors_test[i] * mask[i] for i in range(Ntest + Ntest_out)]\n",
    "mean_error_test = tf.add_n(errors_test_mask)\n",
    "mean_error_test /= tf.add_n(mask)\n",
    "\n",
    "#### RUN TEST ####\n",
    "\n",
    "no_of_batches = int(num_test/batch_size)\n",
    "\n",
    "seq_length = Ntest\n",
    "print(\"Testing on sequences of length \" + str(seq_length-2))\n",
    "print(\"\")\n",
    "\n",
    "error_means = []\n",
    "for j in range(no_of_batches):\n",
    "    inp = []\n",
    "    out = []\n",
    "\n",
    "    for z in range(batch_size):\n",
    "        a, a_onehot, fa_onehot = io_generator(max_symbol=num_classes-3,\n",
    "                                                      input_length=seq_length-2,\n",
    "                                                      total_length=Ntest+Ntest_out)\n",
    "            \n",
    "        inp.append(a_onehot)\n",
    "        out.append(fa_onehot)        \n",
    "        \n",
    "    feed_dict = {}\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        in_node = inputs_test[d]\n",
    "        ti = []\n",
    "        for k in range(batch_size):\n",
    "            ti.append(inp[k][d])\n",
    "        feed_dict[in_node] = np.array(ti)\n",
    "\n",
    "    for d in range(Ntest + Ntest_out):\n",
    "        out_node = targets_test[d]\n",
    "        to = []\n",
    "        for k in range(batch_size):\n",
    "            to.append(out[k][d])\n",
    "        feed_dict[out_node] = np.array(to)\n",
    "            \n",
    "    current_mean = sess.run(mean_error_test, feed_dict)\n",
    "    error_means.append(current_mean)\n",
    "    print(\"Batch - \" + str(j+1) + \", Mean error - \" + str(current_mean))\n",
    "\n",
    "final_error = np.mean(error_means)\n",
    "\n",
    "print(\"\")        \n",
    "print(\"###########\")\n",
    "print(\"# Summary #\")\n",
    "print(\"###########\")\n",
    "print(\"\")\n",
    "print(\"model         - \" + use_model)\n",
    "print(\"task name     - \" + task)\n",
    "print(\"epochs        - \" + str(epoch))\n",
    "print(\"num_classes   - \" + str(num_classes))\n",
    "print(\"N             - \" + str(N))\n",
    "print(\"Ntest         - \" + str(Ntest))\n",
    "print(\"# weights     - \" + str(ntm.count_number_trainable_params()))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"test error    - \" + str(final_error))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
