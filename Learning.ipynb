{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  2.  4.  6.  3.  6.  9.]\n"
     ]
    }
   ],
   "source": [
    "# In TensorFlow once you import the library, commands\n",
    "# such as tf.constant create new nodes in a global\n",
    "# \"default graph\". Then for example the tf.matmul\n",
    "# command actually creates a new node whose value is\n",
    "# tied by an equation to the values of c,d. When evaluated\n",
    "# in a Session via sess.run, the values of these derived\n",
    "# nodes can be extracted.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# Build a dataflow graph.\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "t = tf.matmul(tf.transpose(x),x)\n",
    "t = tf.reshape(t,[-1])\n",
    "\n",
    "# Construct a `Session` to execute the graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Execute the graph and store the value that `e` represents in `result`.\n",
    "result = sess.run(t)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e93f731d902b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Now the row index in inputs and shape currently represents the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1045\u001b[0m       ops.convert_to_tensor(axis,\n\u001b[1;32m   1046\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m                             ).assert_is_compatible_with(tensor_shape.scalar())\n\u001b[1;32m   1049\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                          as_ref=False):\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 302\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "# Here is an example of the main loop in our linear logic RNN\n",
    "# the batch size is 2, input size is 1, state size is 2\n",
    "\n",
    "inputs = tf.constant([[0.0],[1.0]])\n",
    "state = tf.constant([[1.0, 2.0],[3.0, 4.0]])\n",
    "h = array_ops.concat(1, [inputs,state])\n",
    "\n",
    "# Now the row index in inputs and shape currently represents the batch\n",
    "# we convert this to a list index using unpack, after first inserting\n",
    "# a new index to be the row\n",
    "h2 = tf.expand_dims(h,1)\n",
    "h3 = tf.unpack(h2) # a list, containing 1x3 row vectors\n",
    "li = []\n",
    "for row in h3:\n",
    "    li.append(tf.matmul(tf.transpose(row),row))\n",
    "h4 = tf.pack(li)\n",
    "h5 = tf.reshape(h4,[int(h4.get_shape()[0]),-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"inputs shape: \" + str(inputs.get_shape()))\n",
    "print(\"inputs is: \")\n",
    "print(sess.run(inputs))\n",
    "print(\"state shape: \" + str(state.get_shape()))\n",
    "print(\"state is: \")\n",
    "print(sess.run(state))\n",
    "print(\"h shape: \" + str(h.get_shape()))\n",
    "print(\"h is: \")\n",
    "print(sess.run(h))\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"first element of h3 shape: \" + str(h3[0].get_shape()))\n",
    "print(\"first element of h3 is: \")\n",
    "print(sess.run(h3[0]))\n",
    "print(\"h4 shape: \" + str(h4.get_shape()))\n",
    "print(sess.run(h4))\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In practice however the situation is more complicated,\n",
    "# because TF does not infer the batch size and hence cannot\n",
    "# use tf.pack and tf.unpack. Instead we use TensorArray, as follows\n",
    "\n",
    "batch_size = 2\n",
    "TensorArr = tf.TensorArray(tf.float32, 1, dynamic_size=True, infer_shape=False)\n",
    "h3 = TensorArr.unpack(h2)\n",
    "\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"h3 size: \" + str(h3.size()))\n",
    "print(\"h3 first element: \")\n",
    "print(sess.run(h3.read(0)))\n",
    "\n",
    "h3p = tf.TensorArray(tf.float32, 1, dynamic_size=True,infer_shape=False)\n",
    "for row in range(batch_size):\n",
    "    row_tensor = h3.read(row)\n",
    "    \n",
    "    # Note it's important to put h3p = h3p.write each time\n",
    "    h3p = h3p.write(row, tf.matmul(tf.transpose(row_tensor),row_tensor))\n",
    "\n",
    "h4 = h3p.pack()\n",
    "h5 = tf.reshape(h4,[2,-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternatively we can use map_fn. Much better! Uses TensorArray under the hood\n",
    "f = lambda x: tf.reshape(tf.matmul(tf.transpose(x),x),[-1])\n",
    "h5 = tf.map_fn(f, h2)\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trying to understand Tensor / np.array operations\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([-1.0, 2.0])\n",
    "print(sess.run(c+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_reverse(seq):\n",
    "    t = [0]*len(seq)\n",
    "    for j in range(len(seq)):\n",
    "        t[len(seq)-j-1] = seq[j]\n",
    "    return t\n",
    "\n",
    "seq = [0,1,0,1,1]\n",
    "\n",
    "f_reverse(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(10.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = tf.expand_dims(tf.constant([[1.0, 2.0], [3.0, 4.0]]),1)\n",
    "print(sess.run(c))\n",
    "print(c.get_shape())\n",
    "d = tf.constant([[[1.0, 0.0], [0.0, 1.0]], [[2.0, 0.0], [0.0, 2.0]]])\n",
    "e = tf.batch_matmul(c,d)\n",
    "f = tf.squeeze(e)\n",
    "print(sess.run(e))\n",
    "print(\"\")\n",
    "print(sess.run(tf.reshape(e,[2,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "operator_size = 2\n",
    "state_size = 4\n",
    "\n",
    "iota_matrix = []\n",
    "for i in range(state_size):\n",
    "    a = [0.0]*operator_size\n",
    "    if i < operator_size:\n",
    "        a[i] = 1.0\n",
    "    iota_matrix.append(a)\n",
    "    \n",
    "rho_matrix = []\n",
    "for i in range(operator_size):\n",
    "    a = [0.0]*state_size\n",
    "    if i < state_size:\n",
    "        a[i] = 1.0\n",
    "    rho_matrix.append(a)\n",
    "    \n",
    "print(iota_matrix)\n",
    "print(rho_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "#d = tf.expand_dims(c,1)\n",
    "make_diag = lambda A: tf.diag(A)\n",
    "v = tf.map_fn(make_diag,c)\n",
    "print(sess.run(v))\n",
    "print(v.get_shape())\n",
    "print(c.get_shape())\n",
    "print(tf.diag([1.0,2.0,3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the projections to and injections from H to H1 (see Remark 2.6)\n",
    "\n",
    "rho_matrix = []\n",
    "for i in range(state_size):\n",
    "    a = [0.0]*operator_size\n",
    "    if i < operator_size:\n",
    "        a[i] = 1.0\n",
    "    rho_matrix.append(a)\n",
    "    \n",
    "iota_matrix = []\n",
    "for i in range(operator_size):\n",
    "    a = [0.0]*state_size\n",
    "    if i < state_size:\n",
    "        a[i] = 1.0\n",
    "    iota_matrix.append(a)\n",
    "    \n",
    "# If you're confused about the dimensions, it's because we are going\n",
    "# to multiply on the RIGHT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skiprepeat(seq):\n",
    "    t = []\n",
    "    for j in range(len(seq)):\n",
    "        if j % 2 == 0:\n",
    "            t.append(seq[j])\n",
    "        else:\n",
    "            t.append(seq[j-1])\n",
    "    return t\n",
    "\n",
    "print(skiprepeat([1,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotation_tensor(size):\n",
    "    \"\"\"\n",
    "    Returns rotation matrices as a [3,3,3] tensor, which is [R^0, R^1, ..., R^{size-1}] \n",
    "    where R is the rotation matrix sending the first basis element to the second and \n",
    "    the final basis element to the first.\n",
    "    \"\"\"\n",
    "    one_hots = []\n",
    "    for i in range(size):\n",
    "        a = [0.0]*size\n",
    "        a[i] = 1.0\n",
    "        one_hots.append(tf.constant(a))\n",
    "\n",
    "    R_list = []\n",
    "    for i in range(size):\n",
    "        R = []\n",
    "        for j in range(size):\n",
    "            index = (j + i) % size\n",
    "            R.append(one_hots[index])\n",
    "        R_list.append(tf.stack(R))\n",
    "\n",
    "    R_tensor = tf.stack(R_list)\n",
    "\n",
    "    return R_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rotations = rotation_tensor(3)\n",
    "print(rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(rotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hots = []\n",
    "size = 3\n",
    "for i in range(size):\n",
    "    a = [0.0]*size\n",
    "    a[i] = 1.0\n",
    "    one_hots.append(tf.constant(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(1, 13, dtype=np.int32),shape=[2, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.constant(np.arange(13, 25, dtype=np.int32),shape=[2, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(c.get_shape()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "a = array([[[2.0,1.0],[3.0,4.0]],\n",
    "           [[5.0,6.0],[7.0,8.0]]])\n",
    "b = array([[1.0,2.0],\n",
    "          [3.0,4.0]])\n",
    "np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import learnfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_repetitionpattern(seq,pattern):\n",
    "    t = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while(len(t) < len(seq)):\n",
    "        t.append(seq[j % len(seq)])\n",
    "        j = j + pattern[i % len(pattern)]\n",
    "        i = i + 1\n",
    "    return t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = [0,0,1]\n",
    "func_to_learn = lambda s: f_repetitionpattern(s,pattern)\n",
    "\n",
    "func_to_learn([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotation_tensor(size,powers):\n",
    "    \"\"\"\n",
    "    Returns rotation matrices as a [3,3,3] tensor, which is [R^{p_1}, R^{p_2}, ...]\n",
    "    where R is the rotation matrix sending the first basis element to the second and \n",
    "    the final basis element to the first, and powers = [p_1,p_2,...]. The size of the\n",
    "    matrices is given by \"siez\". Note the convention about matrices at the\n",
    "    top of this file.\n",
    "    \"\"\"\n",
    "    one_hots = []\n",
    "    for i in range(size):\n",
    "        a = [0.0]*size\n",
    "        a[i] = 1.0\n",
    "        one_hots.append(tf.constant(a))\n",
    "\n",
    "    R_list = []\n",
    "    for i in powers:\n",
    "        R = []\n",
    "        for j in range(size):\n",
    "            index = (j + i) % size\n",
    "            R.append(one_hots[index])\n",
    "        R_list.append(tf.stack(R))\n",
    "\n",
    "    R_tensor = tf.stack(R_list)\n",
    "\n",
    "    return R_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rotation_tensor(3,[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(rotation_tensor(4,[-1,0,1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffled_seqs(N,num_classes):\n",
    "    \"\"\"\n",
    "    Creates a shuffled list of all sequences of length N from the set {0,1,...,num_classes-1}.\n",
    "    Each sequence comes in the form \n",
    "    \"\"\"\n",
    "    seq_unshuffled = []\n",
    "    a = [0]*N\n",
    "    inc_index = N - 1\n",
    "    \n",
    "    while(1):\n",
    "        seq_unshuffled.append(a)\n",
    "        a = list(a) # make a copy\n",
    "        j = N - 1\n",
    "        \n",
    "        while( j >= 0 and a[j] == num_classes - 1 ):\n",
    "            a[j] = 0\n",
    "            j = j - 1\n",
    "            \n",
    "        if( j == -1 ):\n",
    "            break\n",
    "            \n",
    "        a[j] = a[j] + 1\n",
    "    \n",
    "    seq_shuffled = shuffle(seq_unshuffled)\n",
    "    return seq_unshuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffled_seqs(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [0]*2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.true_divide(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.sample([0,1,2,3,4],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [random.randint(0,3) for i in range(6)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2**20*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.00001*3**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.zeros([2,3])\n",
    "print(a + [1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "ra = [0.0] * 4\n",
    "ra[0] = 1.0\n",
    "ra = np.zeros([2,4,4]) + ra\n",
    "print(ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros([2,10]) + ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1.0,1.0],[1.0,1.0]])\n",
    "b = tf.constant([2.0])\n",
    "print(b.get_shape())\n",
    "print(sess.run(1.0 + a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1.0, 2.0, 3.0])\n",
    "W = tf.constant([[1.],[2.]])\n",
    "B = tf.constant(2.0)\n",
    "h = tf.constant([[1.0, 2.0],[3.0,4.0]])\n",
    "gamma = 1.0 + tf.nn.relu(tf.matmul(h,W) + B)\n",
    "print(sess.run(gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "sharpening_tensor_r = tf.zeros_like(r) + gamma\n",
    "print(sess.run(sharpening_tensor_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharp_r = tf.pow(r, sharpening_tensor_r)\n",
    "print(sess.run(sharp_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "denom_r = tf.reduce_sum(sharp_r,axis=1,keep_dims=True)\n",
    "print(sess.run(denom_r))\n",
    "r_new = sharp_r / denom_r\n",
    "print(sess.run(r_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(r_new.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1/257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "256/257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "4.782969e06/2.73218432e08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.01*2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[0] + [2,3,4] + [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "8**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "256**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed()\n",
    "N = 10\n",
    "N_out = 10\n",
    "term_symbol = 9\n",
    "init_symbol = 8\n",
    "num_classes = 10\n",
    "seq_length = random.randint(3,N)\n",
    "print(\"seq_length = \" + str(seq_length))\n",
    "a = [random.randint(0,num_classes-3) for k in range(seq_length-2)]\n",
    "print(a)\n",
    "fa = [term_symbol for k in range(seq_length-1)] + a + [term_symbol for k in range(N+N_out-2*seq_length+3)]\n",
    "a = [init_symbol] + a + [term_symbol] + [term_symbol for k in range(N+N_out-seq_length)]\n",
    "print(a)\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "print(a[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_of_copies = 2\n",
    "pattern = [0]*(no_of_copies - 1) + [1]\n",
    "print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([1.0] + [0.0]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.zeros([2,2]) + [1.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [[1,2],[2,3]]\n",
    "print(a[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "ax.imshow([[[0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [1.0, 0.0, 0.0]]], cmap='bone', interpolation='nearest', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [0,1,2,3,4]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p():\n",
    "    print(\"x\")\n",
    "    \n",
    "h = p\n",
    "h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_multpattern(seq,pattern1,pattern2,div_symbol):\n",
    "    patterns = [pattern1,pattern2]\n",
    "    t = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    while(j < len(seq)):        \n",
    "        t.append(seq[j])\n",
    "            \n",
    "        j = j + patterns[k][i % len(patterns[k])]\n",
    "        i = i + 1\n",
    "        \n",
    "        while(j < len(seq) and seq[j] == div_symbol ):\n",
    "            k = (k + 1) % 2\n",
    "            j = j + 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 6, 3, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 3, 6, 3, 7,7, 7, 4]\n",
    "f_multpattern(a,[1],[0,1],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1 % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_logits = [False, True]\n",
    "if( use_logits == True ):\n",
    "    print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAEQCAYAAAADNFZtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115805190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "plt.figure(1)\n",
    "ax = plt.subplot(1,1,1)\n",
    "arr = [[[0.1, 0.1, 1.0], [0.0, 0.0, 1.0]]]\n",
    "ax.imshow(arr, cmap='bone', interpolation='nearest', aspect='equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(18.5183889866)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_on(delims, seq, remove_empty=True):\n",
    "    '''Split seq into lists using delims as a delimiting elements.\n",
    "\n",
    "    For example, split_on(delims=2, list=xrange(0,5)) yields [ [0,1], [3,4] ].\n",
    "\n",
    "    delims can be either a single delimiting element or a list or\n",
    "    tuple of multiple delimiting elements. If you wish to use a list\n",
    "    or tuple as a delimiter, you must enclose it in another list or\n",
    "    tuple.\n",
    "\n",
    "    If remove_empty is False, then consecutive delimiter elements or delimiter elements at\n",
    "    the beginning or end of the longlist'''\n",
    "    if type(delims) not in (type(list()), type(tuple())):\n",
    "        delims = ( delims, )\n",
    "    def reduce_fun(lists, elem):\n",
    "        if elem in delims:\n",
    "            if remove_empty and lists[-1] == []:\n",
    "                # Avoid adding multiple empty lists\n",
    "                pass\n",
    "            else:\n",
    "                lists.append([])\n",
    "        else:\n",
    "            lists[-1].append(elem)\n",
    "        return lists\n",
    "    result_list = reduce(reduce_fun, seq, [ [], ])\n",
    "    # Maybe remove trailing empty list\n",
    "    if remove_empty and result_list[-1] == []:\n",
    "        result_list.pop()\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [8, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(split_on([7],[7,1,2,3,7,7,8,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 1, 2, 3, 4, 5, 1, 1, 2, 2, 3, 3, 4, 4, 1, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_repetitionpattern(seq, pattern):\n",
    "    t = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while(j < len(seq)):\n",
    "        t.append(seq[j])\n",
    "        j = j + pattern[i % len(pattern)]\n",
    "        i = i + 1\n",
    "    return t\n",
    "\n",
    "def f_multpattern(seq,patterns,div_symbol):    \n",
    "    # We parse the sequence and create a list of lists,\n",
    "    # of the form [n, L] where n = 0,1 is the pattern\n",
    "    # to use and L is a list of integers to which it should\n",
    "    # be applied\n",
    "\n",
    "    parse_list = []\n",
    "    curr_subseq = []\n",
    "    curr_pattern = 0\n",
    "    j = 0\n",
    "    \n",
    "    while(j < len(seq)):\n",
    "        if(seq[j] != div_symbol):\n",
    "            curr_subseq.append(seq[j])\n",
    "\n",
    "        if(seq[j] == div_symbol or j == len(seq)-1):\n",
    "            if( len(curr_subseq) != 0 ):\n",
    "                parse_list.append([curr_pattern,curr_subseq])\n",
    "\n",
    "        if(seq[j] == div_symbol):\n",
    "            curr_pattern = (curr_pattern + 1) % len(patterns)\n",
    "            curr_subseq = []\n",
    "        \n",
    "        j = j + 1\n",
    "\n",
    "    t = []    \n",
    "    for q in parse_list:\n",
    "        t = t + f_repetitionpattern(q[1],patterns[q[0]])\n",
    "\n",
    "    return t\n",
    "\n",
    "pattern1 = [1] # so (a,b,c,d,e,f,...) goes to (a,b,c,d,e,f,...)\n",
    "pattern2 = [0,1] # so (a,b,c,d,e,f,...) goes to (a,a,c,c,...)\n",
    "func_to_learn = lambda s: f_multpattern(s,[pattern1,pattern2,[1,2]],7)\n",
    "func_to_learn([7,1,2,7,7,1,2,3,4,5,7,1,2,3,4,7,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]]\n",
      "[ True  True False]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def one_hot_vectors(num_classes):\n",
    "    one_hots = []\n",
    "    for i in range(num_classes):\n",
    "        a = [0.0]*num_classes\n",
    "        a[i] = 1.0\n",
    "        one_hots.append(np.array(a))\n",
    "    return one_hots\n",
    "\n",
    "one_hots = one_hot_vectors(4)\n",
    "#print(one_hots)\n",
    "term_symbol = 3\n",
    "\n",
    "targets = np.array([one_hots[0], one_hots[1], one_hots[2]])\n",
    "t = tf.constant(targets,dtype=tf.float32,shape=[3,4])\n",
    "q = tf.not_equal(tf.argmax(t,1),2)\n",
    "print(sess.run(t))\n",
    "print(sess.run(q))\n",
    "#print(sess.run(tf.argmax(t,1)))\n",
    "#print(tf.argmax(t,1).get_shape())\n",
    "#mask = tf.not_equal(t,2)\n",
    "#print(sess.run(mask))\n",
    "#print(tf.argmax(one_hots[2],0))\n",
    "r = tf.reduce_max(tf.cast(q, tf.float32))\n",
    "print(sess.run(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 4, 4, 5]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def f_repetitionpattern(seq, pattern):\n",
    "    t = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while(j < len(seq)):\n",
    "        t.append(seq[j])\n",
    "        j = j + pattern[i % len(pattern)]\n",
    "        i = i + 1\n",
    "    return t\n",
    "\n",
    "f_repetitionpattern([1,2,3,4,5,6],[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2]\n",
      "[1, 2, 2, 4, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "random_pattern = [random.randint(0,2) for k in range(3)]\n",
    "print(random_pattern)\n",
    "a = f_repetitionpattern([1,2,3,4,5,6],random_pattern)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "a[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5]\n",
      "[0, 1, 8, 2, 4, 2, 3, 6, 7, 4]\n"
     ]
    }
   ],
   "source": [
    "def f_varpattern(seq, init_symbol):    \n",
    "    # We parse seq into A.S.B where \".\" stands for concatentation,\n",
    "    # A, B are sequences and S is the init_symbol. Then we run A\n",
    "    # as a pattern on B using f_repetitionpattern\n",
    "    \n",
    "    A = []\n",
    "    B = []\n",
    "    \n",
    "    Sfound = False\n",
    "    for x in seq:\n",
    "        if( x == init_symbol ):\n",
    "            Sfound = True\n",
    "        else:\n",
    "            if( Sfound == False ):\n",
    "                A.append(x)\n",
    "            else:\n",
    "                B.append(x)\n",
    "    \n",
    "    t = f_repetitionpattern(B,A)\n",
    "    return t\n",
    "\n",
    "print(f_varpattern([2,8,1,2,3,4,5],8))\n",
    "\n",
    "varpatterns = [[1],[2],[0,1],[0,2],[1,2]]\n",
    "init_symbol = 8\n",
    "\n",
    "def generate_input_seq_varpattern(max_symbol,input_length):\n",
    "    vp = varpatterns[random.randint(0,len(varpatterns)-1)]\n",
    "    t = vp + [init_symbol] + [random.randint(0,max_symbol) for k in range(input_length-len(vp)-1)]\n",
    "    return t\n",
    "\n",
    "print(generate_input_seq_varpattern(7,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "vp_length = random.randint(1,8)\n",
    "print(vp_length)\n",
    "vp = [random.randint(0,2) for k in range(vp_length)]\n",
    "print(vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])-np.array([0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "q = [1,2,3,4]\n",
    "p = [1,6,3,5]\n",
    "print([int(a==b) for a,b in zip(q,p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
