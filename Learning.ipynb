{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  2.  4.  6.  3.  6.  9.]\n"
     ]
    }
   ],
   "source": [
    "# In TensorFlow once you import the library, commands\n",
    "# such as tf.constant create new nodes in a global\n",
    "# \"default graph\". Then for example the tf.matmul\n",
    "# command actually creates a new node whose value is\n",
    "# tied by an equation to the values of c,d. When evaluated\n",
    "# in a Session via sess.run, the values of these derived\n",
    "# nodes can be extracted.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# Build a dataflow graph.\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "t = tf.matmul(tf.transpose(x),x)\n",
    "t = tf.reshape(t,[-1])\n",
    "\n",
    "# Construct a `Session` to execute the graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Execute the graph and store the value that `e` represents in `result`.\n",
    "result = sess.run(t)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (2, 1)\n",
      "inputs is: \n",
      "[[ 0.]\n",
      " [ 1.]]\n",
      "state shape: (2, 2)\n",
      "state is: \n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]]\n",
      "h shape: (2, 3)\n",
      "h is: \n",
      "[[ 0.  1.  2.]\n",
      " [ 1.  3.  4.]]\n",
      "h2 shape: (2, 1, 3)\n",
      "first element of h3 shape: (1, 3)\n",
      "first element of h3 is: \n",
      "[[ 0.  1.  2.]]\n",
      "h4 shape: (2, 3, 3)\n",
      "[[[  0.   0.   0.]\n",
      "  [  0.   1.   2.]\n",
      "  [  0.   2.   4.]]\n",
      "\n",
      " [[  1.   3.   4.]\n",
      "  [  3.   9.  12.]\n",
      "  [  4.  12.  16.]]]\n",
      "h5 shape: (2, 9)\n",
      "[[  0.   0.   0.   0.   1.   2.   0.   2.   4.]\n",
      " [  1.   3.   4.   3.   9.  12.   4.  12.  16.]]\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of the main loop in our linear logic RNN\n",
    "# the batch size is 2, input size is 1, state size is 2\n",
    "\n",
    "inputs = tf.constant([[0.0],[1.0]])\n",
    "state = tf.constant([[1.0, 2.0],[3.0, 4.0]])\n",
    "h = array_ops.concat(1, [inputs,state])\n",
    "\n",
    "# Now the row index in inputs and shape currently represents the batch\n",
    "# we convert this to a list index using unpack, after first inserting\n",
    "# a new index to be the row\n",
    "h2 = tf.expand_dims(h,1)\n",
    "h3 = tf.unpack(h2) # a list, containing 1x3 row vectors\n",
    "li = []\n",
    "for row in h3:\n",
    "    li.append(tf.matmul(tf.transpose(row),row))\n",
    "h4 = tf.pack(li)\n",
    "h5 = tf.reshape(h4,[int(h4.get_shape()[0]),-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"inputs shape: \" + str(inputs.get_shape()))\n",
    "print(\"inputs is: \")\n",
    "print(sess.run(inputs))\n",
    "print(\"state shape: \" + str(state.get_shape()))\n",
    "print(\"state is: \")\n",
    "print(sess.run(state))\n",
    "print(\"h shape: \" + str(h.get_shape()))\n",
    "print(\"h is: \")\n",
    "print(sess.run(h))\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"first element of h3 shape: \" + str(h3[0].get_shape()))\n",
    "print(\"first element of h3 is: \")\n",
    "print(sess.run(h3[0]))\n",
    "print(\"h4 shape: \" + str(h4.get_shape()))\n",
    "print(sess.run(h4))\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2 shape: (2, 1, 3)\n",
      "h3 size: Tensor(\"TensorArraySize:0\", shape=(), dtype=int32)\n",
      "h3 first element: \n",
      "[[ 0.  1.  2.]]\n",
      "h5 shape: (2, ?)\n",
      "[[  0.   0.   0.   0.   1.   2.   0.   2.   4.]\n",
      " [  1.   3.   4.   3.   9.  12.   4.  12.  16.]]\n"
     ]
    }
   ],
   "source": [
    "# In practice however the situation is more complicated,\n",
    "# because TF does not infer the batch size and hence cannot\n",
    "# use tf.pack and tf.unpack. Instead we use TensorArray, as follows\n",
    "\n",
    "batch_size = 2\n",
    "TensorArr = tf.TensorArray(tf.float32, 1, dynamic_size=True, infer_shape=False)\n",
    "h3 = TensorArr.unpack(h2)\n",
    "\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"h3 size: \" + str(h3.size()))\n",
    "print(\"h3 first element: \")\n",
    "print(sess.run(h3.read(0)))\n",
    "\n",
    "h3p = tf.TensorArray(tf.float32, 1, dynamic_size=True,infer_shape=False)\n",
    "for row in range(batch_size):\n",
    "    row_tensor = h3.read(row)\n",
    "    \n",
    "    # Note it's important to put h3p = h3p.write each time\n",
    "    h3p = h3p.write(row, tf.matmul(tf.transpose(row_tensor),row_tensor))\n",
    "\n",
    "h4 = h3p.pack()\n",
    "h5 = tf.reshape(h4,[2,-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 shape: (2, 9)\n",
      "[[  0.   0.   0.   0.   1.   2.   0.   2.   4.]\n",
      " [  1.   3.   4.   3.   9.  12.   4.  12.  16.]]\n"
     ]
    }
   ],
   "source": [
    "# Alternatively we can use map_fn. Much better! Uses TensorArray under the hood\n",
    "f = lambda x: tf.reshape(tf.matmul(tf.transpose(x),x),[-1])\n",
    "h5 = tf.map_fn(f, h2)\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  4.]\n",
      " [ 2.  6.]]\n"
     ]
    }
   ],
   "source": [
    "# Trying to understand Tensor / np.array operations\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([-1.0, 2.0])\n",
    "print(sess.run(c+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 1.,  0.]), array([ 1.,  0.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.]), array([ 0.,  1.])]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-27ff79e93549>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-27ff79e93549>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for i in range(3)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_reverse(seq):\n",
    "    t = [0]*len(seq)\n",
    "    for j in range(len(seq)):\n",
    "        t[len(seq)-j-1] = seq[j]\n",
    "    return t\n",
    "\n",
    "seq = [0,1,0,1,1]\n",
    "\n",
    "f_reverse(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(10.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  2.]]\n",
      "\n",
      " [[ 3.  4.]]]\n",
      "(2, 1, 2)\n",
      "[[[ 1.  2.]]\n",
      "\n",
      " [[ 6.  8.]]]\n",
      "\n",
      "[[ 1.  2.]\n",
      " [ 6.  8.]]\n"
     ]
    }
   ],
   "source": [
    "c = tf.expand_dims(tf.constant([[1.0, 2.0], [3.0, 4.0]]),1)\n",
    "print(sess.run(c))\n",
    "print(c.get_shape())\n",
    "d = tf.constant([[[1.0, 0.0], [0.0, 1.0]], [[2.0, 0.0], [0.0, 2.0]]])\n",
    "e = tf.batch_matmul(c,d)\n",
    "f = tf.squeeze(e)\n",
    "print(sess.run(e))\n",
    "print(\"\")\n",
    "print(sess.run(tf.reshape(e,[2,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.0], [0.0, 1.0], [0.0, 0.0], [0.0, 0.0]]\n",
      "[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "operator_size = 2\n",
    "state_size = 4\n",
    "\n",
    "iota_matrix = []\n",
    "for i in range(state_size):\n",
    "    a = [0.0]*operator_size\n",
    "    if i < operator_size:\n",
    "        a[i] = 1.0\n",
    "    iota_matrix.append(a)\n",
    "    \n",
    "rho_matrix = []\n",
    "for i in range(operator_size):\n",
    "    a = [0.0]*state_size\n",
    "    if i < state_size:\n",
    "        a[i] = 1.0\n",
    "    rho_matrix.append(a)\n",
    "    \n",
    "print(iota_matrix)\n",
    "print(rho_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
