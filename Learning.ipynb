{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  2.  4.  6.  3.  6.  9.]\n"
     ]
    }
   ],
   "source": [
    "# In TensorFlow once you import the library, commands\n",
    "# such as tf.constant create new nodes in a global\n",
    "# \"default graph\". Then for example the tf.matmul\n",
    "# command actually creates a new node whose value is\n",
    "# tied by an equation to the values of c,d. When evaluated\n",
    "# in a Session via sess.run, the values of these derived\n",
    "# nodes can be extracted.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "# Build a dataflow graph.\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "t = tf.matmul(tf.transpose(x),x)\n",
    "t = tf.reshape(t,[-1])\n",
    "\n",
    "# Construct a `Session` to execute the graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Execute the graph and store the value that `e` represents in `result`.\n",
    "result = sess.run(t)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is an example of the main loop in our linear logic RNN\n",
    "# the batch size is 2, input size is 1, state size is 2\n",
    "\n",
    "inputs = tf.constant([[0.0],[1.0]])\n",
    "state = tf.constant([[1.0, 2.0],[3.0, 4.0]])\n",
    "h = array_ops.concat(1, [inputs,state])\n",
    "\n",
    "# Now the row index in inputs and shape currently represents the batch\n",
    "# we convert this to a list index using unpack, after first inserting\n",
    "# a new index to be the row\n",
    "h2 = tf.expand_dims(h,1)\n",
    "h3 = tf.unpack(h2) # a list, containing 1x3 row vectors\n",
    "li = []\n",
    "for row in h3:\n",
    "    li.append(tf.matmul(tf.transpose(row),row))\n",
    "h4 = tf.pack(li)\n",
    "h5 = tf.reshape(h4,[int(h4.get_shape()[0]),-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"inputs shape: \" + str(inputs.get_shape()))\n",
    "print(\"inputs is: \")\n",
    "print(sess.run(inputs))\n",
    "print(\"state shape: \" + str(state.get_shape()))\n",
    "print(\"state is: \")\n",
    "print(sess.run(state))\n",
    "print(\"h shape: \" + str(h.get_shape()))\n",
    "print(\"h is: \")\n",
    "print(sess.run(h))\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"first element of h3 shape: \" + str(h3[0].get_shape()))\n",
    "print(\"first element of h3 is: \")\n",
    "print(sess.run(h3[0]))\n",
    "print(\"h4 shape: \" + str(h4.get_shape()))\n",
    "print(sess.run(h4))\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In practice however the situation is more complicated,\n",
    "# because TF does not infer the batch size and hence cannot\n",
    "# use tf.pack and tf.unpack. Instead we use TensorArray, as follows\n",
    "\n",
    "batch_size = 2\n",
    "TensorArr = tf.TensorArray(tf.float32, 1, dynamic_size=True, infer_shape=False)\n",
    "h3 = TensorArr.unpack(h2)\n",
    "\n",
    "print(\"h2 shape: \" + str(h2.get_shape()))\n",
    "print(\"h3 size: \" + str(h3.size()))\n",
    "print(\"h3 first element: \")\n",
    "print(sess.run(h3.read(0)))\n",
    "\n",
    "h3p = tf.TensorArray(tf.float32, 1, dynamic_size=True,infer_shape=False)\n",
    "for row in range(batch_size):\n",
    "    row_tensor = h3.read(row)\n",
    "    \n",
    "    # Note it's important to put h3p = h3p.write each time\n",
    "    h3p = h3p.write(row, tf.matmul(tf.transpose(row_tensor),row_tensor))\n",
    "\n",
    "h4 = h3p.pack()\n",
    "h5 = tf.reshape(h4,[2,-1]) # convert back to a 2D tensor\n",
    "\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternatively we can use map_fn. Much better! Uses TensorArray under the hood\n",
    "f = lambda x: tf.reshape(tf.matmul(tf.transpose(x),x),[-1])\n",
    "h5 = tf.map_fn(f, h2)\n",
    "print(\"h5 shape: \" + str(h5.get_shape()))\n",
    "print(sess.run(h5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trying to understand Tensor / np.array operations\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([-1.0, 2.0])\n",
    "print(sess.run(c+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_reverse(seq):\n",
    "    t = [0]*len(seq)\n",
    "    for j in range(len(seq)):\n",
    "        t[len(seq)-j-1] = seq[j]\n",
    "    return t\n",
    "\n",
    "seq = [0,1,0,1,1]\n",
    "\n",
    "f_reverse(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(10.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = tf.expand_dims(tf.constant([[1.0, 2.0], [3.0, 4.0]]),1)\n",
    "print(sess.run(c))\n",
    "print(c.get_shape())\n",
    "d = tf.constant([[[1.0, 0.0], [0.0, 1.0]], [[2.0, 0.0], [0.0, 2.0]]])\n",
    "e = tf.batch_matmul(c,d)\n",
    "f = tf.squeeze(e)\n",
    "print(sess.run(e))\n",
    "print(\"\")\n",
    "print(sess.run(tf.reshape(e,[2,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "operator_size = 2\n",
    "state_size = 4\n",
    "\n",
    "iota_matrix = []\n",
    "for i in range(state_size):\n",
    "    a = [0.0]*operator_size\n",
    "    if i < operator_size:\n",
    "        a[i] = 1.0\n",
    "    iota_matrix.append(a)\n",
    "    \n",
    "rho_matrix = []\n",
    "for i in range(operator_size):\n",
    "    a = [0.0]*state_size\n",
    "    if i < state_size:\n",
    "        a[i] = 1.0\n",
    "    rho_matrix.append(a)\n",
    "    \n",
    "print(iota_matrix)\n",
    "print(rho_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "#d = tf.expand_dims(c,1)\n",
    "make_diag = lambda A: tf.diag(A)\n",
    "v = tf.map_fn(make_diag,c)\n",
    "print(sess.run(v))\n",
    "print(v.get_shape())\n",
    "print(c.get_shape())\n",
    "print(tf.diag([1.0,2.0,3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the projections to and injections from H to H1 (see Remark 2.6)\n",
    "\n",
    "rho_matrix = []\n",
    "for i in range(state_size):\n",
    "    a = [0.0]*operator_size\n",
    "    if i < operator_size:\n",
    "        a[i] = 1.0\n",
    "    rho_matrix.append(a)\n",
    "    \n",
    "iota_matrix = []\n",
    "for i in range(operator_size):\n",
    "    a = [0.0]*state_size\n",
    "    if i < state_size:\n",
    "        a[i] = 1.0\n",
    "    iota_matrix.append(a)\n",
    "    \n",
    "# If you're confused about the dimensions, it's because we are going\n",
    "# to multiply on the RIGHT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skiprepeat(seq):\n",
    "    t = []\n",
    "    for j in range(len(seq)):\n",
    "        if j % 2 == 0:\n",
    "            t.append(seq[j])\n",
    "        else:\n",
    "            t.append(seq[j-1])\n",
    "    return t\n",
    "\n",
    "print(skiprepeat([1,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotation_tensor(size):\n",
    "    \"\"\"\n",
    "    Returns rotation matrices as a [3,3,3] tensor, which is [R^0, R^1, ..., R^{size-1}] \n",
    "    where R is the rotation matrix sending the first basis element to the second and \n",
    "    the final basis element to the first.\n",
    "    \"\"\"\n",
    "    one_hots = []\n",
    "    for i in range(size):\n",
    "        a = [0.0]*size\n",
    "        a[i] = 1.0\n",
    "        one_hots.append(tf.constant(a))\n",
    "\n",
    "    R_list = []\n",
    "    for i in range(size):\n",
    "        R = []\n",
    "        for j in range(size):\n",
    "            index = (j + i) % size\n",
    "            R.append(one_hots[index])\n",
    "        R_list.append(tf.stack(R))\n",
    "\n",
    "    R_tensor = tf.stack(R_list)\n",
    "\n",
    "    return R_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stack_7:0\", shape=(3, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rotations = rotation_tensor(3)\n",
    "print(rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.]\n",
      "  [ 0.  1.  0.]\n",
      "  [ 0.  0.  1.]]\n",
      "\n",
      " [[ 0.  1.  0.]\n",
      "  [ 0.  0.  1.]\n",
      "  [ 1.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.]\n",
      "  [ 1.  0.  0.]\n",
      "  [ 0.  1.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(rotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hots = []\n",
    "size = 3\n",
    "for i in range(size):\n",
    "    a = [0.0]*size\n",
    "    a[i] = 1.0\n",
    "    one_hots.append(tf.constant(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(1, 13, dtype=np.int32),shape=[2, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.constant(np.arange(13, 25, dtype=np.int32),shape=[2, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(c.get_shape()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2.,   2.],\n",
       "        [  9.,  16.]],\n",
       "\n",
       "       [[  5.,  12.],\n",
       "        [ 21.,  32.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "a = array([[[2.0,1.0],[3.0,4.0]],\n",
    "           [[5.0,6.0],[7.0,8.0]]])\n",
    "b = array([[1.0,2.0],\n",
    "          [3.0,4.0]])\n",
    "np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named learnfuncs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4a199da0232c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlearnfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named learnfuncs"
     ]
    }
   ],
   "source": [
    "import learnfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_repetitionpattern(seq,pattern):\n",
    "    t = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while(len(t) < len(seq)):\n",
    "        t.append(seq[j % len(seq)])\n",
    "        j = j + pattern[i % len(pattern)]\n",
    "        i = i + 1\n",
    "    return t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = [1,0,1,2,0,3,0,1,1,0,0,2,2,4,0,1,7,10,2,0,0]\n",
    "func_to_learn = lambda s: f_repetitionpattern(s,pattern)\n",
    "\n",
    "func_to_learn([1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
